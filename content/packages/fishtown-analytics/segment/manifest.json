{"nodes": {"seed.segment_integration_tests.example_segment_pages": {"raw_sql": "", "database": "claire", "schema": "dbt_claire", "fqn": ["segment_integration_tests", "example_segment_pages"], "unique_id": "seed.segment_integration_tests.example_segment_pages", "package_name": "segment_integration_tests", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests", "path": "example_segment_pages.csv", "original_file_path": "data/example_segment_pages.csv", "name": "example_segment_pages", "resource_type": "seed", "alias": "example_segment_pages", "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "tags": []}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "compiled": true, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "", "wrapped_sql": null, "seed_file_path": "/Users/claire/fishtown/packages/segment/integration_tests/data/example_segment_pages.csv"}, "model.segment.segment_web_user_stitching": {"raw_sql": "{{ config(\n    materialized = 'table'\n) }}\n\nwith events as (\n\n    select * from {{ref('segment_web_page_views')}}\n\n),\n\nmapping as (\n\n    select distinct\n    \n        anonymous_id, \n\n        last_value(user_id ignore nulls) over (\n            partition by anonymous_id \n            order by tstamp \n            rows between unbounded preceding and unbounded following\n        ) as user_id,\n\n        min(tstamp) over (\n            partition by anonymous_id\n        ) as first_seen_at,\n\n        max(tstamp) over (\n            partition by anonymous_id\n        ) as last_seen_at\n\n    from events\n\n)\n\nselect * from mapping", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "sessionization", "segment_web_user_stitching"], "unique_id": "model.segment.segment_web_user_stitching", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "sessionization/segment_web_user_stitching.sql", "original_file_path": "models/sessionization/segment_web_user_stitching.sql", "name": "segment_web_user_stitching", "resource_type": "model", "alias": "segment_web_user_stitching", "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": []}, "tags": [], "refs": [["segment_web_page_views"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.segment.segment_web_page_views"]}, "description": "This model performs \"user stitching\" on top of web event data. User stitching is the process of tying all events associated with a cookie to the same user_id, and solves a common problem in event analytics that users are only identified part way through their activity stream. This model returns a single user_id for every anonymous_id, and is later joined in to build a `blended_user_id` field, that acts as the primary user identifier for all sessions.", "columns": {"anonymous_id": {"name": "anonymous_id", "description": "", "meta": {}, "data_type": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "models/sessionization/schema.yml", "build_path": "target/compiled/segment/sessionization/segment_web_user_stitching.sql", "compiled": true, "compiled_sql": "\n\nwith events as (\n\n    select * from \"claire\".\"dbt_claire\".\"segment_web_page_views\"\n\n),\n\nmapping as (\n\n    select distinct\n    \n        anonymous_id, \n\n        last_value(user_id ignore nulls) over (\n            partition by anonymous_id \n            order by tstamp \n            rows between unbounded preceding and unbounded following\n        ) as user_id,\n\n        min(tstamp) over (\n            partition by anonymous_id\n        ) as first_seen_at,\n\n        max(tstamp) over (\n            partition by anonymous_id\n        ) as last_seen_at\n\n    from events\n\n)\n\nselect * from mapping", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith events as (\n\n    select * from \"claire\".\"dbt_claire\".\"segment_web_page_views\"\n\n),\n\nmapping as (\n\n    select distinct\n    \n        anonymous_id, \n\n        last_value(user_id ignore nulls) over (\n            partition by anonymous_id \n            order by tstamp \n            rows between unbounded preceding and unbounded following\n        ) as user_id,\n\n        min(tstamp) over (\n            partition by anonymous_id\n        ) as first_seen_at,\n\n        max(tstamp) over (\n            partition by anonymous_id\n        ) as last_seen_at\n\n    from events\n\n)\n\nselect * from mapping", "wrapped_sql": null}, "model.segment.segment_web_sessions": {"raw_sql": "{{ config(\n    materialized = 'incremental',\n    unique_key = 'session_id',\n    sort = 'session_start_tstamp',\n    dist = 'session_id'\n) }}\n\n{% set sessionization_cutoff %}\n(\n    select\n        {{ dbt_utils.dateadd(\n            'hour',\n            -var('segment_sessionization_trailing_window'),\n            'max(session_start_tstamp)'\n        ) }}\n    from {{this}}\n)\n{% endset %}\n\n{#\nWindow functions are challenging to make incremental. This approach grabs\nexisting values from the existing table and then adds the value of session_number\non top of that seed. During development, this decreased the model runtime\nby 25x on 2 years of data (from 600 to 25 seconds), so even though the code is\nmore complicated, the performance tradeoff is worth it.\n#}\n\nwith sessions as (\n\n    select * from {{ref('segment_web_sessions__stitched')}}\n\n    {% if is_incremental() %}\n    where cast(session_start_tstamp as datetime) > {{sessionization_cutoff}}\n    {% endif %}\n\n),\n\n{% if is_incremental() %}\n\nagg as (\n\n    select\n        blended_user_id,\n        count(*) as starting_session_number\n    from {{this}}\n\n    -- only include sessions that are not going to be resessionized in this run\n    where cast(session_start_tstamp as datetime) <= {{sessionization_cutoff}}\n\n    group by 1\n\n),\n\n{% endif %}\n\nwindowed as (\n\n    select\n\n        *,\n\n        row_number() over (\n            partition by blended_user_id\n            order by sessions.session_start_tstamp\n            )\n            {% if is_incremental() %}+ coalesce(agg.starting_session_number, 0) {% endif %}\n            as session_number\n\n    from sessions\n\n    {% if is_incremental() %}\n    left join agg using (blended_user_id)\n    {% endif %}\n\n\n)\n\nselect * from windowed", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "sessionization", "segment_web_sessions"], "unique_id": "model.segment.segment_web_sessions", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "sessionization/segment_web_sessions.sql", "original_file_path": "models/sessionization/segment_web_sessions.sql", "name": "segment_web_sessions", "resource_type": "model", "alias": "segment_web_sessions", "config": {"enabled": true, "materialized": "incremental", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "unique_key": "session_id", "sort": "session_start_tstamp", "dist": "session_id"}, "tags": [], "refs": [["segment_web_sessions__stitched"]], "sources": [], "depends_on": {"macros": ["macro.dbt_utils.dateadd", "macro.dbt.is_incremental"], "nodes": ["model.segment.segment_web_sessions__stitched"]}, "description": "The purpose of this model is to expose a single web session, derived from Segment web events. Sessions are the most common way that analysis of web visitor behavior is conducted, and although Segment doesn't natively output session data, this model uses standard logic to create sessions out of page view events. \n\nA session is meant to represent a single instance of web activity where a user is actively browsing a website. In this case, we are demarcating sessions by 30 minute windows of inactivity: if there is 30 minutes of inactivity between two page views, the second page view begins a new session. Additionally, page views across different devices will always be tied to different sessions.\n\nThe logic implemented in this particular model is responsible for incrementally calculating a user's session number; the core sessionization logic is done in upstream models.", "columns": {"session_id": {"name": "session_id", "description": "", "meta": {}, "data_type": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "models/sessionization/schema.yml", "build_path": "target/compiled/segment/sessionization/segment_web_sessions.sql", "compiled": true, "compiled_sql": "\n\n\n\n\n\nwith sessions as (\n\n    select * from \"claire\".\"dbt_claire\".\"segment_web_sessions__stitched\"\n\n    \n    where cast(session_start_tstamp as datetime) > \n(\n    select\n        \n  \n\n    dateadd(\n        hour,\n        -3,\n        max(session_start_tstamp)\n        )\n\n\n\n    from \"claire\".\"dbt_claire\".\"segment_web_sessions\"\n)\n\n    \n\n),\n\n\n\nagg as (\n\n    select\n        blended_user_id,\n        count(*) as starting_session_number\n    from \"claire\".\"dbt_claire\".\"segment_web_sessions\"\n\n    -- only include sessions that are not going to be resessionized in this run\n    where cast(session_start_tstamp as datetime) <= \n(\n    select\n        \n  \n\n    dateadd(\n        hour,\n        -3,\n        max(session_start_tstamp)\n        )\n\n\n\n    from \"claire\".\"dbt_claire\".\"segment_web_sessions\"\n)\n\n\n    group by 1\n\n),\n\n\n\nwindowed as (\n\n    select\n\n        *,\n\n        row_number() over (\n            partition by blended_user_id\n            order by sessions.session_start_tstamp\n            )\n            + coalesce(agg.starting_session_number, 0) \n            as session_number\n\n    from sessions\n\n    \n    left join agg using (blended_user_id)\n    \n\n\n)\n\nselect * from windowed", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n\n\n\n\nwith sessions as (\n\n    select * from \"claire\".\"dbt_claire\".\"segment_web_sessions__stitched\"\n\n    \n    where cast(session_start_tstamp as datetime) > \n(\n    select\n        \n  \n\n    dateadd(\n        hour,\n        -3,\n        max(session_start_tstamp)\n        )\n\n\n\n    from \"claire\".\"dbt_claire\".\"segment_web_sessions\"\n)\n\n    \n\n),\n\n\n\nagg as (\n\n    select\n        blended_user_id,\n        count(*) as starting_session_number\n    from \"claire\".\"dbt_claire\".\"segment_web_sessions\"\n\n    -- only include sessions that are not going to be resessionized in this run\n    where cast(session_start_tstamp as datetime) <= \n(\n    select\n        \n  \n\n    dateadd(\n        hour,\n        -3,\n        max(session_start_tstamp)\n        )\n\n\n\n    from \"claire\".\"dbt_claire\".\"segment_web_sessions\"\n)\n\n\n    group by 1\n\n),\n\n\n\nwindowed as (\n\n    select\n\n        *,\n\n        row_number() over (\n            partition by blended_user_id\n            order by sessions.session_start_tstamp\n            )\n            + coalesce(agg.starting_session_number, 0) \n            as session_number\n\n    from sessions\n\n    \n    left join agg using (blended_user_id)\n    \n\n\n)\n\nselect * from windowed", "wrapped_sql": null}, "model.segment.segment_web_sessions__stitched": {"raw_sql": "{{ config(\n    materialized = 'incremental',\n    unique_key = 'session_id',\n    sort = 'session_start_tstamp',\n    dist = 'session_id'\n) }}\n\nwith sessions as (\n\n    select * from {{ref('segment_web_sessions__initial')}}\n\n    {% if is_incremental() %}\n        where cast(session_start_tstamp as datetime) > (\n          select\n            {{ dbt_utils.dateadd(\n                'hour',\n                -var('segment_sessionization_trailing_window'),\n                'max(session_start_tstamp)'\n            ) }}\n          from {{ this }})\n    {% endif %}\n\n),\n\nid_stitching as (\n\n    select * from {{ref('segment_web_user_stitching')}}\n\n),\n\njoined as (\n\n    select\n\n        sessions.*,\n\n        coalesce(id_stitching.user_id, sessions.anonymous_id)\n            as blended_user_id\n\n    from sessions\n    left join id_stitching using (anonymous_id)\n\n)\n\nselect * from joined", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "sessionization", "segment_web_sessions__stitched"], "unique_id": "model.segment.segment_web_sessions__stitched", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "sessionization/segment_web_sessions__stitched.sql", "original_file_path": "models/sessionization/segment_web_sessions__stitched.sql", "name": "segment_web_sessions__stitched", "resource_type": "model", "alias": "segment_web_sessions__stitched", "config": {"enabled": true, "materialized": "incremental", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "unique_key": "session_id", "sort": "session_start_tstamp", "dist": "session_id"}, "tags": [], "refs": [["segment_web_sessions__initial"], ["segment_web_user_stitching"]], "sources": [], "depends_on": {"macros": ["macro.dbt.is_incremental", "macro.dbt_utils.dateadd"], "nodes": ["model.segment.segment_web_sessions__initial", "model.segment.segment_web_user_stitching"]}, "description": "This model joins initial session data with user stitching to get the field `blended_user_id`, the id for a user across all devices that they can be identified on. This logic is broken out from other models because, while incremental, it will frequently need to be rebuilt from scratch: this is because the user stitching process can change the `blended_user_id` values for historical sessions.\n\nIt is recommended to typically run this model in its default configuration (incrementally) but on some regular basis to do a `dbt run --full-refresh --models segment_web_sessions__stitched+` so that this model and downstream models get rebuilt.", "columns": {"session_id": {"name": "session_id", "description": "", "meta": {}, "data_type": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "models/sessionization/schema.yml", "build_path": "target/compiled/segment/sessionization/segment_web_sessions__stitched.sql", "compiled": true, "compiled_sql": "\n\nwith sessions as (\n\n    select * from \"claire\".\"dbt_claire\".\"segment_web_sessions__initial\"\n\n    \n        where cast(session_start_tstamp as datetime) > (\n          select\n            \n  \n\n    dateadd(\n        hour,\n        -3,\n        max(session_start_tstamp)\n        )\n\n\n\n          from \"claire\".\"dbt_claire\".\"segment_web_sessions__stitched\")\n    \n\n),\n\nid_stitching as (\n\n    select * from \"claire\".\"dbt_claire\".\"segment_web_user_stitching\"\n\n),\n\njoined as (\n\n    select\n\n        sessions.*,\n\n        coalesce(id_stitching.user_id, sessions.anonymous_id)\n            as blended_user_id\n\n    from sessions\n    left join id_stitching using (anonymous_id)\n\n)\n\nselect * from joined", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith sessions as (\n\n    select * from \"claire\".\"dbt_claire\".\"segment_web_sessions__initial\"\n\n    \n        where cast(session_start_tstamp as datetime) > (\n          select\n            \n  \n\n    dateadd(\n        hour,\n        -3,\n        max(session_start_tstamp)\n        )\n\n\n\n          from \"claire\".\"dbt_claire\".\"segment_web_sessions__stitched\")\n    \n\n),\n\nid_stitching as (\n\n    select * from \"claire\".\"dbt_claire\".\"segment_web_user_stitching\"\n\n),\n\njoined as (\n\n    select\n\n        sessions.*,\n\n        coalesce(id_stitching.user_id, sessions.anonymous_id)\n            as blended_user_id\n\n    from sessions\n    left join id_stitching using (anonymous_id)\n\n)\n\nselect * from joined", "wrapped_sql": null}, "model.segment.segment_web_sessions__initial": {"raw_sql": "{{ config(\n    materialized = 'incremental',\n    unique_key = 'session_id',\n    sort = 'session_start_tstamp',\n    dist = 'session_id'\n) }}\n\n{% set partition_by = \"partition by session_id\" %}\n\n{% set window_clause = \"\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    \" %}\n\n{% set first_values = {\n    'utm_source' : 'utm_source',\n    'utm_content' : 'utm_content',\n    'utm_medium' : 'utm_medium',\n    'utm_campaign' : 'utm_campaign',\n    'utm_term' : 'utm_term',\n    'gclid' : 'gclid',\n    'page_url' : 'first_page_url',\n    'page_url_host' : 'first_page_url_host',\n    'page_url_path' : 'first_page_url_path',\n    'page_url_query' : 'first_page_url_query',\n    'referrer' : 'referrer',\n    'referrer_host' : 'referrer_host',\n    'device' : 'device',\n    'device_category' : 'device_category'\n    } %}\n\n{% set last_values = {\n    'page_url' : 'last_page_url',\n    'page_url_host' : 'last_page_url_host',\n    'page_url_path' : 'last_page_url_path',\n    'page_url_query' : 'last_page_url_query'\n    } %}\n\n{% for col in var('segment_pass_through_columns') %}\n    {% do first_values.update({col: 'first_' ~ col}) %}\n    {% do last_values.update({col: 'last_' ~ col}) %}\n{% endfor %}\n\nwith pageviews_sessionized as (\n\n    select * from {{ref('segment_web_page_views__sessionized')}}\n\n    {% if is_incremental() %}\n        where cast(tstamp as datetime) > (\n          select\n            {{ dbt_utils.dateadd(\n                'hour',\n                -var('segment_sessionization_trailing_window'),\n                'max(session_start_tstamp)'\n            ) }}\n          from {{ this }})\n    {% endif %}\n\n),\n\nreferrer_mapping as (\n\n    select * from {{ ref('referrer_mapping') }}\n\n),\n\nagg as (\n\n    select distinct\n\n        session_id,\n        anonymous_id,\n        min(tstamp) over ( {{partition_by}} ) as session_start_tstamp,\n        max(tstamp) over ( {{partition_by}} ) as session_end_tstamp,\n        count(*) over ( {{partition_by}} ) as page_views,\n\n        {% for (key, value) in first_values.items() %}\n        first_value({{key}}) over ({{window_clause}}) as {{value}},\n        {% endfor %}\n\n        {% for (key, value) in last_values.items() %}\n        last_value({{key}}) over ({{window_clause}}) as {{value}}{% if not loop.last %},{% endif %}\n        {% endfor %}\n\n    from pageviews_sessionized\n\n),\n\ndiffs as (\n\n    select\n\n        *,\n\n        {{ dbt_utils.datediff('session_start_tstamp', 'session_end_tstamp', 'second') }} as duration_in_s\n\n    from agg\n\n),\n\ntiers as (\n\n    select\n\n        *,\n\n        case\n            when duration_in_s between 0 and 9 then '0s to 9s'\n            when duration_in_s between 10 and 29 then '10s to 29s'\n            when duration_in_s between 30 and 59 then '30s to 59s'\n            when duration_in_s > 59 then '60s or more'\n            else null\n        end as duration_in_s_tier\n\n    from diffs\n\n),\n\nmapped as (\n\n    select\n        tiers.*,\n        referrer_mapping.medium as referrer_medium,\n        referrer_mapping.source as referrer_source\n\n    from tiers\n\n    left join referrer_mapping on tiers.referrer_host = referrer_mapping.host\n\n)\n\nselect * from mapped", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "sessionization", "segment_web_sessions__initial"], "unique_id": "model.segment.segment_web_sessions__initial", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "sessionization/segment_web_sessions__initial.sql", "original_file_path": "models/sessionization/segment_web_sessions__initial.sql", "name": "segment_web_sessions__initial", "resource_type": "model", "alias": "segment_web_sessions__initial", "config": {"enabled": true, "materialized": "incremental", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "unique_key": "session_id", "sort": "session_start_tstamp", "dist": "session_id"}, "tags": [], "refs": [["segment_web_page_views__sessionized"], ["referrer_mapping"]], "sources": [], "depends_on": {"macros": ["macro.dbt.is_incremental", "macro.dbt_utils.datediff", "macro.dbt_utils.dateadd"], "nodes": ["model.segment.segment_web_page_views__sessionized", "seed.segment.referrer_mapping"]}, "description": "This model performs the aggregation of page views into sessions. The `session_id` having already been calculated in `segment_web_page_views__sessionized`, this model simply calls a bunch of window functions to grab the first or last value of a given field and store it at the session level.", "columns": {"session_id": {"name": "session_id", "description": "", "meta": {}, "data_type": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "models/sessionization/schema.yml", "build_path": "target/compiled/segment/sessionization/segment_web_sessions__initial.sql", "compiled": true, "compiled_sql": "\n\n\n\n\n\n\n\n\n\n\n\nwith pageviews_sessionized as (\n\n    select * from \"claire\".\"dbt_claire\".\"segment_web_page_views__sessionized\"\n\n    \n        where cast(tstamp as datetime) > (\n          select\n            \n  \n\n    dateadd(\n        hour,\n        -3,\n        max(session_start_tstamp)\n        )\n\n\n\n          from \"claire\".\"dbt_claire\".\"segment_web_sessions__initial\")\n    \n\n),\n\nreferrer_mapping as (\n\n    select * from \"claire\".\"dbt_claire\".\"referrer_mapping\"\n\n),\n\nagg as (\n\n    select distinct\n\n        session_id,\n        anonymous_id,\n        min(tstamp) over ( partition by session_id ) as session_start_tstamp,\n        max(tstamp) over ( partition by session_id ) as session_end_tstamp,\n        count(*) over ( partition by session_id ) as page_views,\n\n        \n        first_value(utm_source) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as utm_source,\n        \n        first_value(utm_content) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as utm_content,\n        \n        first_value(utm_medium) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as utm_medium,\n        \n        first_value(utm_campaign) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as utm_campaign,\n        \n        first_value(utm_term) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as utm_term,\n        \n        first_value(gclid) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as gclid,\n        \n        first_value(page_url) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as first_page_url,\n        \n        first_value(page_url_host) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as first_page_url_host,\n        \n        first_value(page_url_path) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as first_page_url_path,\n        \n        first_value(page_url_query) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as first_page_url_query,\n        \n        first_value(referrer) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as referrer,\n        \n        first_value(referrer_host) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as referrer_host,\n        \n        first_value(device) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as device,\n        \n        first_value(device_category) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as device_category,\n        \n\n        \n        last_value(page_url) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as last_page_url,\n        \n        last_value(page_url_host) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as last_page_url_host,\n        \n        last_value(page_url_path) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as last_page_url_path,\n        \n        last_value(page_url_query) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as last_page_url_query\n        \n\n    from pageviews_sessionized\n\n),\n\ndiffs as (\n\n    select\n\n        *,\n\n        \n  \n\n    datediff(\n        second,\n        session_start_tstamp,\n        session_end_tstamp\n        )\n\n\n as duration_in_s\n\n    from agg\n\n),\n\ntiers as (\n\n    select\n\n        *,\n\n        case\n            when duration_in_s between 0 and 9 then '0s to 9s'\n            when duration_in_s between 10 and 29 then '10s to 29s'\n            when duration_in_s between 30 and 59 then '30s to 59s'\n            when duration_in_s > 59 then '60s or more'\n            else null\n        end as duration_in_s_tier\n\n    from diffs\n\n),\n\nmapped as (\n\n    select\n        tiers.*,\n        referrer_mapping.medium as referrer_medium,\n        referrer_mapping.source as referrer_source\n\n    from tiers\n\n    left join referrer_mapping on tiers.referrer_host = referrer_mapping.host\n\n)\n\nselect * from mapped", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n\n\n\n\n\n\n\n\n\n\nwith pageviews_sessionized as (\n\n    select * from \"claire\".\"dbt_claire\".\"segment_web_page_views__sessionized\"\n\n    \n        where cast(tstamp as datetime) > (\n          select\n            \n  \n\n    dateadd(\n        hour,\n        -3,\n        max(session_start_tstamp)\n        )\n\n\n\n          from \"claire\".\"dbt_claire\".\"segment_web_sessions__initial\")\n    \n\n),\n\nreferrer_mapping as (\n\n    select * from \"claire\".\"dbt_claire\".\"referrer_mapping\"\n\n),\n\nagg as (\n\n    select distinct\n\n        session_id,\n        anonymous_id,\n        min(tstamp) over ( partition by session_id ) as session_start_tstamp,\n        max(tstamp) over ( partition by session_id ) as session_end_tstamp,\n        count(*) over ( partition by session_id ) as page_views,\n\n        \n        first_value(utm_source) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as utm_source,\n        \n        first_value(utm_content) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as utm_content,\n        \n        first_value(utm_medium) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as utm_medium,\n        \n        first_value(utm_campaign) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as utm_campaign,\n        \n        first_value(utm_term) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as utm_term,\n        \n        first_value(gclid) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as gclid,\n        \n        first_value(page_url) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as first_page_url,\n        \n        first_value(page_url_host) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as first_page_url_host,\n        \n        first_value(page_url_path) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as first_page_url_path,\n        \n        first_value(page_url_query) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as first_page_url_query,\n        \n        first_value(referrer) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as referrer,\n        \n        first_value(referrer_host) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as referrer_host,\n        \n        first_value(device) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as device,\n        \n        first_value(device_category) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as device_category,\n        \n\n        \n        last_value(page_url) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as last_page_url,\n        \n        last_value(page_url_host) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as last_page_url_host,\n        \n        last_value(page_url_path) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as last_page_url_path,\n        \n        last_value(page_url_query) over (\n    partition by session_id\n    order by page_view_number\n    rows between unbounded preceding and unbounded following\n    ) as last_page_url_query\n        \n\n    from pageviews_sessionized\n\n),\n\ndiffs as (\n\n    select\n\n        *,\n\n        \n  \n\n    datediff(\n        second,\n        session_start_tstamp,\n        session_end_tstamp\n        )\n\n\n as duration_in_s\n\n    from agg\n\n),\n\ntiers as (\n\n    select\n\n        *,\n\n        case\n            when duration_in_s between 0 and 9 then '0s to 9s'\n            when duration_in_s between 10 and 29 then '10s to 29s'\n            when duration_in_s between 30 and 59 then '30s to 59s'\n            when duration_in_s > 59 then '60s or more'\n            else null\n        end as duration_in_s_tier\n\n    from diffs\n\n),\n\nmapped as (\n\n    select\n        tiers.*,\n        referrer_mapping.medium as referrer_medium,\n        referrer_mapping.source as referrer_source\n\n    from tiers\n\n    left join referrer_mapping on tiers.referrer_host = referrer_mapping.host\n\n)\n\nselect * from mapped", "wrapped_sql": null}, "model.segment.segment_web_page_views__sessionized": {"raw_sql": "{{ config(\n    materialized = 'incremental',\n    unique_key = 'page_view_id',\n    sort = 'tstamp',\n    dist = 'page_view_id'\n) }}\n\n{#\nthe initial CTE in this model is unusually complicated; its function is to\nselect all pageviews (for all time) for users who have pageviews since the\nmodel was most recently run. there are many window functions in this model so\nin order to appropriately calculate all of them we need each user's entire\npage view history, but we only want to grab that for users who have page view\nevents we need to calculate.\n#}\n\nwith pageviews as (\n\n    select * from {{ref('segment_web_page_views')}}\n\n    {% if is_incremental() %}\n    where anonymous_id in (\n        select distinct anonymous_id\n        from {{ref('segment_web_page_views')}}\n        where cast(tstamp as datetime) >= (\n          select\n            {{ dbt_utils.dateadd(\n                'hour',\n                -var('segment_sessionization_trailing_window'),\n                'max(tstamp)'\n            ) }}\n          from {{ this }})\n        )\n    {% endif %}\n\n),\n\nnumbered as (\n\n    --This CTE is responsible for assigning an all-time page view number for a\n    --given anonymous_id. We don't need to do this across devices because the\n    --whole point of this field is for sessionization, and sessions can't span\n    --multiple devices.\n\n    select\n\n        *,\n\n        row_number() over (\n            partition by anonymous_id\n            order by tstamp\n            ) as page_view_number\n\n    from pageviews\n\n),\n\nlagged as (\n\n    --This CTE is responsible for simply grabbing the last value of `tstamp`.\n    --We'll use this downstream to do timestamp math--it's how we determine the\n    --period of inactivity.\n\n    select\n\n        *,\n\n        lag(tstamp) over (\n            partition by anonymous_id\n            order by page_view_number\n            ) as previous_tstamp\n\n    from numbered\n\n),\n\ndiffed as (\n\n    --This CTE simply calculates `period_of_inactivity`.\n\n    select\n        *,\n        {{ dbt_utils.datediff('previous_tstamp', 'tstamp', 'second') }} as period_of_inactivity\n    from lagged\n\n),\n\nnew_sessions as (\n\n    --This CTE calculates a single 1/0 field--if the period of inactivity prior\n    --to this page view was greater than 30 minutes, the value is 1, otherwise\n    --it's 0. We'll use this to calculate the user's session #.\n\n    select\n        *,\n        case\n            when period_of_inactivity <= {{var('segment_inactivity_cutoff')}} then 0\n            else 1\n        end as new_session\n    from diffed\n\n),\n\nsession_numbers as (\n\n    --This CTE calculates a user's session (1, 2, 3) number from `new_session`.\n    --This single field is the entire point of the entire prior series of\n    --calculations.\n\n    select\n\n        *,\n\n        sum(new_session) over (\n            partition by anonymous_id\n            order by page_view_number\n            rows between unbounded preceding and current row\n            ) as session_number\n\n    from new_sessions\n\n),\n\nsession_ids as (\n\n    --This CTE assigns a globally unique session id based on the combination of\n    --`anonymous_id` and `session_number`.\n\n    select\n\n        {{dbt_utils.star(ref('segment_web_page_views'))}},\n        page_view_number,\n        {{dbt_utils.surrogate_key('anonymous_id', 'session_number')}} as session_id\n\n    from session_numbers\n\n)\n\nselect * from session_ids", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "sessionization", "segment_web_page_views__sessionized"], "unique_id": "model.segment.segment_web_page_views__sessionized", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "sessionization/segment_web_page_views__sessionized.sql", "original_file_path": "models/sessionization/segment_web_page_views__sessionized.sql", "name": "segment_web_page_views__sessionized", "resource_type": "model", "alias": "segment_web_page_views__sessionized", "config": {"enabled": true, "materialized": "incremental", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "unique_key": "page_view_id", "sort": "tstamp", "dist": "page_view_id"}, "tags": [], "refs": [["segment_web_page_views"], ["segment_web_page_views"]], "sources": [], "depends_on": {"macros": ["macro.dbt.is_incremental", "macro.dbt_utils.datediff", "macro.dbt_utils.star", "macro.dbt_utils.surrogate_key", "macro.dbt_utils.dateadd"], "nodes": ["model.segment.segment_web_page_views", "model.segment.segment_web_page_views"]}, "description": "The purpose of this model is to assign a `session_id` to page views. The business logic of how this is done is that any period of inactivity of 30 minutes or more resets the session, and any subsequent page views are assigned a new `session_id`.\n\nThe implementation of this logic is rather involved, and requires multiple CTEs. Comments have been added to the source to describe the purpose of the CTEs that are more esoteric.", "columns": {"page_view_id": {"name": "page_view_id", "description": "", "meta": {}, "data_type": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "models/sessionization/schema.yml", "build_path": "target/compiled/segment/sessionization/segment_web_page_views__sessionized.sql", "compiled": true, "compiled_sql": "\n\n\n\nwith pageviews as (\n\n    select * from \"claire\".\"dbt_claire\".\"segment_web_page_views\"\n\n    \n    where anonymous_id in (\n        select distinct anonymous_id\n        from \"claire\".\"dbt_claire\".\"segment_web_page_views\"\n        where cast(tstamp as datetime) >= (\n          select\n            \n  \n\n    dateadd(\n        hour,\n        -3,\n        max(tstamp)\n        )\n\n\n\n          from \"claire\".\"dbt_claire\".\"segment_web_page_views__sessionized\")\n        )\n    \n\n),\n\nnumbered as (\n\n    --This CTE is responsible for assigning an all-time page view number for a\n    --given anonymous_id. We don't need to do this across devices because the\n    --whole point of this field is for sessionization, and sessions can't span\n    --multiple devices.\n\n    select\n\n        *,\n\n        row_number() over (\n            partition by anonymous_id\n            order by tstamp\n            ) as page_view_number\n\n    from pageviews\n\n),\n\nlagged as (\n\n    --This CTE is responsible for simply grabbing the last value of `tstamp`.\n    --We'll use this downstream to do timestamp math--it's how we determine the\n    --period of inactivity.\n\n    select\n\n        *,\n\n        lag(tstamp) over (\n            partition by anonymous_id\n            order by page_view_number\n            ) as previous_tstamp\n\n    from numbered\n\n),\n\ndiffed as (\n\n    --This CTE simply calculates `period_of_inactivity`.\n\n    select\n        *,\n        \n  \n\n    datediff(\n        second,\n        previous_tstamp,\n        tstamp\n        )\n\n\n as period_of_inactivity\n    from lagged\n\n),\n\nnew_sessions as (\n\n    --This CTE calculates a single 1/0 field--if the period of inactivity prior\n    --to this page view was greater than 30 minutes, the value is 1, otherwise\n    --it's 0. We'll use this to calculate the user's session #.\n\n    select\n        *,\n        case\n            when period_of_inactivity <= 30 * 60 then 0\n            else 1\n        end as new_session\n    from diffed\n\n),\n\nsession_numbers as (\n\n    --This CTE calculates a user's session (1, 2, 3) number from `new_session`.\n    --This single field is the entire point of the entire prior series of\n    --calculations.\n\n    select\n\n        *,\n\n        sum(new_session) over (\n            partition by anonymous_id\n            order by page_view_number\n            rows between unbounded preceding and current row\n            ) as session_number\n\n    from new_sessions\n\n),\n\nsession_ids as (\n\n    --This CTE assigns a globally unique session id based on the combination of\n    --`anonymous_id` and `session_number`.\n\n    select\n\n        \"page_view_id\",\n\"anonymous_id\",\n\"user_id\",\n\"received_at_tstamp\",\n\"sent_at_tstamp\",\n\"tstamp\",\n\"page_url\",\n\"page_url_host\",\n\"page_url_path\",\n\"page_title\",\n\"page_url_query\",\n\"referrer\",\n\"referrer_host\",\n\"utm_source\",\n\"utm_medium\",\n\"utm_campaign\",\n\"utm_term\",\n\"utm_content\",\n\"gclid\",\n\"ip\",\n\"user_agent\",\n\"device\",\n\"device_category\",\n        page_view_number,\n        \n\n    \n        \n    \n\n    md5(cast(\n  \n    \n    coalesce(cast(anonymous_id as \n  varchar\n), '') || '-' || coalesce(cast(session_number as \n  varchar\n), '')\n\n\n as \n  varchar\n)) as session_id\n\n    from session_numbers\n\n)\n\nselect * from session_ids", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n\n\nwith pageviews as (\n\n    select * from \"claire\".\"dbt_claire\".\"segment_web_page_views\"\n\n    \n    where anonymous_id in (\n        select distinct anonymous_id\n        from \"claire\".\"dbt_claire\".\"segment_web_page_views\"\n        where cast(tstamp as datetime) >= (\n          select\n            \n  \n\n    dateadd(\n        hour,\n        -3,\n        max(tstamp)\n        )\n\n\n\n          from \"claire\".\"dbt_claire\".\"segment_web_page_views__sessionized\")\n        )\n    \n\n),\n\nnumbered as (\n\n    --This CTE is responsible for assigning an all-time page view number for a\n    --given anonymous_id. We don't need to do this across devices because the\n    --whole point of this field is for sessionization, and sessions can't span\n    --multiple devices.\n\n    select\n\n        *,\n\n        row_number() over (\n            partition by anonymous_id\n            order by tstamp\n            ) as page_view_number\n\n    from pageviews\n\n),\n\nlagged as (\n\n    --This CTE is responsible for simply grabbing the last value of `tstamp`.\n    --We'll use this downstream to do timestamp math--it's how we determine the\n    --period of inactivity.\n\n    select\n\n        *,\n\n        lag(tstamp) over (\n            partition by anonymous_id\n            order by page_view_number\n            ) as previous_tstamp\n\n    from numbered\n\n),\n\ndiffed as (\n\n    --This CTE simply calculates `period_of_inactivity`.\n\n    select\n        *,\n        \n  \n\n    datediff(\n        second,\n        previous_tstamp,\n        tstamp\n        )\n\n\n as period_of_inactivity\n    from lagged\n\n),\n\nnew_sessions as (\n\n    --This CTE calculates a single 1/0 field--if the period of inactivity prior\n    --to this page view was greater than 30 minutes, the value is 1, otherwise\n    --it's 0. We'll use this to calculate the user's session #.\n\n    select\n        *,\n        case\n            when period_of_inactivity <= 30 * 60 then 0\n            else 1\n        end as new_session\n    from diffed\n\n),\n\nsession_numbers as (\n\n    --This CTE calculates a user's session (1, 2, 3) number from `new_session`.\n    --This single field is the entire point of the entire prior series of\n    --calculations.\n\n    select\n\n        *,\n\n        sum(new_session) over (\n            partition by anonymous_id\n            order by page_view_number\n            rows between unbounded preceding and current row\n            ) as session_number\n\n    from new_sessions\n\n),\n\nsession_ids as (\n\n    --This CTE assigns a globally unique session id based on the combination of\n    --`anonymous_id` and `session_number`.\n\n    select\n\n        \"page_view_id\",\n\"anonymous_id\",\n\"user_id\",\n\"received_at_tstamp\",\n\"sent_at_tstamp\",\n\"tstamp\",\n\"page_url\",\n\"page_url_host\",\n\"page_url_path\",\n\"page_title\",\n\"page_url_query\",\n\"referrer\",\n\"referrer_host\",\n\"utm_source\",\n\"utm_medium\",\n\"utm_campaign\",\n\"utm_term\",\n\"utm_content\",\n\"gclid\",\n\"ip\",\n\"user_agent\",\n\"device\",\n\"device_category\",\n        page_view_number,\n        \n\n    \n        \n    \n\n    md5(cast(\n  \n    \n    coalesce(cast(anonymous_id as \n  varchar\n), '') || '-' || coalesce(cast(session_number as \n  varchar\n), '')\n\n\n as \n  varchar\n)) as session_id\n\n    from session_numbers\n\n)\n\nselect * from session_ids", "wrapped_sql": null}, "model.segment.segment_web_page_views": {"raw_sql": "with source as (\n\n    select * from {{var('segment_page_views_table')}}\n    \n),\n\nrenamed as (\n\n    select\n    \n        id as page_view_id,\n        anonymous_id,\n        user_id,\n        \n        received_at as received_at_tstamp,\n        sent_at as sent_at_tstamp,\n        timestamp as tstamp,\n\n        url as page_url,\n        {{ dbt_utils.get_url_host('url') }} as page_url_host,\n        path as page_url_path,\n        title as page_title,\n        search as page_url_query,\n        \n        referrer,\n        replace(\n            {{ dbt_utils.get_url_host('referrer') }},\n            'www.',\n            ''\n        ) as referrer_host,\n\n        context_campaign_source as utm_source,\n        context_campaign_medium as utm_medium,\n        context_campaign_name as utm_campaign,\n        context_campaign_term as utm_term,\n        context_campaign_content as utm_content,\n        {{ dbt_utils.get_url_parameter('url', 'gclid') }} as gclid,\n        context_ip as ip,\n        context_user_agent as user_agent,\n        case\n            when lower(context_user_agent) like '%android%' then 'Android'\n            else replace(\n                {{ dbt_utils.split_part(dbt_utils.split_part('context_user_agent', \"'('\", 2), \"' '\", 1) }},\n                ';', '')\n        end as device\n        \n        {% if var('segment_pass_through_columns') != [] %}\n        ,\n        {{ var('segment_pass_through_columns') | join (\", \")}}\n        \n        {% endif %}\n                        \n    from source\n\n),\n\nfinal as (\n    \n    select\n        *,\n        case\n            when device = 'iPhone' then 'iPhone'\n            when device = 'Android' then 'Android'\n            when device in ('iPad', 'iPod') then 'Tablet'\n            when device in ('Windows', 'Macintosh', 'X11') then 'Desktop'\n            else 'Uncategorized'\n        end as device_category\n    from renamed\n\n)\n\nselect * from final", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "base", "segment_web_page_views"], "unique_id": "model.segment.segment_web_page_views", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "base/segment_web_page_views.sql", "original_file_path": "models/base/segment_web_page_views.sql", "name": "segment_web_page_views", "resource_type": "model", "alias": "segment_web_page_views", "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": []}, "tags": [], "refs": [["example_segment_pages"]], "sources": [], "depends_on": {"macros": ["macro.dbt_utils.get_url_host", "macro.dbt_utils.get_url_parameter", "macro.dbt_utils.split_part"], "nodes": ["seed.segment_integration_tests.example_segment_pages"]}, "description": "This is a base model for Segment's web page views table. It does some straightforward renaming and parsing of Segment raw data in this table.", "columns": {"page_view_id": {"name": "page_view_id", "description": "", "meta": {}, "data_type": null, "tags": []}}, "meta": {}, "docs": {"show": true}, "patch_path": "models/base/schema.yml", "build_path": "target/compiled/segment/base/segment_web_page_views.sql", "compiled": true, "compiled_sql": "with source as (\n\n    select * from \"claire\".\"dbt_claire\".\"example_segment_pages\"\n    \n),\n\nrenamed as (\n\n    select\n    \n        id as page_view_id,\n        anonymous_id,\n        user_id,\n        \n        received_at as received_at_tstamp,\n        sent_at as sent_at_tstamp,\n        timestamp as tstamp,\n\n        url as page_url,\n        \n  \n    \n    cast(\n  \n\n    split_part(\n        \n  \n\n    split_part(\n        \n\n    replace(\n        \n\n    replace(\n        url,\n        'http://',\n        ''\n    )\n    \n\n\n,\n        'https://',\n        ''\n    )\n    \n\n\n,\n        '/',\n        1\n        )\n\n\n,\n        '?',\n        1\n        )\n\n\n as \n  varchar\n)\n\n as page_url_host,\n        path as page_url_path,\n        title as page_title,\n        search as page_url_query,\n        \n        referrer,\n        replace(\n            \n  \n    \n    cast(\n  \n\n    split_part(\n        \n  \n\n    split_part(\n        \n\n    replace(\n        \n\n    replace(\n        referrer,\n        'http://',\n        ''\n    )\n    \n\n\n,\n        'https://',\n        ''\n    )\n    \n\n\n,\n        '/',\n        1\n        )\n\n\n,\n        '?',\n        1\n        )\n\n\n as \n  varchar\n)\n\n,\n            'www.',\n            ''\n        ) as referrer_host,\n\n        context_campaign_source as utm_source,\n        context_campaign_medium as utm_medium,\n        context_campaign_name as utm_campaign,\n        context_campaign_term as utm_term,\n        context_campaign_content as utm_content,\n        nullif(\n  \n\n    split_part(\n        \n  \n\n    split_part(\n        url,\n        'gclid=',\n        2\n        )\n\n\n,\n        '&',\n        1\n        )\n\n\n,'') as gclid,\n        context_ip as ip,\n        context_user_agent as user_agent,\n        case\n            when lower(context_user_agent) like '%android%' then 'Android'\n            else replace(\n                \n  \n\n    split_part(\n        \n  \n\n    split_part(\n        context_user_agent,\n        '(',\n        2\n        )\n\n\n,\n        ' ',\n        1\n        )\n\n\n,\n                ';', '')\n        end as device\n        \n        \n                        \n    from source\n\n),\n\nfinal as (\n    \n    select\n        *,\n        case\n            when device = 'iPhone' then 'iPhone'\n            when device = 'Android' then 'Android'\n            when device in ('iPad', 'iPod') then 'Tablet'\n            when device in ('Windows', 'Macintosh', 'X11') then 'Desktop'\n            else 'Uncategorized'\n        end as device_category\n    from renamed\n\n)\n\nselect * from final", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "with source as (\n\n    select * from \"claire\".\"dbt_claire\".\"example_segment_pages\"\n    \n),\n\nrenamed as (\n\n    select\n    \n        id as page_view_id,\n        anonymous_id,\n        user_id,\n        \n        received_at as received_at_tstamp,\n        sent_at as sent_at_tstamp,\n        timestamp as tstamp,\n\n        url as page_url,\n        \n  \n    \n    cast(\n  \n\n    split_part(\n        \n  \n\n    split_part(\n        \n\n    replace(\n        \n\n    replace(\n        url,\n        'http://',\n        ''\n    )\n    \n\n\n,\n        'https://',\n        ''\n    )\n    \n\n\n,\n        '/',\n        1\n        )\n\n\n,\n        '?',\n        1\n        )\n\n\n as \n  varchar\n)\n\n as page_url_host,\n        path as page_url_path,\n        title as page_title,\n        search as page_url_query,\n        \n        referrer,\n        replace(\n            \n  \n    \n    cast(\n  \n\n    split_part(\n        \n  \n\n    split_part(\n        \n\n    replace(\n        \n\n    replace(\n        referrer,\n        'http://',\n        ''\n    )\n    \n\n\n,\n        'https://',\n        ''\n    )\n    \n\n\n,\n        '/',\n        1\n        )\n\n\n,\n        '?',\n        1\n        )\n\n\n as \n  varchar\n)\n\n,\n            'www.',\n            ''\n        ) as referrer_host,\n\n        context_campaign_source as utm_source,\n        context_campaign_medium as utm_medium,\n        context_campaign_name as utm_campaign,\n        context_campaign_term as utm_term,\n        context_campaign_content as utm_content,\n        nullif(\n  \n\n    split_part(\n        \n  \n\n    split_part(\n        url,\n        'gclid=',\n        2\n        )\n\n\n,\n        '&',\n        1\n        )\n\n\n,'') as gclid,\n        context_ip as ip,\n        context_user_agent as user_agent,\n        case\n            when lower(context_user_agent) like '%android%' then 'Android'\n            else replace(\n                \n  \n\n    split_part(\n        \n  \n\n    split_part(\n        context_user_agent,\n        '(',\n        2\n        )\n\n\n,\n        ' ',\n        1\n        )\n\n\n,\n                ';', '')\n        end as device\n        \n        \n                        \n    from source\n\n),\n\nfinal as (\n    \n    select\n        *,\n        case\n            when device = 'iPhone' then 'iPhone'\n            when device = 'Android' then 'Android'\n            when device in ('iPad', 'iPod') then 'Tablet'\n            when device in ('Windows', 'Macintosh', 'X11') then 'Desktop'\n            else 'Uncategorized'\n        end as device_category\n    from renamed\n\n)\n\nselect * from final", "wrapped_sql": null}, "analysis.segment.audience_overview": {"raw_sql": "{#-\n-- When compiled, the following query can be used in Mode to calculate the\n-- metrics required for an audience overview similar to the one found in GA.\n-- Since the Liquid `form` tag looks similar to a Jinja tag, dbt is erroring\n-- when compiling as `form` is an unknown tag in Jinja (even when it is wrapped\n-- in a `raw` tag).\n-- As a result, when adding to Mode, replace the comments with the correct tags.\n-#}\n\nwith source as (\n    \n    select * from {{ref('segment_web_sessions')}}\n    \n)\n\n, final as (\n    \n    select\n        date_trunc({% raw %}'{{date_part}}'{% endraw %}, session_start_tstamp)::date as period,\n        \n        count(*) as sessions,\n        count(distinct blended_user_id) as distinct_users,\n        sum(page_views) as page_views,\n        1.0 * sum(page_views) / nullif(count(*), 0) as pages_per_session,\n        avg(duration_in_s) as avg_session_duration,\n        1.0 * sum(case when page_views = 1 then 1 else 0 end) /\n            nullif(count(*), 0) as bounce_rate,\n        sum(case when session_number = 1 then 1 else 0 end) as new_sessions,\n        sum(case when session_number > 1 then 1 else 0 end) as repeat_sessions\n\n    from source\n        \n    where session_start_tstamp >= '{% raw %}{{start_date}}{% endraw %}'\n      and session_start_tstamp <  '{% raw %}{{end_date}}{% endraw %}'\n     \n    group by 1\n    \n)\n\nselect * from final\n\n-- A form tag needs to go here\n\ndate_part:\n    type: select\n    default: day\n    options: [hour, day, week, month]\n\nstart_date:\n    type: date\n    default: 2018-11-01\n\nend_date:\n    type: date\n    default: 2018-12-01\n\n-- An endform tag needs to go here", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "analysis", "mode_queries", "audience_overview"], "unique_id": "analysis.segment.audience_overview", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "analysis/mode_queries/audience_overview.sql", "original_file_path": "analysis/mode_queries/audience_overview.sql", "name": "audience_overview", "resource_type": "analysis", "alias": "audience_overview", "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": []}, "tags": [], "refs": [["segment_web_sessions"]], "sources": [], "depends_on": {"macros": [], "nodes": ["model.segment.segment_web_sessions"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/segment/analysis/mode_queries/audience_overview.sql", "compiled": true, "compiled_sql": "with source as (\n    \n    select * from \"claire\".\"dbt_claire\".\"segment_web_sessions\"\n    \n)\n\n, final as (\n    \n    select\n        date_trunc('{{date_part}}', session_start_tstamp)::date as period,\n        \n        count(*) as sessions,\n        count(distinct blended_user_id) as distinct_users,\n        sum(page_views) as page_views,\n        1.0 * sum(page_views) / nullif(count(*), 0) as pages_per_session,\n        avg(duration_in_s) as avg_session_duration,\n        1.0 * sum(case when page_views = 1 then 1 else 0 end) /\n            nullif(count(*), 0) as bounce_rate,\n        sum(case when session_number = 1 then 1 else 0 end) as new_sessions,\n        sum(case when session_number > 1 then 1 else 0 end) as repeat_sessions\n\n    from source\n        \n    where session_start_tstamp >= '{{start_date}}'\n      and session_start_tstamp <  '{{end_date}}'\n     \n    group by 1\n    \n)\n\nselect * from final\n\n-- A form tag needs to go here\n\ndate_part:\n    type: select\n    default: day\n    options: [hour, day, week, month]\n\nstart_date:\n    type: date\n    default: 2018-11-01\n\nend_date:\n    type: date\n    default: 2018-12-01\n\n-- An endform tag needs to go here", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "with source as (\n    \n    select * from \"claire\".\"dbt_claire\".\"segment_web_sessions\"\n    \n)\n\n, final as (\n    \n    select\n        date_trunc('{{date_part}}', session_start_tstamp)::date as period,\n        \n        count(*) as sessions,\n        count(distinct blended_user_id) as distinct_users,\n        sum(page_views) as page_views,\n        1.0 * sum(page_views) / nullif(count(*), 0) as pages_per_session,\n        avg(duration_in_s) as avg_session_duration,\n        1.0 * sum(case when page_views = 1 then 1 else 0 end) /\n            nullif(count(*), 0) as bounce_rate,\n        sum(case when session_number = 1 then 1 else 0 end) as new_sessions,\n        sum(case when session_number > 1 then 1 else 0 end) as repeat_sessions\n\n    from source\n        \n    where session_start_tstamp >= '{{start_date}}'\n      and session_start_tstamp <  '{{end_date}}'\n     \n    group by 1\n    \n)\n\nselect * from final\n\n-- A form tag needs to go here\n\ndate_part:\n    type: select\n    default: day\n    options: [hour, day, week, month]\n\nstart_date:\n    type: date\n    default: 2018-11-01\n\nend_date:\n    type: date\n    default: 2018-12-01\n\n-- An endform tag needs to go here", "wrapped_sql": null}, "seed.segment.referrer_mapping": {"raw_sql": "", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "referrer_mapping"], "unique_id": "seed.segment.referrer_mapping", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "referrer_mapping.csv", "original_file_path": "data/referrer_mapping.csv", "name": "referrer_mapping", "resource_type": "seed", "alias": "referrer_mapping", "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "tags": []}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "compiled": true, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "", "wrapped_sql": null, "seed_file_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment/data/referrer_mapping.csv"}, "test.segment.unique_segment_web_user_stitching_anonymous_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_unique(model=ref('segment_web_user_stitching'), column_name='anonymous_id') }}", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "schema_test", "unique_segment_web_user_stitching_anonymous_id"], "unique_id": "test.segment.unique_segment_web_user_stitching_anonymous_id", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "schema_test/unique_segment_web_user_stitching_anonymous_id.sql", "original_file_path": "models/sessionization/schema.yml", "name": "unique_segment_web_user_stitching_anonymous_id", "resource_type": "test", "alias": "unique_segment_web_user_stitching_anonymous_id", "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["segment_web_user_stitching"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_unique"], "nodes": ["model.segment.segment_web_user_stitching"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/segment/schema_test/unique_segment_web_user_stitching_anonymous_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        anonymous_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_user_stitching\"\n    where anonymous_id is not null\n    group by anonymous_id\n    having count(*) > 1\n\n) validation_errors\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        anonymous_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_user_stitching\"\n    where anonymous_id is not null\n    group by anonymous_id\n    having count(*) > 1\n\n) validation_errors\n\n", "wrapped_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        anonymous_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_user_stitching\"\n    where anonymous_id is not null\n    group by anonymous_id\n    having count(*) > 1\n\n) validation_errors\n\n", "column_name": "anonymous_id", "test_metadata": {"namespace": null, "name": "unique", "kwargs": {"column_name": "anonymous_id"}}}, "test.segment.not_null_segment_web_user_stitching_anonymous_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_not_null(model=ref('segment_web_user_stitching'), column_name='anonymous_id') }}", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "schema_test", "not_null_segment_web_user_stitching_anonymous_id"], "unique_id": "test.segment.not_null_segment_web_user_stitching_anonymous_id", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "schema_test/not_null_segment_web_user_stitching_anonymous_id.sql", "original_file_path": "models/sessionization/schema.yml", "name": "not_null_segment_web_user_stitching_anonymous_id", "resource_type": "test", "alias": "not_null_segment_web_user_stitching_anonymous_id", "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["segment_web_user_stitching"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_not_null"], "nodes": ["model.segment.segment_web_user_stitching"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/segment/schema_test/not_null_segment_web_user_stitching_anonymous_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_user_stitching\"\nwhere anonymous_id is null\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_user_stitching\"\nwhere anonymous_id is null\n\n", "wrapped_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_user_stitching\"\nwhere anonymous_id is null\n\n", "column_name": "anonymous_id", "test_metadata": {"namespace": null, "name": "not_null", "kwargs": {"column_name": "anonymous_id"}}}, "test.segment.unique_segment_web_page_views__sessionized_page_view_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_unique(model=ref('segment_web_page_views__sessionized'), column_name='page_view_id') }}", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "schema_test", "unique_segment_web_page_views__sessionized_page_view_id"], "unique_id": "test.segment.unique_segment_web_page_views__sessionized_page_view_id", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "schema_test/unique_segment_web_page_views__sessionized_page_view_id.sql", "original_file_path": "models/sessionization/schema.yml", "name": "unique_segment_web_page_views__sessionized_page_view_id", "resource_type": "test", "alias": "unique_segment_web_page_views__sessionized_page_view_id", "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["segment_web_page_views__sessionized"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_unique"], "nodes": ["model.segment.segment_web_page_views__sessionized"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/segment/schema_test/unique_segment_web_page_views__sessionized_page_view_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        page_view_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_page_views__sessionized\"\n    where page_view_id is not null\n    group by page_view_id\n    having count(*) > 1\n\n) validation_errors\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        page_view_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_page_views__sessionized\"\n    where page_view_id is not null\n    group by page_view_id\n    having count(*) > 1\n\n) validation_errors\n\n", "wrapped_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        page_view_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_page_views__sessionized\"\n    where page_view_id is not null\n    group by page_view_id\n    having count(*) > 1\n\n) validation_errors\n\n", "column_name": "page_view_id", "test_metadata": {"namespace": null, "name": "unique", "kwargs": {"column_name": "page_view_id"}}}, "test.segment.not_null_segment_web_page_views__sessionized_page_view_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_not_null(model=ref('segment_web_page_views__sessionized'), column_name='page_view_id') }}", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "schema_test", "not_null_segment_web_page_views__sessionized_page_view_id"], "unique_id": "test.segment.not_null_segment_web_page_views__sessionized_page_view_id", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "schema_test/not_null_segment_web_page_views__sessionized_page_view_id.sql", "original_file_path": "models/sessionization/schema.yml", "name": "not_null_segment_web_page_views__sessionized_page_view_id", "resource_type": "test", "alias": "not_null_segment_web_page_views__sessionized_page_view_id", "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["segment_web_page_views__sessionized"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_not_null"], "nodes": ["model.segment.segment_web_page_views__sessionized"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/segment/schema_test/not_null_segment_web_page_views__sessionized_page_view_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_page_views__sessionized\"\nwhere page_view_id is null\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_page_views__sessionized\"\nwhere page_view_id is null\n\n", "wrapped_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_page_views__sessionized\"\nwhere page_view_id is null\n\n", "column_name": "page_view_id", "test_metadata": {"namespace": null, "name": "not_null", "kwargs": {"column_name": "page_view_id"}}}, "test.segment.unique_segment_web_sessions__initial_session_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_unique(model=ref('segment_web_sessions__initial'), column_name='session_id') }}", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "schema_test", "unique_segment_web_sessions__initial_session_id"], "unique_id": "test.segment.unique_segment_web_sessions__initial_session_id", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "schema_test/unique_segment_web_sessions__initial_session_id.sql", "original_file_path": "models/sessionization/schema.yml", "name": "unique_segment_web_sessions__initial_session_id", "resource_type": "test", "alias": "unique_segment_web_sessions__initial_session_id", "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["segment_web_sessions__initial"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_unique"], "nodes": ["model.segment.segment_web_sessions__initial"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/segment/schema_test/unique_segment_web_sessions__initial_session_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        session_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_sessions__initial\"\n    where session_id is not null\n    group by session_id\n    having count(*) > 1\n\n) validation_errors\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        session_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_sessions__initial\"\n    where session_id is not null\n    group by session_id\n    having count(*) > 1\n\n) validation_errors\n\n", "wrapped_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        session_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_sessions__initial\"\n    where session_id is not null\n    group by session_id\n    having count(*) > 1\n\n) validation_errors\n\n", "column_name": "session_id", "test_metadata": {"namespace": null, "name": "unique", "kwargs": {"column_name": "session_id"}}}, "test.segment.not_null_segment_web_sessions__initial_session_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_not_null(model=ref('segment_web_sessions__initial'), column_name='session_id') }}", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "schema_test", "not_null_segment_web_sessions__initial_session_id"], "unique_id": "test.segment.not_null_segment_web_sessions__initial_session_id", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "schema_test/not_null_segment_web_sessions__initial_session_id.sql", "original_file_path": "models/sessionization/schema.yml", "name": "not_null_segment_web_sessions__initial_session_id", "resource_type": "test", "alias": "not_null_segment_web_sessions__initial_session_id", "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["segment_web_sessions__initial"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_not_null"], "nodes": ["model.segment.segment_web_sessions__initial"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/segment/schema_test/not_null_segment_web_sessions__initial_session_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_sessions__initial\"\nwhere session_id is null\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_sessions__initial\"\nwhere session_id is null\n\n", "wrapped_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_sessions__initial\"\nwhere session_id is null\n\n", "column_name": "session_id", "test_metadata": {"namespace": null, "name": "not_null", "kwargs": {"column_name": "session_id"}}}, "test.segment.unique_segment_web_sessions__stitched_session_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_unique(model=ref('segment_web_sessions__stitched'), column_name='session_id') }}", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "schema_test", "unique_segment_web_sessions__stitched_session_id"], "unique_id": "test.segment.unique_segment_web_sessions__stitched_session_id", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "schema_test/unique_segment_web_sessions__stitched_session_id.sql", "original_file_path": "models/sessionization/schema.yml", "name": "unique_segment_web_sessions__stitched_session_id", "resource_type": "test", "alias": "unique_segment_web_sessions__stitched_session_id", "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["segment_web_sessions__stitched"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_unique"], "nodes": ["model.segment.segment_web_sessions__stitched"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/segment/schema_test/unique_segment_web_sessions__stitched_session_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        session_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_sessions__stitched\"\n    where session_id is not null\n    group by session_id\n    having count(*) > 1\n\n) validation_errors\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        session_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_sessions__stitched\"\n    where session_id is not null\n    group by session_id\n    having count(*) > 1\n\n) validation_errors\n\n", "wrapped_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        session_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_sessions__stitched\"\n    where session_id is not null\n    group by session_id\n    having count(*) > 1\n\n) validation_errors\n\n", "column_name": "session_id", "test_metadata": {"namespace": null, "name": "unique", "kwargs": {"column_name": "session_id"}}}, "test.segment.not_null_segment_web_sessions__stitched_session_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_not_null(model=ref('segment_web_sessions__stitched'), column_name='session_id') }}", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "schema_test", "not_null_segment_web_sessions__stitched_session_id"], "unique_id": "test.segment.not_null_segment_web_sessions__stitched_session_id", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "schema_test/not_null_segment_web_sessions__stitched_session_id.sql", "original_file_path": "models/sessionization/schema.yml", "name": "not_null_segment_web_sessions__stitched_session_id", "resource_type": "test", "alias": "not_null_segment_web_sessions__stitched_session_id", "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["segment_web_sessions__stitched"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_not_null"], "nodes": ["model.segment.segment_web_sessions__stitched"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/segment/schema_test/not_null_segment_web_sessions__stitched_session_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_sessions__stitched\"\nwhere session_id is null\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_sessions__stitched\"\nwhere session_id is null\n\n", "wrapped_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_sessions__stitched\"\nwhere session_id is null\n\n", "column_name": "session_id", "test_metadata": {"namespace": null, "name": "not_null", "kwargs": {"column_name": "session_id"}}}, "test.segment.unique_segment_web_sessions_session_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_unique(model=ref('segment_web_sessions'), column_name='session_id') }}", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "schema_test", "unique_segment_web_sessions_session_id"], "unique_id": "test.segment.unique_segment_web_sessions_session_id", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "schema_test/unique_segment_web_sessions_session_id.sql", "original_file_path": "models/sessionization/schema.yml", "name": "unique_segment_web_sessions_session_id", "resource_type": "test", "alias": "unique_segment_web_sessions_session_id", "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["segment_web_sessions"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_unique"], "nodes": ["model.segment.segment_web_sessions"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/segment/schema_test/unique_segment_web_sessions_session_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        session_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_sessions\"\n    where session_id is not null\n    group by session_id\n    having count(*) > 1\n\n) validation_errors\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        session_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_sessions\"\n    where session_id is not null\n    group by session_id\n    having count(*) > 1\n\n) validation_errors\n\n", "wrapped_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        session_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_sessions\"\n    where session_id is not null\n    group by session_id\n    having count(*) > 1\n\n) validation_errors\n\n", "column_name": "session_id", "test_metadata": {"namespace": null, "name": "unique", "kwargs": {"column_name": "session_id"}}}, "test.segment.not_null_segment_web_sessions_session_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_not_null(model=ref('segment_web_sessions'), column_name='session_id') }}", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "schema_test", "not_null_segment_web_sessions_session_id"], "unique_id": "test.segment.not_null_segment_web_sessions_session_id", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "schema_test/not_null_segment_web_sessions_session_id.sql", "original_file_path": "models/sessionization/schema.yml", "name": "not_null_segment_web_sessions_session_id", "resource_type": "test", "alias": "not_null_segment_web_sessions_session_id", "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["segment_web_sessions"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_not_null"], "nodes": ["model.segment.segment_web_sessions"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/segment/schema_test/not_null_segment_web_sessions_session_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_sessions\"\nwhere session_id is null\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_sessions\"\nwhere session_id is null\n\n", "wrapped_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_sessions\"\nwhere session_id is null\n\n", "column_name": "session_id", "test_metadata": {"namespace": null, "name": "not_null", "kwargs": {"column_name": "session_id"}}}, "test.segment.unique_segment_web_page_views_page_view_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_unique(model=ref('segment_web_page_views'), column_name='page_view_id') }}", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "schema_test", "unique_segment_web_page_views_page_view_id"], "unique_id": "test.segment.unique_segment_web_page_views_page_view_id", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "schema_test/unique_segment_web_page_views_page_view_id.sql", "original_file_path": "models/base/schema.yml", "name": "unique_segment_web_page_views_page_view_id", "resource_type": "test", "alias": "unique_segment_web_page_views_page_view_id", "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["segment_web_page_views"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_unique"], "nodes": ["model.segment.segment_web_page_views"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/segment/schema_test/unique_segment_web_page_views_page_view_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        page_view_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_page_views\"\n    where page_view_id is not null\n    group by page_view_id\n    having count(*) > 1\n\n) validation_errors\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        page_view_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_page_views\"\n    where page_view_id is not null\n    group by page_view_id\n    having count(*) > 1\n\n) validation_errors\n\n", "wrapped_sql": "\n\n\n\nselect count(*)\nfrom (\n\n    select\n        page_view_id\n\n    from \"claire\".\"dbt_claire\".\"segment_web_page_views\"\n    where page_view_id is not null\n    group by page_view_id\n    having count(*) > 1\n\n) validation_errors\n\n", "column_name": "page_view_id", "test_metadata": {"namespace": null, "name": "unique", "kwargs": {"column_name": "page_view_id"}}}, "test.segment.not_null_segment_web_page_views_page_view_id": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_not_null(model=ref('segment_web_page_views'), column_name='page_view_id') }}", "database": "claire", "schema": "dbt_claire", "fqn": ["segment", "schema_test", "not_null_segment_web_page_views_page_view_id"], "unique_id": "test.segment.not_null_segment_web_page_views_page_view_id", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "schema_test/not_null_segment_web_page_views_page_view_id.sql", "original_file_path": "models/base/schema.yml", "name": "not_null_segment_web_page_views_page_view_id", "resource_type": "test", "alias": "not_null_segment_web_page_views_page_view_id", "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {"segment_page_views_table": "{{ ref('example_segment_pages') }}", "segment_sessionization_trailing_window": 3, "segment_inactivity_cutoff": "30 * 60", "segment_pass_through_columns": []}, "quoting": {}, "column_types": {}, "tags": [], "severity": "ERROR"}, "tags": ["schema"], "refs": [["segment_web_page_views"]], "sources": [], "depends_on": {"macros": ["macro.dbt.test_not_null"], "nodes": ["model.segment.segment_web_page_views"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target/compiled/segment/schema_test/not_null_segment_web_page_views_page_view_id.sql", "compiled": true, "compiled_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_page_views\"\nwhere page_view_id is null\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_page_views\"\nwhere page_view_id is null\n\n", "wrapped_sql": "\n\n\n\nselect count(*)\nfrom \"claire\".\"dbt_claire\".\"segment_web_page_views\"\nwhere page_view_id is null\n\n", "column_name": "page_view_id", "test_metadata": {"namespace": null, "name": "not_null", "kwargs": {"column_name": "page_view_id"}}}}, "macros": {"macro.dbt.statement": {"raw_sql": "{% macro statement(name=None, fetch_result=False, auto_begin=True) -%}\n  {%- if execute: -%}\n    {%- set sql = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n      {{ write(sql) }}\n    {%- endif -%}\n\n    {%- set status, res = adapter.execute(sql, auto_begin=auto_begin, fetch=fetch_result) -%}\n    {%- if name is not none -%}\n      {{ store_result(name, status=status, agate_table=res) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro noop_statement(name=None, status=None, res=None) -%}\n  {%- set sql = caller() -%}\n\n  {%- if name == 'main' -%}\n    {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n    {{ write(sql) }}\n  {%- endif -%}\n\n  {%- if name is not none -%}\n    {{ store_result(name, status=status, agate_table=res) }}\n  {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt.statement", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/core.sql", "original_file_path": "macros/core.sql", "resource_type": "macro", "name": "statement", "macro_sql": "{% macro statement(name=None, fetch_result=False, auto_begin=True) -%}\n  {%- if execute: -%}\n    {%- set sql = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n      {{ write(sql) }}\n    {%- endif -%}\n\n    {%- set status, res = adapter.execute(sql, auto_begin=auto_begin, fetch=fetch_result) -%}\n    {%- if name is not none -%}\n      {{ store_result(name, status=status, agate_table=res) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.noop_statement": {"raw_sql": "{% macro statement(name=None, fetch_result=False, auto_begin=True) -%}\n  {%- if execute: -%}\n    {%- set sql = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n      {{ write(sql) }}\n    {%- endif -%}\n\n    {%- set status, res = adapter.execute(sql, auto_begin=auto_begin, fetch=fetch_result) -%}\n    {%- if name is not none -%}\n      {{ store_result(name, status=status, agate_table=res) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro noop_statement(name=None, status=None, res=None) -%}\n  {%- set sql = caller() -%}\n\n  {%- if name == 'main' -%}\n    {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n    {{ write(sql) }}\n  {%- endif -%}\n\n  {%- if name is not none -%}\n    {{ store_result(name, status=status, agate_table=res) }}\n  {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt.noop_statement", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/core.sql", "original_file_path": "macros/core.sql", "resource_type": "macro", "name": "noop_statement", "macro_sql": "{% macro noop_statement(name=None, status=None, res=None) -%}\n  {%- set sql = caller() -%}\n\n  {%- if name == 'main' -%}\n    {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n    {{ write(sql) }}\n  {%- endif -%}\n\n  {%- if name is not none -%}\n    {{ store_result(name, status=status, agate_table=res) }}\n  {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.run_hooks": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.run_hooks", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "run_hooks", "macro_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.column_list": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.column_list", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "column_list", "macro_sql": "{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.column_list_for_create_table": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.column_list_for_create_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "column_list_for_create_table", "macro_sql": "{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.make_hook_config": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.make_hook_config", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "make_hook_config", "macro_sql": "{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.before_begin": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.before_begin", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "before_begin", "macro_sql": "{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.in_transaction": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.in_transaction", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "in_transaction", "macro_sql": "{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.after_commit": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.after_commit", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "after_commit", "macro_sql": "{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.drop_relation_if_exists": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.drop_relation_if_exists", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "drop_relation_if_exists", "macro_sql": "{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.load_relation": {"raw_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}\n\n\n{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}\n\n\n{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}\n\n\n{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}\n\n\n{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}\n\n\n{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "unique_id": "macro.dbt.load_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/helpers.sql", "original_file_path": "macros/materializations/helpers.sql", "resource_type": "macro", "name": "load_relation", "macro_sql": "{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_merge_sql": {"raw_sql": "{% macro snapshot_merge_sql(target, source, insert_cols) -%}\n  {{ adapter_macro('snapshot_merge_sql', target, source, insert_cols) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set insert_cols_csv = insert_cols | join(', ') -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n    using {{ source }} as DBT_INTERNAL_SOURCE\n    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id\n\n    when matched\n     and DBT_INTERNAL_DEST.dbt_valid_to is null\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'update'\n        then update\n        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert ({{ insert_cols_csv }})\n        values ({{ insert_cols_csv }})\n    ;\n{% endmacro %}", "unique_id": "macro.dbt.snapshot_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshot/snapshot_merge.sql", "resource_type": "macro", "name": "snapshot_merge_sql", "macro_sql": "{% macro snapshot_merge_sql(target, source, insert_cols) -%}\n  {{ adapter_macro('snapshot_merge_sql', target, source, insert_cols) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_merge_sql": {"raw_sql": "{% macro snapshot_merge_sql(target, source, insert_cols) -%}\n  {{ adapter_macro('snapshot_merge_sql', target, source, insert_cols) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set insert_cols_csv = insert_cols | join(', ') -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n    using {{ source }} as DBT_INTERNAL_SOURCE\n    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id\n\n    when matched\n     and DBT_INTERNAL_DEST.dbt_valid_to is null\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'update'\n        then update\n        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert ({{ insert_cols_csv }})\n        values ({{ insert_cols_csv }})\n    ;\n{% endmacro %}", "unique_id": "macro.dbt.default__snapshot_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshot/snapshot_merge.sql", "resource_type": "macro", "name": "default__snapshot_merge_sql", "macro_sql": "{% macro default__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set insert_cols_csv = insert_cols | join(', ') -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n    using {{ source }} as DBT_INTERNAL_SOURCE\n    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id\n\n    when matched\n     and DBT_INTERNAL_DEST.dbt_valid_to is null\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'update'\n        then update\n        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert ({{ insert_cols_csv }})\n        values ({{ insert_cols_csv }})\n    ;\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.strategy_dispatch": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.strategy_dispatch", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "strategy_dispatch", "macro_sql": "{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_hash_arguments": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.snapshot_hash_arguments", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "snapshot_hash_arguments", "macro_sql": "{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_hash_arguments": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.default__snapshot_hash_arguments", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "default__snapshot_hash_arguments", "macro_sql": "{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_get_time": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.snapshot_get_time", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "snapshot_get_time", "macro_sql": "{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_get_time": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.default__snapshot_get_time", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "default__snapshot_get_time", "macro_sql": "{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_timestamp_strategy": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.snapshot_timestamp_strategy", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "snapshot_timestamp_strategy", "macro_sql": "{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_string_as_time": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.snapshot_string_as_time", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "snapshot_string_as_time", "macro_sql": "{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_string_as_time": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.default__snapshot_string_as_time", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "default__snapshot_string_as_time", "macro_sql": "{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_check_all_get_existing_columns": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.snapshot_check_all_get_existing_columns", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "snapshot_check_all_get_existing_columns", "macro_sql": "{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_check_strategy": {"raw_sql": "{#\n    Dispatch strategies by name, optionally qualified to a package\n#}\n{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}\n\n\n{#\n    Create SCD Hash SQL fields cross-db\n#}\n{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter_macro('snapshot_hash_arguments', args) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}\n\n\n{#\n    Get the current time cross-db\n#}\n{% macro snapshot_get_time() -%}\n  {{ adapter_macro('snapshot_get_time') }}\n{%- endmacro %}\n\n{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}\n\n\n{#\n    Core strategy definitions\n#}\n{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ updated_at }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}\n\n\n{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter_macro('snapshot_string_as_time', timestamp) }}\n{%- endmacro %}\n\n\n{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}\n\n\n{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}\n\n\n{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "unique_id": "macro.dbt.snapshot_check_strategy", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/strategies.sql", "original_file_path": "macros/materializations/snapshot/strategies.sql", "resource_type": "macro", "name": "snapshot_check_strategy", "macro_sql": "{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {# don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.create_columns": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.create_columns", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "create_columns", "macro_sql": "{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_columns": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.default__create_columns", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "default__create_columns", "macro_sql": "{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.post_snapshot": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.post_snapshot", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "post_snapshot", "macro_sql": "{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__post_snapshot": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.default__post_snapshot", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "default__post_snapshot", "macro_sql": "{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_staging_table_inserts": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.snapshot_staging_table_inserts", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "snapshot_staging_table_inserts", "macro_sql": "{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_staging_table_updates": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.snapshot_staging_table_updates", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "snapshot_staging_table_updates", "macro_sql": "{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.build_snapshot_table": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.build_snapshot_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "build_snapshot_table", "macro_sql": "{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_or_create_relation": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.get_or_create_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "get_or_create_relation", "macro_sql": "{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.build_snapshot_staging_table": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.build_snapshot_staging_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "build_snapshot_staging_table", "macro_sql": "{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_snapshot_default": {"raw_sql": "{#\n    Add new columns to the table if applicable\n#}\n{% macro create_columns(relation, columns) %}\n  {{ adapter_macro('create_columns', relation, columns) }}\n{% endmacro %}\n\n{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}\n\n\n{% macro post_snapshot(staging_relation) %}\n  {{ adapter_macro('post_snapshot', staging_relation) }}\n{% endmacro %}\n\n{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}\n\n\n{% macro snapshot_staging_table_inserts(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    )\n\n    select * from insertions\n\n{%- endmacro %}\n\n\n{% macro snapshot_staging_table_updates(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    source_data as (\n\n        select\n            *,\n            {{ strategy.scd_id }} as dbt_scd_id,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from\n\n        from snapshot_query\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            snapshotted_data.dbt_scd_id,\n            source_data.dbt_valid_from as dbt_valid_to\n\n        from source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n\n    )\n\n    select * from updates\n\n{%- endmacro %}\n\n\n{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}\n\n\n{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}\n\n{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set inserts_select = snapshot_staging_table_inserts(strategy, sql, target_relation) %}\n    {% set updates_select = snapshot_staging_table_updates(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation_inserts') %}\n        {{ create_table_as(True, tmp_relation, inserts_select) }}\n    {% endcall %}\n\n    {% call statement('build_snapshot_staging_relation_updates') %}\n        insert into {{ tmp_relation }} (dbt_change_type, dbt_scd_id, dbt_valid_to)\n        select dbt_change_type, dbt_scd_id, dbt_valid_to from (\n            {{ updates_select }}\n        ) dbt_sbq\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n\n{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.materialization_snapshot_default", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshot/snapshot.sql", "original_file_path": "macros/materializations/snapshot/snapshot.sql", "resource_type": "macro", "name": "materialization_snapshot_default", "macro_sql": "{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% call statement('main') -%}\n          {{ create_table_as(False, target_relation, build_sql) }}\n      {% endcall %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% call statement('main') %}\n          {{ snapshot_merge_sql(\n                target = target_relation,\n                source = staging_table,\n                insert_cols = quoted_source_columns\n             )\n          }}\n      {% endcall %}\n\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.create_csv_table": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.create_csv_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "create_csv_table", "macro_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.reset_csv_table": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.reset_csv_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "reset_csv_table", "macro_sql": "{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.load_csv_rows": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.load_csv_rows", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "load_csv_rows", "macro_sql": "{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_csv_table": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.default__create_csv_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "default__create_csv_table", "macro_sql": "{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__reset_csv_table": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.default__reset_csv_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "default__reset_csv_table", "macro_sql": "{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_seed_column_quoted_csv": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.get_seed_column_quoted_csv", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "get_seed_column_quoted_csv", "macro_sql": "{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.basic_load_csv_rows": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.basic_load_csv_rows", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "basic_load_csv_rows", "macro_sql": "{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__load_csv_rows": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.default__load_csv_rows", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "default__load_csv_rows", "macro_sql": "{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_seed_default": {"raw_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter_macro('create_csv_table', model, agate_table) }}\n{%- endmacro %}\n\n{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter_macro('reset_csv_table', model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}\n\n{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter_macro('load_csv_rows', model, agate_table) }}\n{%- endmacro %}\n\n{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}\n\n\n{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}\n\n\n{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}\n\n\n{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "unique_id": "macro.dbt.materialization_seed_default", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/seed/seed.sql", "original_file_path": "macros/materializations/seed/seed.sql", "resource_type": "macro", "name": "materialization_seed_default", "macro_sql": "{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.incremental_upsert": {"raw_sql": "{% macro incremental_upsert(tmp_relation, target_relation, unique_key=none, statement_name=\"main\") %}\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n\n    {%- if unique_key is not none -%}\n    delete\n    from {{ target_relation }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ tmp_relation }}\n    );\n    {%- endif %}\n\n    insert into {{ target_relation }} ({{ dest_cols_csv }})\n    (\n       select {{ dest_cols_csv }}\n       from {{ tmp_relation }}\n    );\n{%- endmacro %}", "unique_id": "macro.dbt.incremental_upsert", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/incremental/helpers.sql", "original_file_path": "macros/materializations/incremental/helpers.sql", "resource_type": "macro", "name": "incremental_upsert", "macro_sql": "{% macro incremental_upsert(tmp_relation, target_relation, unique_key=none, statement_name=\"main\") %}\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n\n    {%- if unique_key is not none -%}\n    delete\n    from {{ target_relation }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ tmp_relation }}\n    );\n    {%- endif %}\n\n    insert into {{ target_relation }} ({{ dest_cols_csv }})\n    (\n       select {{ dest_cols_csv }}\n       from {{ tmp_relation }}\n    );\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_incremental_default": {"raw_sql": "{% materialization incremental, default -%}\n\n  {% set unique_key = config.get('unique_key') %}\n  {% set full_refresh_mode = flags.FULL_REFRESH %}\n\n  {% set target_relation = this %}\n  {% set existing_relation = load_relation(this) %}\n  {% set tmp_relation = make_temp_relation(this) %}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set to_drop = [] %}\n  {% if existing_relation is none %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif existing_relation.is_view or full_refresh_mode %}\n      {#-- Make sure the backup doesn't exist so we don't encounter issues with the rename below #}\n      {% set backup_identifier = existing_relation.identifier ~ \"__dbt_backup\" %}\n      {% set backup_relation = existing_relation.incorporate(path={\"identifier\": backup_identifier}) %}\n      {% do adapter.drop_relation(backup_relation) %}\n\n      {% do adapter.rename_relation(target_relation, backup_relation) %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n      {% do to_drop.append(backup_relation) %}\n  {% else %}\n      {% set tmp_relation = make_temp_relation(target_relation) %}\n      {% do run_query(create_table_as(True, tmp_relation, sql)) %}\n      {% do adapter.expand_target_column_types(\n             from_relation=tmp_relation,\n             to_relation=target_relation) %}\n      {% set build_sql = incremental_upsert(tmp_relation, target_relation, unique_key=unique_key) %}\n  {% endif %}\n\n  {% call statement(\"main\") %}\n      {{ build_sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {% do adapter.commit() %}\n\n  {% for rel in to_drop %}\n      {% do adapter.drop_relation(rel) %}\n  {% endfor %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "unique_id": "macro.dbt.materialization_incremental_default", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "resource_type": "macro", "name": "materialization_incremental_default", "macro_sql": "{% materialization incremental, default -%}\n\n  {% set unique_key = config.get('unique_key') %}\n  {% set full_refresh_mode = flags.FULL_REFRESH %}\n\n  {% set target_relation = this %}\n  {% set existing_relation = load_relation(this) %}\n  {% set tmp_relation = make_temp_relation(this) %}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set to_drop = [] %}\n  {% if existing_relation is none %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif existing_relation.is_view or full_refresh_mode %}\n      {#-- Make sure the backup doesn't exist so we don't encounter issues with the rename below #}\n      {% set backup_identifier = existing_relation.identifier ~ \"__dbt_backup\" %}\n      {% set backup_relation = existing_relation.incorporate(path={\"identifier\": backup_identifier}) %}\n      {% do adapter.drop_relation(backup_relation) %}\n\n      {% do adapter.rename_relation(target_relation, backup_relation) %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n      {% do to_drop.append(backup_relation) %}\n  {% else %}\n      {% set tmp_relation = make_temp_relation(target_relation) %}\n      {% do run_query(create_table_as(True, tmp_relation, sql)) %}\n      {% do adapter.expand_target_column_types(\n             from_relation=tmp_relation,\n             to_relation=target_relation) %}\n      {% set build_sql = incremental_upsert(tmp_relation, target_relation, unique_key=unique_key) %}\n  {% endif %}\n\n  {% call statement(\"main\") %}\n      {{ build_sql }}\n  {% endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {% do adapter.commit() %}\n\n  {% for rel in to_drop %}\n      {% do adapter.drop_relation(rel) %}\n  {% endfor %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_merge_sql": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.get_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "get_merge_sql", "macro_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_delete_insert_merge_sql": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "get_delete_insert_merge_sql", "macro_sql": "{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_insert_overwrite_merge_sql": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.get_insert_overwrite_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "get_insert_overwrite_merge_sql", "macro_sql": "{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_merge_sql": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.default__get_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "default__get_merge_sql", "macro_sql": "{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_quoted_csv": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.get_quoted_csv", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "get_quoted_csv", "macro_sql": "{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.common_get_delete_insert_merge_sql": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.common_get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "common_get_delete_insert_merge_sql", "macro_sql": "{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_delete_insert_merge_sql": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.default__get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "default__get_delete_insert_merge_sql", "macro_sql": "{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_insert_overwrite_merge_sql": {"raw_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter_macro('get_merge_sql', target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter_macro('get_delete_insert_merge_sql', target, source, unique_key, dest_columns) }}\n{%- endmacro %}\n\n\n{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n  {{ adapter_macro('get_insert_overwrite_merge_sql', target, source, dest_columns, predicates) }}\n{%- endmacro %}\n\n\n{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}\n\n\n{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}\n\n\n{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}\n\n{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}\n\n\n{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "unique_id": "macro.dbt.default__get_insert_overwrite_merge_sql", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/common/merge.sql", "original_file_path": "macros/materializations/common/merge.sql", "resource_type": "macro", "name": "default__get_insert_overwrite_merge_sql", "macro_sql": "{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n    \n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_table_default": {"raw_sql": "{% materialization table, default %}\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type='table') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema,\n                                                      database=database,\n                                                      type='table') -%}\n\n  /*\n      See ../view/view.sql for more information about this relation.\n  */\n  {%- set backup_relation_type = 'table' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type=backup_relation_type) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n\n  -- drop the temp relations if they exists for some reason\n  {{ adapter.drop_relation(intermediate_relation) }}\n  {{ adapter.drop_relation(backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_table_as(False, intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  {% if old_relation is not none %}\n      {{ adapter.rename_relation(target_relation, backup_relation) }}\n  {% endif %}\n\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  -- finally, drop the existing/backup relation after the commit\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n{% endmaterialization %}", "unique_id": "macro.dbt.materialization_table_default", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/table/table.sql", "original_file_path": "macros/materializations/table/table.sql", "resource_type": "macro", "name": "materialization_table_default", "macro_sql": "{% materialization table, default %}\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type='table') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema,\n                                                      database=database,\n                                                      type='table') -%}\n\n  /*\n      See ../view/view.sql for more information about this relation.\n  */\n  {%- set backup_relation_type = 'table' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type=backup_relation_type) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n\n  -- drop the temp relations if they exists for some reason\n  {{ adapter.drop_relation(intermediate_relation) }}\n  {{ adapter.drop_relation(backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_table_as(False, intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  {% if old_relation is not none %}\n      {{ adapter.rename_relation(target_relation, backup_relation) }}\n  {% endif %}\n\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  -- finally, drop the existing/backup relation after the commit\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n{% endmaterialization %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_view_default": {"raw_sql": "{%- materialization view, default -%}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, database=database,\n                                                type='view') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema, database=database, type='view') -%}\n\n  /*\n     This relation (probably) doesn't exist yet. If it does exist, it's a leftover from\n     a previous run, and we're going to try to drop it immediately. At the end of this\n     materialization, we're going to rename the \"old_relation\" to this identifier,\n     and then we're going to drop it. In order to make sure we run the correct one of:\n       - drop view ...\n       - drop table ...\n\n     We need to set the type of this relation to be the type of the old_relation, if it exists,\n     or else \"view\" as a sane default if it does not. Note that if the old_relation does not\n     exist, then there is nothing to move out of the way and subsequentally drop. In that case,\n     this relation will be effectively unused.\n  */\n  {%- set backup_relation_type = 'view' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema, database=database,\n                                                type=backup_relation_type) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- drop the temp relations if they exists for some reason\n  {{ adapter.drop_relation(intermediate_relation) }}\n  {{ adapter.drop_relation(backup_relation) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  -- move the existing view out of the way\n  {% if old_relation is not none %}\n    {{ adapter.rename_relation(target_relation, backup_relation) }}\n  {% endif %}\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization -%}", "unique_id": "macro.dbt.materialization_view_default", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/view/view.sql", "original_file_path": "macros/materializations/view/view.sql", "resource_type": "macro", "name": "materialization_view_default", "macro_sql": "{%- materialization view, default -%}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, database=database,\n                                                type='view') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema, database=database, type='view') -%}\n\n  /*\n     This relation (probably) doesn't exist yet. If it does exist, it's a leftover from\n     a previous run, and we're going to try to drop it immediately. At the end of this\n     materialization, we're going to rename the \"old_relation\" to this identifier,\n     and then we're going to drop it. In order to make sure we run the correct one of:\n       - drop view ...\n       - drop table ...\n\n     We need to set the type of this relation to be the type of the old_relation, if it exists,\n     or else \"view\" as a sane default if it does not. Note that if the old_relation does not\n     exist, then there is nothing to move out of the way and subsequentally drop. In that case,\n     this relation will be effectively unused.\n  */\n  {%- set backup_relation_type = 'view' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema, database=database,\n                                                type=backup_relation_type) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- drop the temp relations if they exists for some reason\n  {{ adapter.drop_relation(intermediate_relation) }}\n  {{ adapter.drop_relation(backup_relation) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  -- move the existing view out of the way\n  {% if old_relation is not none %}\n    {{ adapter.rename_relation(target_relation, backup_relation) }}\n  {% endif %}\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization -%}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.handle_existing_table": {"raw_sql": "{% macro handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter_macro(\"dbt.handle_existing_table\", full_refresh, old_relation) }}\n{% endmacro %}\n\n{% macro default__handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}\n\n{# /*\n       Core materialization implementation. BigQuery and Snowflake are similar\n       because both can use `create or replace view` where the resulting view schema\n       is not necessarily the same as the existing view. On Redshift, this would\n       result in: ERROR:  cannot change number of columns in view\n\n       This implementation is superior to the create_temp, swap_with_existing, drop_old\n       paradigm because transactions don't run DDL queries atomically on Snowflake. By using\n       `create or replace view`, the materialization becomes atomic in nature.\n    */\n#}\n\n{% macro create_or_replace_view(run_outside_transaction_hooks=True) %}\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set target_relation = api.Relation.create(\n      identifier=identifier, schema=schema, database=database,\n      type='view') -%}\n\n  {% if run_outside_transaction_hooks %}\n      -- no transactions on BigQuery\n      {{ run_hooks(pre_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  -- `BEGIN` happens here on Snowflake\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- If there's a table with the same name and we weren't told to full refresh,\n  -- that's an error. If we were told to full refresh, drop it. This behavior differs\n  -- for Snowflake and BigQuery, so multiple dispatch is used.\n  {%- if old_relation is not none and old_relation.is_table -%}\n    {{ handle_existing_table(flags.FULL_REFRESH, old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(target_relation, sql) }}\n  {%- endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if run_outside_transaction_hooks %}\n      -- No transactions on BigQuery\n      {{ run_hooks(post_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmacro %}", "unique_id": "macro.dbt.handle_existing_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/view/create_or_replace_view.sql", "original_file_path": "macros/materializations/view/create_or_replace_view.sql", "resource_type": "macro", "name": "handle_existing_table", "macro_sql": "{% macro handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter_macro(\"dbt.handle_existing_table\", full_refresh, old_relation) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__handle_existing_table": {"raw_sql": "{% macro handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter_macro(\"dbt.handle_existing_table\", full_refresh, old_relation) }}\n{% endmacro %}\n\n{% macro default__handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}\n\n{# /*\n       Core materialization implementation. BigQuery and Snowflake are similar\n       because both can use `create or replace view` where the resulting view schema\n       is not necessarily the same as the existing view. On Redshift, this would\n       result in: ERROR:  cannot change number of columns in view\n\n       This implementation is superior to the create_temp, swap_with_existing, drop_old\n       paradigm because transactions don't run DDL queries atomically on Snowflake. By using\n       `create or replace view`, the materialization becomes atomic in nature.\n    */\n#}\n\n{% macro create_or_replace_view(run_outside_transaction_hooks=True) %}\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set target_relation = api.Relation.create(\n      identifier=identifier, schema=schema, database=database,\n      type='view') -%}\n\n  {% if run_outside_transaction_hooks %}\n      -- no transactions on BigQuery\n      {{ run_hooks(pre_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  -- `BEGIN` happens here on Snowflake\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- If there's a table with the same name and we weren't told to full refresh,\n  -- that's an error. If we were told to full refresh, drop it. This behavior differs\n  -- for Snowflake and BigQuery, so multiple dispatch is used.\n  {%- if old_relation is not none and old_relation.is_table -%}\n    {{ handle_existing_table(flags.FULL_REFRESH, old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(target_relation, sql) }}\n  {%- endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if run_outside_transaction_hooks %}\n      -- No transactions on BigQuery\n      {{ run_hooks(post_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmacro %}", "unique_id": "macro.dbt.default__handle_existing_table", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/view/create_or_replace_view.sql", "original_file_path": "macros/materializations/view/create_or_replace_view.sql", "resource_type": "macro", "name": "default__handle_existing_table", "macro_sql": "{% macro default__handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.create_or_replace_view": {"raw_sql": "{% macro handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter_macro(\"dbt.handle_existing_table\", full_refresh, old_relation) }}\n{% endmacro %}\n\n{% macro default__handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}\n\n{# /*\n       Core materialization implementation. BigQuery and Snowflake are similar\n       because both can use `create or replace view` where the resulting view schema\n       is not necessarily the same as the existing view. On Redshift, this would\n       result in: ERROR:  cannot change number of columns in view\n\n       This implementation is superior to the create_temp, swap_with_existing, drop_old\n       paradigm because transactions don't run DDL queries atomically on Snowflake. By using\n       `create or replace view`, the materialization becomes atomic in nature.\n    */\n#}\n\n{% macro create_or_replace_view(run_outside_transaction_hooks=True) %}\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set target_relation = api.Relation.create(\n      identifier=identifier, schema=schema, database=database,\n      type='view') -%}\n\n  {% if run_outside_transaction_hooks %}\n      -- no transactions on BigQuery\n      {{ run_hooks(pre_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  -- `BEGIN` happens here on Snowflake\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- If there's a table with the same name and we weren't told to full refresh,\n  -- that's an error. If we were told to full refresh, drop it. This behavior differs\n  -- for Snowflake and BigQuery, so multiple dispatch is used.\n  {%- if old_relation is not none and old_relation.is_table -%}\n    {{ handle_existing_table(flags.FULL_REFRESH, old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(target_relation, sql) }}\n  {%- endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if run_outside_transaction_hooks %}\n      -- No transactions on BigQuery\n      {{ run_hooks(post_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmacro %}", "unique_id": "macro.dbt.create_or_replace_view", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/materializations/view/create_or_replace_view.sql", "original_file_path": "macros/materializations/view/create_or_replace_view.sql", "resource_type": "macro", "name": "create_or_replace_view", "macro_sql": "{% macro create_or_replace_view(run_outside_transaction_hooks=True) %}\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set target_relation = api.Relation.create(\n      identifier=identifier, schema=schema, database=database,\n      type='view') -%}\n\n  {% if run_outside_transaction_hooks %}\n      -- no transactions on BigQuery\n      {{ run_hooks(pre_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  -- `BEGIN` happens here on Snowflake\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- If there's a table with the same name and we weren't told to full refresh,\n  -- that's an error. If we were told to full refresh, drop it. This behavior differs\n  -- for Snowflake and BigQuery, so multiple dispatch is used.\n  {%- if old_relation is not none and old_relation.is_table -%}\n    {{ handle_existing_table(flags.FULL_REFRESH, old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(target_relation, sql) }}\n  {%- endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if run_outside_transaction_hooks %}\n      -- No transactions on BigQuery\n      {{ run_hooks(post_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.generate_alias_name": {"raw_sql": "{#\n    Renders a alias name given a custom alias name. If the custom\n    alias name is none, then the resulting alias is just the filename of the\n    model. If an alias override is specified, then that is used.\n\n    This macro can be overriden in projects to define different semantics\n    for rendering a alias name.\n\n    Arguments:\n    custom_alias_name: The custom alias name specified for a model, or none\n    node: The available node that an alias is being generated for, or none\n\n#}\n{% macro generate_alias_name(custom_alias_name=none, node=none) -%}\n\n    {%- if custom_alias_name is none -%}\n\n        {{ node.name }}\n\n    {%- else -%}\n\n        {{ custom_alias_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt.generate_alias_name", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/get_custom_alias.sql", "original_file_path": "macros/etc/get_custom_alias.sql", "resource_type": "macro", "name": "generate_alias_name", "macro_sql": "{% macro generate_alias_name(custom_alias_name=none, node=none) -%}\n\n    {%- if custom_alias_name is none -%}\n\n        {{ node.name }}\n\n    {%- else -%}\n\n        {{ custom_alias_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.run_query": {"raw_sql": "{% macro run_query(sql) %}\n  {% call statement(\"run_query_statement\", fetch_result=true, auto_begin=false) %}\n    {{ sql }}\n  {% endcall %}\n\n  {% do return(load_result(\"run_query_statement\").table) %}\n{% endmacro %}", "unique_id": "macro.dbt.run_query", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/query.sql", "original_file_path": "macros/etc/query.sql", "resource_type": "macro", "name": "run_query", "macro_sql": "{% macro run_query(sql) %}\n  {% call statement(\"run_query_statement\", fetch_result=true, auto_begin=false) %}\n    {{ sql }}\n  {% endcall %}\n\n  {% do return(load_result(\"run_query_statement\").table) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.is_incremental": {"raw_sql": "{% macro is_incremental() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n        {{ return(relation is not none\n                  and relation.type == 'table'\n                  and model.config.materialized == 'incremental'\n                  and not flags.FULL_REFRESH) }}\n    {% endif %}\n{% endmacro %}", "unique_id": "macro.dbt.is_incremental", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/is_incremental.sql", "original_file_path": "macros/etc/is_incremental.sql", "resource_type": "macro", "name": "is_incremental", "macro_sql": "{% macro is_incremental() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n        {{ return(relation is not none\n                  and relation.type == 'table'\n                  and model.config.materialized == 'incremental'\n                  and not flags.FULL_REFRESH) }}\n    {% endif %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.table_options": {"raw_sql": "{% macro table_options() %}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n\n{%- endmacro -%}\n\n{% macro get_relation_comment(persist_docs, model) %}\n\n  {%- if persist_docs is not mapping -%}\n    {{ exceptions.raise_compiler_error(\"Invalid value provided for 'persist_docs'. Expected dict but got value: \" ~ raw_persist_docs) }}\n  {% endif %}\n\n  {% if persist_docs.get('relation', false) %}\n    {{ return((model.description | tojson)[1:-1]) }}\n  {%- else -%}\n    {{ return(none) }}\n  {% endif %}\n\n{% endmacro %}", "unique_id": "macro.dbt.table_options", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/get_relation_comment.sql", "original_file_path": "macros/etc/get_relation_comment.sql", "resource_type": "macro", "name": "table_options", "macro_sql": "{% macro table_options() %}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_relation_comment": {"raw_sql": "{% macro table_options() %}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n\n{%- endmacro -%}\n\n{% macro get_relation_comment(persist_docs, model) %}\n\n  {%- if persist_docs is not mapping -%}\n    {{ exceptions.raise_compiler_error(\"Invalid value provided for 'persist_docs'. Expected dict but got value: \" ~ raw_persist_docs) }}\n  {% endif %}\n\n  {% if persist_docs.get('relation', false) %}\n    {{ return((model.description | tojson)[1:-1]) }}\n  {%- else -%}\n    {{ return(none) }}\n  {% endif %}\n\n{% endmacro %}", "unique_id": "macro.dbt.get_relation_comment", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/get_relation_comment.sql", "original_file_path": "macros/etc/get_relation_comment.sql", "resource_type": "macro", "name": "get_relation_comment", "macro_sql": "{% macro get_relation_comment(persist_docs, model) %}\n\n  {%- if persist_docs is not mapping -%}\n    {{ exceptions.raise_compiler_error(\"Invalid value provided for 'persist_docs'. Expected dict but got value: \" ~ raw_persist_docs) }}\n  {% endif %}\n\n  {% if persist_docs.get('relation', false) %}\n    {{ return((model.description | tojson)[1:-1]) }}\n  {%- else -%}\n    {{ return(none) }}\n  {% endif %}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.convert_datetime": {"raw_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}\n\n{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partiton start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}\n\n{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}\n\n{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "unique_id": "macro.dbt.convert_datetime", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "resource_type": "macro", "name": "convert_datetime", "macro_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.dates_in_range": {"raw_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}\n\n{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partiton start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}\n\n{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}\n\n{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "unique_id": "macro.dbt.dates_in_range", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "resource_type": "macro", "name": "dates_in_range", "macro_sql": "{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partiton start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.partition_range": {"raw_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}\n\n{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partiton start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}\n\n{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}\n\n{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "unique_id": "macro.dbt.partition_range", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "resource_type": "macro", "name": "partition_range", "macro_sql": "{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.py_current_timestring": {"raw_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}\n\n{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partiton start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}\n\n{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}\n\n{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "unique_id": "macro.dbt.py_current_timestring", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "resource_type": "macro", "name": "py_current_timestring", "macro_sql": "{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.generate_schema_name": {"raw_sql": "{#\n    Renders a schema name given a custom schema name. If the custom\n    schema name is none, then the resulting schema is just the \"schema\"\n    value in the specified target. If a schema override is specified, then\n    the resulting schema is the default schema concatenated with the\n    custom schema.\n\n    This macro can be overriden in projects to define different semantics\n    for rendering a schema name.\n\n    Arguments:\n    custom_schema_name: The custom schema name specified for a model, or none\n    node: The node the schema is being generated for\n\n#}\n{% macro generate_schema_name(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if custom_schema_name is none -%}\n\n        {{ default_schema }}\n\n    {%- else -%}\n\n        {{ default_schema }}_{{ custom_schema_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}\n\n\n{#\n    Renders a schema name given a custom schema name. In production, this macro\n    will render out the overriden schema name for a model. Otherwise, the default\n    schema specified in the active target is used.\n\n    Arguments:\n    custom_schema_name: The custom schema name specified for a model, or none\n    node: The node the schema is being generated for\n\n#}\n{% macro generate_schema_name_for_env(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if target.name == 'prod' and custom_schema_name is not none -%}\n\n        {{ custom_schema_name | trim }}\n\n    {%- else -%}\n\n        {{ default_schema }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt.generate_schema_name", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/get_custom_schema.sql", "original_file_path": "macros/etc/get_custom_schema.sql", "resource_type": "macro", "name": "generate_schema_name", "macro_sql": "{% macro generate_schema_name(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if custom_schema_name is none -%}\n\n        {{ default_schema }}\n\n    {%- else -%}\n\n        {{ default_schema }}_{{ custom_schema_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.generate_schema_name_for_env": {"raw_sql": "{#\n    Renders a schema name given a custom schema name. If the custom\n    schema name is none, then the resulting schema is just the \"schema\"\n    value in the specified target. If a schema override is specified, then\n    the resulting schema is the default schema concatenated with the\n    custom schema.\n\n    This macro can be overriden in projects to define different semantics\n    for rendering a schema name.\n\n    Arguments:\n    custom_schema_name: The custom schema name specified for a model, or none\n    node: The node the schema is being generated for\n\n#}\n{% macro generate_schema_name(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if custom_schema_name is none -%}\n\n        {{ default_schema }}\n\n    {%- else -%}\n\n        {{ default_schema }}_{{ custom_schema_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}\n\n\n{#\n    Renders a schema name given a custom schema name. In production, this macro\n    will render out the overriden schema name for a model. Otherwise, the default\n    schema specified in the active target is used.\n\n    Arguments:\n    custom_schema_name: The custom schema name specified for a model, or none\n    node: The node the schema is being generated for\n\n#}\n{% macro generate_schema_name_for_env(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if target.name == 'prod' and custom_schema_name is not none -%}\n\n        {{ custom_schema_name | trim }}\n\n    {%- else -%}\n\n        {{ default_schema }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt.generate_schema_name_for_env", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/get_custom_schema.sql", "original_file_path": "macros/etc/get_custom_schema.sql", "resource_type": "macro", "name": "generate_schema_name_for_env", "macro_sql": "{% macro generate_schema_name_for_env(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if target.name == 'prod' and custom_schema_name is not none -%}\n\n        {{ custom_schema_name | trim }}\n\n    {%- else -%}\n\n        {{ default_schema }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.generate_database_name": {"raw_sql": "{#\n    Renders a database name given a custom database name. If the custom\n    database name is none, then the resulting database is just the \"database\"\n    value in the specified target. If a database override is specified, then\n    the resulting database is the default database concatenated with the\n    custom database.\n\n    This macro can be overriden in projects to define different semantics\n    for rendering a database name.\n\n    Arguments:\n    custom_database_name: The custom database name specified for a model, or none\n    node: The node the database is being generated for\n\n#}\n{% macro generate_database_name(custom_database_name=none, node=none) -%}\n    {%- set default_database = target.database -%}\n    {%- if custom_database_name is none -%}\n\n        {{ default_database }}\n\n    {%- else -%}\n\n        {{ custom_database_name }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt.generate_database_name", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/etc/get_custom_database.sql", "original_file_path": "macros/etc/get_custom_database.sql", "resource_type": "macro", "name": "generate_database_name", "macro_sql": "{% macro generate_database_name(custom_database_name=none, node=none) -%}\n    {%- set default_database = target.database -%}\n    {%- if custom_database_name is none -%}\n\n        {{ default_database }}\n\n    {%- else -%}\n\n        {{ custom_database_name }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.adapter_macro": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.adapter_macro", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "adapter_macro", "macro_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_columns_in_query": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.get_columns_in_query", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "get_columns_in_query", "macro_sql": "{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_columns_in_query": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__get_columns_in_query", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__get_columns_in_query", "macro_sql": "{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.create_schema": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.create_schema", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "create_schema", "macro_sql": "{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_schema": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__create_schema", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__create_schema", "macro_sql": "{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.drop_schema": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.drop_schema", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "drop_schema", "macro_sql": "{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__drop_schema": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__drop_schema", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__drop_schema", "macro_sql": "{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.create_table_as": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.create_table_as", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "create_table_as", "macro_sql": "{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_table_as": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__create_table_as", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__create_table_as", "macro_sql": "{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.create_view_as": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.create_view_as", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "create_view_as", "macro_sql": "{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_view_as": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__create_view_as", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__create_view_as", "macro_sql": "{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_catalog": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.get_catalog", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "get_catalog", "macro_sql": "{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": ["macro.dbt.adapter_macro"]}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_catalog": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__get_catalog", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__get_catalog", "macro_sql": "{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.get_columns_in_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.get_columns_in_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "get_columns_in_relation", "macro_sql": "{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": ["macro.dbt.adapter_macro"]}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.sql_convert_columns_in_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.sql_convert_columns_in_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "sql_convert_columns_in_relation", "macro_sql": "{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_columns_in_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__get_columns_in_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__get_columns_in_relation", "macro_sql": "{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.alter_column_type": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.alter_column_type", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "alter_column_type", "macro_sql": "{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__alter_column_type": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__alter_column_type", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__alter_column_type", "macro_sql": "{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.drop_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.drop_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "drop_relation", "macro_sql": "{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__drop_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__drop_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__drop_relation", "macro_sql": "{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.truncate_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.truncate_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "truncate_relation", "macro_sql": "{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__truncate_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__truncate_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__truncate_relation", "macro_sql": "{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.rename_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.rename_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "rename_relation", "macro_sql": "{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__rename_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__rename_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__rename_relation", "macro_sql": "{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.information_schema_name": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.information_schema_name", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "information_schema_name", "macro_sql": "{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__information_schema_name": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__information_schema_name", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__information_schema_name", "macro_sql": "{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.list_schemas": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.list_schemas", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "list_schemas", "macro_sql": "{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__list_schemas": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__list_schemas", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__list_schemas", "macro_sql": "{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.check_schema_exists": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.check_schema_exists", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "check_schema_exists", "macro_sql": "{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__check_schema_exists": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__check_schema_exists", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__check_schema_exists", "macro_sql": "{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.list_relations_without_caching": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.list_relations_without_caching", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "list_relations_without_caching", "macro_sql": "{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": ["macro.dbt.adapter_macro"]}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__list_relations_without_caching": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__list_relations_without_caching", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__list_relations_without_caching", "macro_sql": "{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.current_timestamp": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.current_timestamp", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "current_timestamp", "macro_sql": "{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__current_timestamp": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__current_timestamp", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.collect_freshness": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.collect_freshness", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "collect_freshness", "macro_sql": "{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__collect_freshness": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__collect_freshness", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__collect_freshness", "macro_sql": "{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.make_temp_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.make_temp_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "make_temp_relation", "macro_sql": "{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.default__make_temp_relation": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.default__make_temp_relation", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "default__make_temp_relation", "macro_sql": "{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.set_sql_header": {"raw_sql": "{% macro adapter_macro(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        In adapter_macro: could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set separator = '__' -%}\n  {%- set search_name = adapter.type() + separator + name -%}\n  {%- set default_name = 'default' + separator + name -%}\n\n  {%- if package_context.get(search_name) is not none -%}\n    {{ return(package_context[search_name](*varargs, **kwargs)) }}\n  {%- else -%}\n    {{ return(package_context[default_name](*varargs, **kwargs)) }}\n  {%- endif -%}\n{%- endmacro %}\n\n{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter_macro('get_columns_in_query', select_sql)) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}\n\n{% macro create_schema(database_name, schema_name) -%}\n  {{ adapter_macro('create_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__create_schema(database_name, schema_name) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{database_name}}.{{schema_name}}\n  {% endcall %}\n{% endmacro %}\n\n{% macro drop_schema(database_name, schema_name) -%}\n  {{ adapter_macro('drop_schema', database_name, schema_name) }}\n{% endmacro %}\n\n{% macro default__drop_schema(database_name, schema_name) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{database_name}}.{{schema_name}} cascade\n  {% endcall %}\n{% endmacro %}\n\n{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter_macro('create_table_as', temporary, relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n{% macro create_view_as(relation, sql) -%}\n  {{ adapter_macro('create_view_as', relation, sql) }}\n{%- endmacro %}\n\n{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}\n\n\n{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter_macro('get_catalog', information_schema, schemas)) }}\n{%- endmacro %}\n\n{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}\n\n\n{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter_macro('get_columns_in_relation', relation)) }}\n{% endmacro %}\n\n{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}\n\n{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter_macro('alter_column_type', relation, column_name, new_column_type)) }}\n{% endmacro %}\n\n{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}\n\n\n{% macro drop_relation(relation) -%}\n  {{ return(adapter_macro('drop_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}\n\n{% macro truncate_relation(relation) -%}\n  {{ return(adapter_macro('truncate_relation', relation)) }}\n{% endmacro %}\n\n\n{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}\n\n{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter_macro('rename_relation', from_relation, to_relation)) }}\n{% endmacro %}\n\n{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}\n\n\n{% macro information_schema_name(database) %}\n  {{ return(adapter_macro('information_schema_name', database)) }}\n{% endmacro %}\n\n{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ adapter.quote_as_configured(database, 'database') }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}\n\n\n{% macro list_schemas(database) -%}\n  {{ return(adapter_macro('list_schemas', database)) }}\n{% endmacro %}\n\n{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter_macro('check_schema_exists', information_schema, schema)) }}\n{% endmacro %}\n\n{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}\n\n\n{% macro list_relations_without_caching(information_schema, schema) %}\n  {{ return(adapter_macro('list_relations_without_caching', information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro default__list_relations_without_caching(information_schema, schema) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}\n\n\n{% macro current_timestamp() -%}\n  {{ adapter_macro('current_timestamp') }}\n{%- endmacro %}\n\n\n{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}\n\n\n{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter_macro('collect_freshness', source, loaded_at_field, filter))}}\n{% endmacro %}\n\n\n{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}\n\n{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter_macro('make_temp_relation', base_relation, suffix))}}\n{% endmacro %}\n\n{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}\n\n{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "unique_id": "macro.dbt.set_sql_header", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/adapters/common.sql", "original_file_path": "macros/adapters/common.sql", "resource_type": "macro", "name": "set_sql_header", "macro_sql": "{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.test_relationships": {"raw_sql": "{% macro test_relationships(model, to, field) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n\n\nselect count(*)\nfrom (\n    select {{ column_name }} as id from {{ model }}\n) as child\nleft join (\n    select {{ field }} as id from {{ to }}\n) as parent on parent.id = child.id\nwhere child.id is not null\n  and parent.id is null\n\n{% endmacro %}", "unique_id": "macro.dbt.test_relationships", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/schema_tests/relationships.sql", "original_file_path": "macros/schema_tests/relationships.sql", "resource_type": "macro", "name": "test_relationships", "macro_sql": "{% macro test_relationships(model, to, field) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n\n\nselect count(*)\nfrom (\n    select {{ column_name }} as id from {{ model }}\n) as child\nleft join (\n    select {{ field }} as id from {{ to }}\n) as parent on parent.id = child.id\nwhere child.id is not null\n  and parent.id is null\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.test_not_null": {"raw_sql": "{% macro test_not_null(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\nfrom {{ model }}\nwhere {{ column_name }} is null\n\n{% endmacro %}", "unique_id": "macro.dbt.test_not_null", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/schema_tests/not_null.sql", "original_file_path": "macros/schema_tests/not_null.sql", "resource_type": "macro", "name": "test_not_null", "macro_sql": "{% macro test_not_null(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\nfrom {{ model }}\nwhere {{ column_name }} is null\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.test_unique": {"raw_sql": "{% macro test_unique(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\nfrom (\n\n    select\n        {{ column_name }}\n\n    from {{ model }}\n    where {{ column_name }} is not null\n    group by {{ column_name }}\n    having count(*) > 1\n\n) validation_errors\n\n{% endmacro %}", "unique_id": "macro.dbt.test_unique", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/schema_tests/unique.sql", "original_file_path": "macros/schema_tests/unique.sql", "resource_type": "macro", "name": "test_unique", "macro_sql": "{% macro test_unique(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\nfrom (\n\n    select\n        {{ column_name }}\n\n    from {{ model }}\n    where {{ column_name }} is not null\n    group by {{ column_name }}\n    having count(*) > 1\n\n) validation_errors\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt.test_accepted_values": {"raw_sql": "{% macro test_accepted_values(model, values) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('field')) %}\n{% set quote_values = kwargs.get('quote', True) %}\n\nwith all_values as (\n\n    select distinct\n        {{ column_name }} as value_field\n\n    from {{ model }}\n\n),\n\nvalidation_errors as (\n\n    select\n        value_field\n\n    from all_values\n    where value_field not in (\n        {% for value in values -%}\n            {% if quote_values -%}\n            '{{ value }}'\n            {%- else -%}\n            {{ value }}\n            {%- endif -%}\n            {%- if not loop.last -%},{%- endif %}\n        {%- endfor %}\n    )\n)\n\nselect count(*)\nfrom validation_errors\n\n{% endmacro %}", "unique_id": "macro.dbt.test_accepted_values", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "macros/schema_tests/accepted_values.sql", "original_file_path": "macros/schema_tests/accepted_values.sql", "resource_type": "macro", "name": "test_accepted_values", "macro_sql": "{% macro test_accepted_values(model, values) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('field')) %}\n{% set quote_values = kwargs.get('quote', True) %}\n\nwith all_values as (\n\n    select distinct\n        {{ column_name }} as value_field\n\n    from {{ model }}\n\n),\n\nvalidation_errors as (\n\n    select\n        value_field\n\n    from all_values\n    where value_field not in (\n        {% for value in values -%}\n            {% if quote_values -%}\n            '{{ value }}'\n            {%- else -%}\n            {{ value }}\n            {%- endif -%}\n            {%- if not loop.last -%},{%- endif %}\n        {%- endfor %}\n    )\n)\n\nselect count(*)\nfrom validation_errors\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__get_base_catalog": {"raw_sql": "{% macro redshift__get_base_catalog(information_schema, schemas) -%}\n  {%- call statement('base_catalog', fetch_result=True) -%}\n    {% set database = information_schema.database %}\n    {{ adapter.verify_database(database) }}\n\n    with late_binding as (\n      select\n        '{{ database }}'::varchar as table_database,\n        table_schema,\n        table_name,\n        'LATE BINDING VIEW'::varchar as table_type,\n        null::text as table_comment,\n\n        column_name,\n        column_index,\n        column_type,\n        null::text as column_comment\n      from pg_get_late_binding_view_cols()\n        cols(table_schema name, table_name name, column_name name,\n             column_type varchar,\n             column_index int)\n        order by \"column_index\"\n    ),\n\n    table_owners as (\n\n        select\n            '{{ database }}'::varchar as table_database,\n            schemaname as table_schema,\n            tablename as table_name,\n            tableowner as table_owner\n\n        from pg_tables\n\n        union all\n\n        select\n            '{{ database }}'::varchar as table_database,\n            schemaname as table_schema,\n            viewname as table_name,\n            viewowner as table_owner\n\n        from pg_views\n\n    ),\n\n    tables as (\n\n      select\n        table_catalog as table_database,\n        table_schema,\n        table_name,\n        table_type\n\n      from information_schema.tables\n\n    ),\n\n    table_columns as (\n\n        select\n            '{{ database }}'::varchar as table_database,\n            table_schema,\n            table_name,\n            null::varchar as table_comment,\n\n            column_name,\n            ordinal_position as column_index,\n            data_type as column_type,\n            null::varchar as column_comment\n\n\n        from information_schema.\"columns\"\n\n    ),\n\n    unioned as (\n\n        select *\n        from tables\n        join table_columns using (table_database, table_schema, table_name)\n\n        union all\n\n        select *\n        from late_binding\n\n    )\n\n    select *,\n        table_database || '.' || table_schema || '.' || table_name as table_id\n\n    from unioned\n    join table_owners using (table_database, table_schema, table_name)\n\n    where (\n        {%- for schema in schemas -%}\n          upper(table_schema) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n      )\n\n    order by \"column_index\"\n  {%- endcall -%}\n\n  {{ return(load_result('base_catalog').table) }}\n{%- endmacro %}\n\n{% macro redshift__get_extended_catalog(schemas) %}\n  {%- call statement('extended_catalog', fetch_result=True) -%}\n\n    select\n        \"database\" || '.' || \"schema\" || '.' || \"table\" as table_id,\n\n        'Encoded'::text as \"stats:encoded:label\",\n        encoded as \"stats:encoded:value\",\n        'Indicates whether any column in the table has compression encoding defined.'::text as \"stats:encoded:description\",\n        true as \"stats:encoded:include\",\n\n        'Dist Style' as \"stats:diststyle:label\",\n        diststyle as \"stats:diststyle:value\",\n        'Distribution style or distribution key column, if key distribution is defined.'::text as \"stats:diststyle:description\",\n        true as \"stats:diststyle:include\",\n\n        'Sort Key 1' as \"stats:sortkey1:label\",\n        -- handle 0xFF byte in response for interleaved sort styles\n        case\n            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text\n            else sortkey1\n        end as \"stats:sortkey1:value\",\n        'First column in the sort key.'::text as \"stats:sortkey1:description\",\n        (sortkey1 is not null) as \"stats:sortkey1:include\",\n\n        'Max Varchar' as \"stats:max_varchar:label\",\n        max_varchar as \"stats:max_varchar:value\",\n        'Size of the largest column that uses a VARCHAR data type.'::text as \"stats:max_varchar:description\",\n        true as \"stats:max_varchar:include\",\n\n        -- exclude this, as the data is strangely returned with null-byte characters\n        'Sort Key 1 Encoding' as \"stats:sortkey1_enc:label\",\n        sortkey1_enc as \"stats:sortkey1_enc:value\",\n        'Compression encoding of the first column in the sort key.' as \"stats:sortkey1_enc:description\",\n        false as \"stats:sortkey1_enc:include\",\n\n        '# Sort Keys' as \"stats:sortkey_num:label\",\n        sortkey_num as \"stats:sortkey_num:value\",\n        'Number of columns defined as sort keys.' as \"stats:sortkey_num:description\",\n        (sortkey_num > 0) as \"stats:sortkey_num:include\",\n\n        'Approximate Size' as \"stats:size:label\",\n        size / 1000000.0 as \"stats:size:value\",\n        'Approximate size of the table, calculated from a count of 1MB blocks'::text as \"stats:size:description\",\n        true as \"stats:size:include\",\n\n        'Disk Utilization' as \"stats:pct_used:label\",\n        pct_used / 100.0 as \"stats:pct_used:value\",\n        'Percent of available space that is used by the table.'::text as \"stats:pct_used:description\",\n        true as \"stats:pct_used:include\",\n\n        'Unsorted %' as \"stats:unsorted:label\",\n        unsorted / 100.0 as \"stats:unsorted:value\",\n        'Percent of unsorted rows in the table.'::text as \"stats:unsorted:description\",\n        (unsorted is not null) as \"stats:unsorted:include\",\n\n        'Stats Off' as \"stats:stats_off:label\",\n        stats_off as \"stats:stats_off:value\",\n        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as \"stats:stats_off:description\",\n        true as \"stats:stats_off:include\",\n\n        'Approximate Row Count' as \"stats:rows:label\",\n        tbl_rows as \"stats:rows:value\",\n        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as \"stats:rows:description\",\n        true as \"stats:rows:include\",\n\n        'Sort Key Skew' as \"stats:skew_sortkey1:label\",\n        skew_sortkey1 as \"stats:skew_sortkey1:value\",\n        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as \"stats:skew_sortkey1:description\",\n        (skew_sortkey1 is not null) as \"stats:skew_sortkey1:include\",\n\n        'Skew Rows' as \"stats:skew_rows:label\",\n        skew_rows as \"stats:skew_rows:value\",\n        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as \"stats:skew_rows:description\",\n        (skew_rows is not null) as \"stats:skew_rows:include\"\n\n    from svv_table_info\n    where (\n        {%- for schema in schemas -%}\n          upper(schema) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n    )\n\n  {%- endcall -%}\n\n  {{ return(load_result('extended_catalog').table) }}\n\n{% endmacro %}\n\n{% macro redshift__can_select_from(table_name) %}\n\n  {%- call statement('has_table_privilege', fetch_result=True) -%}\n\n    select has_table_privilege(current_user, '{{ table_name }}', 'SELECT') as can_select\n\n  {%- endcall -%}\n\n  {% set can_select = load_result('has_table_privilege').table[0]['can_select'] %}\n  {{ return(can_select) }}\n\n{% endmacro %}\n\n{% macro redshift__no_svv_table_info_warning() %}\n\n    {% set msg %}\n\n    Warning: The database user \"{{ target.user }}\" has insufficient permissions to\n    query the \"svv_table_info\" table. Please grant SELECT permissions on this table\n    to the \"{{ target.user }}\" user to fetch extended table details from Redshift.\n\n    {% endset %}\n\n    {{ log(msg, info=True) }}\n\n{% endmacro %}\n\n\n{% macro redshift__get_catalog(information_schema, schemas) %}\n\n    {#-- Compute a left-outer join in memory. Some Redshift queries are\n      -- leader-only, and cannot be joined to other compute-based queries #}\n\n    {% set catalog = redshift__get_base_catalog(information_schema, schemas) %}\n\n    {% set select_extended =  redshift__can_select_from('svv_table_info') %}\n    {% if select_extended %}\n        {% set extended_catalog = redshift__get_extended_catalog(schemas) %}\n        {% set catalog = catalog.join(extended_catalog, 'table_id') %}\n    {% else %}\n        {{ redshift__no_svv_table_info_warning() }}\n    {% endif %}\n\n    {{ return(catalog.exclude(['table_id'])) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__get_base_catalog", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/catalog.sql", "original_file_path": "macros/catalog.sql", "resource_type": "macro", "name": "redshift__get_base_catalog", "macro_sql": "{% macro redshift__get_base_catalog(information_schema, schemas) -%}\n  {%- call statement('base_catalog', fetch_result=True) -%}\n    {% set database = information_schema.database %}\n    {{ adapter.verify_database(database) }}\n\n    with late_binding as (\n      select\n        '{{ database }}'::varchar as table_database,\n        table_schema,\n        table_name,\n        'LATE BINDING VIEW'::varchar as table_type,\n        null::text as table_comment,\n\n        column_name,\n        column_index,\n        column_type,\n        null::text as column_comment\n      from pg_get_late_binding_view_cols()\n        cols(table_schema name, table_name name, column_name name,\n             column_type varchar,\n             column_index int)\n        order by \"column_index\"\n    ),\n\n    table_owners as (\n\n        select\n            '{{ database }}'::varchar as table_database,\n            schemaname as table_schema,\n            tablename as table_name,\n            tableowner as table_owner\n\n        from pg_tables\n\n        union all\n\n        select\n            '{{ database }}'::varchar as table_database,\n            schemaname as table_schema,\n            viewname as table_name,\n            viewowner as table_owner\n\n        from pg_views\n\n    ),\n\n    tables as (\n\n      select\n        table_catalog as table_database,\n        table_schema,\n        table_name,\n        table_type\n\n      from information_schema.tables\n\n    ),\n\n    table_columns as (\n\n        select\n            '{{ database }}'::varchar as table_database,\n            table_schema,\n            table_name,\n            null::varchar as table_comment,\n\n            column_name,\n            ordinal_position as column_index,\n            data_type as column_type,\n            null::varchar as column_comment\n\n\n        from information_schema.\"columns\"\n\n    ),\n\n    unioned as (\n\n        select *\n        from tables\n        join table_columns using (table_database, table_schema, table_name)\n\n        union all\n\n        select *\n        from late_binding\n\n    )\n\n    select *,\n        table_database || '.' || table_schema || '.' || table_name as table_id\n\n    from unioned\n    join table_owners using (table_database, table_schema, table_name)\n\n    where (\n        {%- for schema in schemas -%}\n          upper(table_schema) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n      )\n\n    order by \"column_index\"\n  {%- endcall -%}\n\n  {{ return(load_result('base_catalog').table) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__get_extended_catalog": {"raw_sql": "{% macro redshift__get_base_catalog(information_schema, schemas) -%}\n  {%- call statement('base_catalog', fetch_result=True) -%}\n    {% set database = information_schema.database %}\n    {{ adapter.verify_database(database) }}\n\n    with late_binding as (\n      select\n        '{{ database }}'::varchar as table_database,\n        table_schema,\n        table_name,\n        'LATE BINDING VIEW'::varchar as table_type,\n        null::text as table_comment,\n\n        column_name,\n        column_index,\n        column_type,\n        null::text as column_comment\n      from pg_get_late_binding_view_cols()\n        cols(table_schema name, table_name name, column_name name,\n             column_type varchar,\n             column_index int)\n        order by \"column_index\"\n    ),\n\n    table_owners as (\n\n        select\n            '{{ database }}'::varchar as table_database,\n            schemaname as table_schema,\n            tablename as table_name,\n            tableowner as table_owner\n\n        from pg_tables\n\n        union all\n\n        select\n            '{{ database }}'::varchar as table_database,\n            schemaname as table_schema,\n            viewname as table_name,\n            viewowner as table_owner\n\n        from pg_views\n\n    ),\n\n    tables as (\n\n      select\n        table_catalog as table_database,\n        table_schema,\n        table_name,\n        table_type\n\n      from information_schema.tables\n\n    ),\n\n    table_columns as (\n\n        select\n            '{{ database }}'::varchar as table_database,\n            table_schema,\n            table_name,\n            null::varchar as table_comment,\n\n            column_name,\n            ordinal_position as column_index,\n            data_type as column_type,\n            null::varchar as column_comment\n\n\n        from information_schema.\"columns\"\n\n    ),\n\n    unioned as (\n\n        select *\n        from tables\n        join table_columns using (table_database, table_schema, table_name)\n\n        union all\n\n        select *\n        from late_binding\n\n    )\n\n    select *,\n        table_database || '.' || table_schema || '.' || table_name as table_id\n\n    from unioned\n    join table_owners using (table_database, table_schema, table_name)\n\n    where (\n        {%- for schema in schemas -%}\n          upper(table_schema) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n      )\n\n    order by \"column_index\"\n  {%- endcall -%}\n\n  {{ return(load_result('base_catalog').table) }}\n{%- endmacro %}\n\n{% macro redshift__get_extended_catalog(schemas) %}\n  {%- call statement('extended_catalog', fetch_result=True) -%}\n\n    select\n        \"database\" || '.' || \"schema\" || '.' || \"table\" as table_id,\n\n        'Encoded'::text as \"stats:encoded:label\",\n        encoded as \"stats:encoded:value\",\n        'Indicates whether any column in the table has compression encoding defined.'::text as \"stats:encoded:description\",\n        true as \"stats:encoded:include\",\n\n        'Dist Style' as \"stats:diststyle:label\",\n        diststyle as \"stats:diststyle:value\",\n        'Distribution style or distribution key column, if key distribution is defined.'::text as \"stats:diststyle:description\",\n        true as \"stats:diststyle:include\",\n\n        'Sort Key 1' as \"stats:sortkey1:label\",\n        -- handle 0xFF byte in response for interleaved sort styles\n        case\n            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text\n            else sortkey1\n        end as \"stats:sortkey1:value\",\n        'First column in the sort key.'::text as \"stats:sortkey1:description\",\n        (sortkey1 is not null) as \"stats:sortkey1:include\",\n\n        'Max Varchar' as \"stats:max_varchar:label\",\n        max_varchar as \"stats:max_varchar:value\",\n        'Size of the largest column that uses a VARCHAR data type.'::text as \"stats:max_varchar:description\",\n        true as \"stats:max_varchar:include\",\n\n        -- exclude this, as the data is strangely returned with null-byte characters\n        'Sort Key 1 Encoding' as \"stats:sortkey1_enc:label\",\n        sortkey1_enc as \"stats:sortkey1_enc:value\",\n        'Compression encoding of the first column in the sort key.' as \"stats:sortkey1_enc:description\",\n        false as \"stats:sortkey1_enc:include\",\n\n        '# Sort Keys' as \"stats:sortkey_num:label\",\n        sortkey_num as \"stats:sortkey_num:value\",\n        'Number of columns defined as sort keys.' as \"stats:sortkey_num:description\",\n        (sortkey_num > 0) as \"stats:sortkey_num:include\",\n\n        'Approximate Size' as \"stats:size:label\",\n        size / 1000000.0 as \"stats:size:value\",\n        'Approximate size of the table, calculated from a count of 1MB blocks'::text as \"stats:size:description\",\n        true as \"stats:size:include\",\n\n        'Disk Utilization' as \"stats:pct_used:label\",\n        pct_used / 100.0 as \"stats:pct_used:value\",\n        'Percent of available space that is used by the table.'::text as \"stats:pct_used:description\",\n        true as \"stats:pct_used:include\",\n\n        'Unsorted %' as \"stats:unsorted:label\",\n        unsorted / 100.0 as \"stats:unsorted:value\",\n        'Percent of unsorted rows in the table.'::text as \"stats:unsorted:description\",\n        (unsorted is not null) as \"stats:unsorted:include\",\n\n        'Stats Off' as \"stats:stats_off:label\",\n        stats_off as \"stats:stats_off:value\",\n        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as \"stats:stats_off:description\",\n        true as \"stats:stats_off:include\",\n\n        'Approximate Row Count' as \"stats:rows:label\",\n        tbl_rows as \"stats:rows:value\",\n        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as \"stats:rows:description\",\n        true as \"stats:rows:include\",\n\n        'Sort Key Skew' as \"stats:skew_sortkey1:label\",\n        skew_sortkey1 as \"stats:skew_sortkey1:value\",\n        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as \"stats:skew_sortkey1:description\",\n        (skew_sortkey1 is not null) as \"stats:skew_sortkey1:include\",\n\n        'Skew Rows' as \"stats:skew_rows:label\",\n        skew_rows as \"stats:skew_rows:value\",\n        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as \"stats:skew_rows:description\",\n        (skew_rows is not null) as \"stats:skew_rows:include\"\n\n    from svv_table_info\n    where (\n        {%- for schema in schemas -%}\n          upper(schema) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n    )\n\n  {%- endcall -%}\n\n  {{ return(load_result('extended_catalog').table) }}\n\n{% endmacro %}\n\n{% macro redshift__can_select_from(table_name) %}\n\n  {%- call statement('has_table_privilege', fetch_result=True) -%}\n\n    select has_table_privilege(current_user, '{{ table_name }}', 'SELECT') as can_select\n\n  {%- endcall -%}\n\n  {% set can_select = load_result('has_table_privilege').table[0]['can_select'] %}\n  {{ return(can_select) }}\n\n{% endmacro %}\n\n{% macro redshift__no_svv_table_info_warning() %}\n\n    {% set msg %}\n\n    Warning: The database user \"{{ target.user }}\" has insufficient permissions to\n    query the \"svv_table_info\" table. Please grant SELECT permissions on this table\n    to the \"{{ target.user }}\" user to fetch extended table details from Redshift.\n\n    {% endset %}\n\n    {{ log(msg, info=True) }}\n\n{% endmacro %}\n\n\n{% macro redshift__get_catalog(information_schema, schemas) %}\n\n    {#-- Compute a left-outer join in memory. Some Redshift queries are\n      -- leader-only, and cannot be joined to other compute-based queries #}\n\n    {% set catalog = redshift__get_base_catalog(information_schema, schemas) %}\n\n    {% set select_extended =  redshift__can_select_from('svv_table_info') %}\n    {% if select_extended %}\n        {% set extended_catalog = redshift__get_extended_catalog(schemas) %}\n        {% set catalog = catalog.join(extended_catalog, 'table_id') %}\n    {% else %}\n        {{ redshift__no_svv_table_info_warning() }}\n    {% endif %}\n\n    {{ return(catalog.exclude(['table_id'])) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__get_extended_catalog", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/catalog.sql", "original_file_path": "macros/catalog.sql", "resource_type": "macro", "name": "redshift__get_extended_catalog", "macro_sql": "{% macro redshift__get_extended_catalog(schemas) %}\n  {%- call statement('extended_catalog', fetch_result=True) -%}\n\n    select\n        \"database\" || '.' || \"schema\" || '.' || \"table\" as table_id,\n\n        'Encoded'::text as \"stats:encoded:label\",\n        encoded as \"stats:encoded:value\",\n        'Indicates whether any column in the table has compression encoding defined.'::text as \"stats:encoded:description\",\n        true as \"stats:encoded:include\",\n\n        'Dist Style' as \"stats:diststyle:label\",\n        diststyle as \"stats:diststyle:value\",\n        'Distribution style or distribution key column, if key distribution is defined.'::text as \"stats:diststyle:description\",\n        true as \"stats:diststyle:include\",\n\n        'Sort Key 1' as \"stats:sortkey1:label\",\n        -- handle 0xFF byte in response for interleaved sort styles\n        case\n            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text\n            else sortkey1\n        end as \"stats:sortkey1:value\",\n        'First column in the sort key.'::text as \"stats:sortkey1:description\",\n        (sortkey1 is not null) as \"stats:sortkey1:include\",\n\n        'Max Varchar' as \"stats:max_varchar:label\",\n        max_varchar as \"stats:max_varchar:value\",\n        'Size of the largest column that uses a VARCHAR data type.'::text as \"stats:max_varchar:description\",\n        true as \"stats:max_varchar:include\",\n\n        -- exclude this, as the data is strangely returned with null-byte characters\n        'Sort Key 1 Encoding' as \"stats:sortkey1_enc:label\",\n        sortkey1_enc as \"stats:sortkey1_enc:value\",\n        'Compression encoding of the first column in the sort key.' as \"stats:sortkey1_enc:description\",\n        false as \"stats:sortkey1_enc:include\",\n\n        '# Sort Keys' as \"stats:sortkey_num:label\",\n        sortkey_num as \"stats:sortkey_num:value\",\n        'Number of columns defined as sort keys.' as \"stats:sortkey_num:description\",\n        (sortkey_num > 0) as \"stats:sortkey_num:include\",\n\n        'Approximate Size' as \"stats:size:label\",\n        size / 1000000.0 as \"stats:size:value\",\n        'Approximate size of the table, calculated from a count of 1MB blocks'::text as \"stats:size:description\",\n        true as \"stats:size:include\",\n\n        'Disk Utilization' as \"stats:pct_used:label\",\n        pct_used / 100.0 as \"stats:pct_used:value\",\n        'Percent of available space that is used by the table.'::text as \"stats:pct_used:description\",\n        true as \"stats:pct_used:include\",\n\n        'Unsorted %' as \"stats:unsorted:label\",\n        unsorted / 100.0 as \"stats:unsorted:value\",\n        'Percent of unsorted rows in the table.'::text as \"stats:unsorted:description\",\n        (unsorted is not null) as \"stats:unsorted:include\",\n\n        'Stats Off' as \"stats:stats_off:label\",\n        stats_off as \"stats:stats_off:value\",\n        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as \"stats:stats_off:description\",\n        true as \"stats:stats_off:include\",\n\n        'Approximate Row Count' as \"stats:rows:label\",\n        tbl_rows as \"stats:rows:value\",\n        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as \"stats:rows:description\",\n        true as \"stats:rows:include\",\n\n        'Sort Key Skew' as \"stats:skew_sortkey1:label\",\n        skew_sortkey1 as \"stats:skew_sortkey1:value\",\n        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as \"stats:skew_sortkey1:description\",\n        (skew_sortkey1 is not null) as \"stats:skew_sortkey1:include\",\n\n        'Skew Rows' as \"stats:skew_rows:label\",\n        skew_rows as \"stats:skew_rows:value\",\n        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as \"stats:skew_rows:description\",\n        (skew_rows is not null) as \"stats:skew_rows:include\"\n\n    from svv_table_info\n    where (\n        {%- for schema in schemas -%}\n          upper(schema) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n    )\n\n  {%- endcall -%}\n\n  {{ return(load_result('extended_catalog').table) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__can_select_from": {"raw_sql": "{% macro redshift__get_base_catalog(information_schema, schemas) -%}\n  {%- call statement('base_catalog', fetch_result=True) -%}\n    {% set database = information_schema.database %}\n    {{ adapter.verify_database(database) }}\n\n    with late_binding as (\n      select\n        '{{ database }}'::varchar as table_database,\n        table_schema,\n        table_name,\n        'LATE BINDING VIEW'::varchar as table_type,\n        null::text as table_comment,\n\n        column_name,\n        column_index,\n        column_type,\n        null::text as column_comment\n      from pg_get_late_binding_view_cols()\n        cols(table_schema name, table_name name, column_name name,\n             column_type varchar,\n             column_index int)\n        order by \"column_index\"\n    ),\n\n    table_owners as (\n\n        select\n            '{{ database }}'::varchar as table_database,\n            schemaname as table_schema,\n            tablename as table_name,\n            tableowner as table_owner\n\n        from pg_tables\n\n        union all\n\n        select\n            '{{ database }}'::varchar as table_database,\n            schemaname as table_schema,\n            viewname as table_name,\n            viewowner as table_owner\n\n        from pg_views\n\n    ),\n\n    tables as (\n\n      select\n        table_catalog as table_database,\n        table_schema,\n        table_name,\n        table_type\n\n      from information_schema.tables\n\n    ),\n\n    table_columns as (\n\n        select\n            '{{ database }}'::varchar as table_database,\n            table_schema,\n            table_name,\n            null::varchar as table_comment,\n\n            column_name,\n            ordinal_position as column_index,\n            data_type as column_type,\n            null::varchar as column_comment\n\n\n        from information_schema.\"columns\"\n\n    ),\n\n    unioned as (\n\n        select *\n        from tables\n        join table_columns using (table_database, table_schema, table_name)\n\n        union all\n\n        select *\n        from late_binding\n\n    )\n\n    select *,\n        table_database || '.' || table_schema || '.' || table_name as table_id\n\n    from unioned\n    join table_owners using (table_database, table_schema, table_name)\n\n    where (\n        {%- for schema in schemas -%}\n          upper(table_schema) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n      )\n\n    order by \"column_index\"\n  {%- endcall -%}\n\n  {{ return(load_result('base_catalog').table) }}\n{%- endmacro %}\n\n{% macro redshift__get_extended_catalog(schemas) %}\n  {%- call statement('extended_catalog', fetch_result=True) -%}\n\n    select\n        \"database\" || '.' || \"schema\" || '.' || \"table\" as table_id,\n\n        'Encoded'::text as \"stats:encoded:label\",\n        encoded as \"stats:encoded:value\",\n        'Indicates whether any column in the table has compression encoding defined.'::text as \"stats:encoded:description\",\n        true as \"stats:encoded:include\",\n\n        'Dist Style' as \"stats:diststyle:label\",\n        diststyle as \"stats:diststyle:value\",\n        'Distribution style or distribution key column, if key distribution is defined.'::text as \"stats:diststyle:description\",\n        true as \"stats:diststyle:include\",\n\n        'Sort Key 1' as \"stats:sortkey1:label\",\n        -- handle 0xFF byte in response for interleaved sort styles\n        case\n            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text\n            else sortkey1\n        end as \"stats:sortkey1:value\",\n        'First column in the sort key.'::text as \"stats:sortkey1:description\",\n        (sortkey1 is not null) as \"stats:sortkey1:include\",\n\n        'Max Varchar' as \"stats:max_varchar:label\",\n        max_varchar as \"stats:max_varchar:value\",\n        'Size of the largest column that uses a VARCHAR data type.'::text as \"stats:max_varchar:description\",\n        true as \"stats:max_varchar:include\",\n\n        -- exclude this, as the data is strangely returned with null-byte characters\n        'Sort Key 1 Encoding' as \"stats:sortkey1_enc:label\",\n        sortkey1_enc as \"stats:sortkey1_enc:value\",\n        'Compression encoding of the first column in the sort key.' as \"stats:sortkey1_enc:description\",\n        false as \"stats:sortkey1_enc:include\",\n\n        '# Sort Keys' as \"stats:sortkey_num:label\",\n        sortkey_num as \"stats:sortkey_num:value\",\n        'Number of columns defined as sort keys.' as \"stats:sortkey_num:description\",\n        (sortkey_num > 0) as \"stats:sortkey_num:include\",\n\n        'Approximate Size' as \"stats:size:label\",\n        size / 1000000.0 as \"stats:size:value\",\n        'Approximate size of the table, calculated from a count of 1MB blocks'::text as \"stats:size:description\",\n        true as \"stats:size:include\",\n\n        'Disk Utilization' as \"stats:pct_used:label\",\n        pct_used / 100.0 as \"stats:pct_used:value\",\n        'Percent of available space that is used by the table.'::text as \"stats:pct_used:description\",\n        true as \"stats:pct_used:include\",\n\n        'Unsorted %' as \"stats:unsorted:label\",\n        unsorted / 100.0 as \"stats:unsorted:value\",\n        'Percent of unsorted rows in the table.'::text as \"stats:unsorted:description\",\n        (unsorted is not null) as \"stats:unsorted:include\",\n\n        'Stats Off' as \"stats:stats_off:label\",\n        stats_off as \"stats:stats_off:value\",\n        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as \"stats:stats_off:description\",\n        true as \"stats:stats_off:include\",\n\n        'Approximate Row Count' as \"stats:rows:label\",\n        tbl_rows as \"stats:rows:value\",\n        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as \"stats:rows:description\",\n        true as \"stats:rows:include\",\n\n        'Sort Key Skew' as \"stats:skew_sortkey1:label\",\n        skew_sortkey1 as \"stats:skew_sortkey1:value\",\n        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as \"stats:skew_sortkey1:description\",\n        (skew_sortkey1 is not null) as \"stats:skew_sortkey1:include\",\n\n        'Skew Rows' as \"stats:skew_rows:label\",\n        skew_rows as \"stats:skew_rows:value\",\n        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as \"stats:skew_rows:description\",\n        (skew_rows is not null) as \"stats:skew_rows:include\"\n\n    from svv_table_info\n    where (\n        {%- for schema in schemas -%}\n          upper(schema) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n    )\n\n  {%- endcall -%}\n\n  {{ return(load_result('extended_catalog').table) }}\n\n{% endmacro %}\n\n{% macro redshift__can_select_from(table_name) %}\n\n  {%- call statement('has_table_privilege', fetch_result=True) -%}\n\n    select has_table_privilege(current_user, '{{ table_name }}', 'SELECT') as can_select\n\n  {%- endcall -%}\n\n  {% set can_select = load_result('has_table_privilege').table[0]['can_select'] %}\n  {{ return(can_select) }}\n\n{% endmacro %}\n\n{% macro redshift__no_svv_table_info_warning() %}\n\n    {% set msg %}\n\n    Warning: The database user \"{{ target.user }}\" has insufficient permissions to\n    query the \"svv_table_info\" table. Please grant SELECT permissions on this table\n    to the \"{{ target.user }}\" user to fetch extended table details from Redshift.\n\n    {% endset %}\n\n    {{ log(msg, info=True) }}\n\n{% endmacro %}\n\n\n{% macro redshift__get_catalog(information_schema, schemas) %}\n\n    {#-- Compute a left-outer join in memory. Some Redshift queries are\n      -- leader-only, and cannot be joined to other compute-based queries #}\n\n    {% set catalog = redshift__get_base_catalog(information_schema, schemas) %}\n\n    {% set select_extended =  redshift__can_select_from('svv_table_info') %}\n    {% if select_extended %}\n        {% set extended_catalog = redshift__get_extended_catalog(schemas) %}\n        {% set catalog = catalog.join(extended_catalog, 'table_id') %}\n    {% else %}\n        {{ redshift__no_svv_table_info_warning() }}\n    {% endif %}\n\n    {{ return(catalog.exclude(['table_id'])) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__can_select_from", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/catalog.sql", "original_file_path": "macros/catalog.sql", "resource_type": "macro", "name": "redshift__can_select_from", "macro_sql": "{% macro redshift__can_select_from(table_name) %}\n\n  {%- call statement('has_table_privilege', fetch_result=True) -%}\n\n    select has_table_privilege(current_user, '{{ table_name }}', 'SELECT') as can_select\n\n  {%- endcall -%}\n\n  {% set can_select = load_result('has_table_privilege').table[0]['can_select'] %}\n  {{ return(can_select) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__no_svv_table_info_warning": {"raw_sql": "{% macro redshift__get_base_catalog(information_schema, schemas) -%}\n  {%- call statement('base_catalog', fetch_result=True) -%}\n    {% set database = information_schema.database %}\n    {{ adapter.verify_database(database) }}\n\n    with late_binding as (\n      select\n        '{{ database }}'::varchar as table_database,\n        table_schema,\n        table_name,\n        'LATE BINDING VIEW'::varchar as table_type,\n        null::text as table_comment,\n\n        column_name,\n        column_index,\n        column_type,\n        null::text as column_comment\n      from pg_get_late_binding_view_cols()\n        cols(table_schema name, table_name name, column_name name,\n             column_type varchar,\n             column_index int)\n        order by \"column_index\"\n    ),\n\n    table_owners as (\n\n        select\n            '{{ database }}'::varchar as table_database,\n            schemaname as table_schema,\n            tablename as table_name,\n            tableowner as table_owner\n\n        from pg_tables\n\n        union all\n\n        select\n            '{{ database }}'::varchar as table_database,\n            schemaname as table_schema,\n            viewname as table_name,\n            viewowner as table_owner\n\n        from pg_views\n\n    ),\n\n    tables as (\n\n      select\n        table_catalog as table_database,\n        table_schema,\n        table_name,\n        table_type\n\n      from information_schema.tables\n\n    ),\n\n    table_columns as (\n\n        select\n            '{{ database }}'::varchar as table_database,\n            table_schema,\n            table_name,\n            null::varchar as table_comment,\n\n            column_name,\n            ordinal_position as column_index,\n            data_type as column_type,\n            null::varchar as column_comment\n\n\n        from information_schema.\"columns\"\n\n    ),\n\n    unioned as (\n\n        select *\n        from tables\n        join table_columns using (table_database, table_schema, table_name)\n\n        union all\n\n        select *\n        from late_binding\n\n    )\n\n    select *,\n        table_database || '.' || table_schema || '.' || table_name as table_id\n\n    from unioned\n    join table_owners using (table_database, table_schema, table_name)\n\n    where (\n        {%- for schema in schemas -%}\n          upper(table_schema) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n      )\n\n    order by \"column_index\"\n  {%- endcall -%}\n\n  {{ return(load_result('base_catalog').table) }}\n{%- endmacro %}\n\n{% macro redshift__get_extended_catalog(schemas) %}\n  {%- call statement('extended_catalog', fetch_result=True) -%}\n\n    select\n        \"database\" || '.' || \"schema\" || '.' || \"table\" as table_id,\n\n        'Encoded'::text as \"stats:encoded:label\",\n        encoded as \"stats:encoded:value\",\n        'Indicates whether any column in the table has compression encoding defined.'::text as \"stats:encoded:description\",\n        true as \"stats:encoded:include\",\n\n        'Dist Style' as \"stats:diststyle:label\",\n        diststyle as \"stats:diststyle:value\",\n        'Distribution style or distribution key column, if key distribution is defined.'::text as \"stats:diststyle:description\",\n        true as \"stats:diststyle:include\",\n\n        'Sort Key 1' as \"stats:sortkey1:label\",\n        -- handle 0xFF byte in response for interleaved sort styles\n        case\n            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text\n            else sortkey1\n        end as \"stats:sortkey1:value\",\n        'First column in the sort key.'::text as \"stats:sortkey1:description\",\n        (sortkey1 is not null) as \"stats:sortkey1:include\",\n\n        'Max Varchar' as \"stats:max_varchar:label\",\n        max_varchar as \"stats:max_varchar:value\",\n        'Size of the largest column that uses a VARCHAR data type.'::text as \"stats:max_varchar:description\",\n        true as \"stats:max_varchar:include\",\n\n        -- exclude this, as the data is strangely returned with null-byte characters\n        'Sort Key 1 Encoding' as \"stats:sortkey1_enc:label\",\n        sortkey1_enc as \"stats:sortkey1_enc:value\",\n        'Compression encoding of the first column in the sort key.' as \"stats:sortkey1_enc:description\",\n        false as \"stats:sortkey1_enc:include\",\n\n        '# Sort Keys' as \"stats:sortkey_num:label\",\n        sortkey_num as \"stats:sortkey_num:value\",\n        'Number of columns defined as sort keys.' as \"stats:sortkey_num:description\",\n        (sortkey_num > 0) as \"stats:sortkey_num:include\",\n\n        'Approximate Size' as \"stats:size:label\",\n        size / 1000000.0 as \"stats:size:value\",\n        'Approximate size of the table, calculated from a count of 1MB blocks'::text as \"stats:size:description\",\n        true as \"stats:size:include\",\n\n        'Disk Utilization' as \"stats:pct_used:label\",\n        pct_used / 100.0 as \"stats:pct_used:value\",\n        'Percent of available space that is used by the table.'::text as \"stats:pct_used:description\",\n        true as \"stats:pct_used:include\",\n\n        'Unsorted %' as \"stats:unsorted:label\",\n        unsorted / 100.0 as \"stats:unsorted:value\",\n        'Percent of unsorted rows in the table.'::text as \"stats:unsorted:description\",\n        (unsorted is not null) as \"stats:unsorted:include\",\n\n        'Stats Off' as \"stats:stats_off:label\",\n        stats_off as \"stats:stats_off:value\",\n        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as \"stats:stats_off:description\",\n        true as \"stats:stats_off:include\",\n\n        'Approximate Row Count' as \"stats:rows:label\",\n        tbl_rows as \"stats:rows:value\",\n        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as \"stats:rows:description\",\n        true as \"stats:rows:include\",\n\n        'Sort Key Skew' as \"stats:skew_sortkey1:label\",\n        skew_sortkey1 as \"stats:skew_sortkey1:value\",\n        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as \"stats:skew_sortkey1:description\",\n        (skew_sortkey1 is not null) as \"stats:skew_sortkey1:include\",\n\n        'Skew Rows' as \"stats:skew_rows:label\",\n        skew_rows as \"stats:skew_rows:value\",\n        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as \"stats:skew_rows:description\",\n        (skew_rows is not null) as \"stats:skew_rows:include\"\n\n    from svv_table_info\n    where (\n        {%- for schema in schemas -%}\n          upper(schema) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n    )\n\n  {%- endcall -%}\n\n  {{ return(load_result('extended_catalog').table) }}\n\n{% endmacro %}\n\n{% macro redshift__can_select_from(table_name) %}\n\n  {%- call statement('has_table_privilege', fetch_result=True) -%}\n\n    select has_table_privilege(current_user, '{{ table_name }}', 'SELECT') as can_select\n\n  {%- endcall -%}\n\n  {% set can_select = load_result('has_table_privilege').table[0]['can_select'] %}\n  {{ return(can_select) }}\n\n{% endmacro %}\n\n{% macro redshift__no_svv_table_info_warning() %}\n\n    {% set msg %}\n\n    Warning: The database user \"{{ target.user }}\" has insufficient permissions to\n    query the \"svv_table_info\" table. Please grant SELECT permissions on this table\n    to the \"{{ target.user }}\" user to fetch extended table details from Redshift.\n\n    {% endset %}\n\n    {{ log(msg, info=True) }}\n\n{% endmacro %}\n\n\n{% macro redshift__get_catalog(information_schema, schemas) %}\n\n    {#-- Compute a left-outer join in memory. Some Redshift queries are\n      -- leader-only, and cannot be joined to other compute-based queries #}\n\n    {% set catalog = redshift__get_base_catalog(information_schema, schemas) %}\n\n    {% set select_extended =  redshift__can_select_from('svv_table_info') %}\n    {% if select_extended %}\n        {% set extended_catalog = redshift__get_extended_catalog(schemas) %}\n        {% set catalog = catalog.join(extended_catalog, 'table_id') %}\n    {% else %}\n        {{ redshift__no_svv_table_info_warning() }}\n    {% endif %}\n\n    {{ return(catalog.exclude(['table_id'])) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__no_svv_table_info_warning", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/catalog.sql", "original_file_path": "macros/catalog.sql", "resource_type": "macro", "name": "redshift__no_svv_table_info_warning", "macro_sql": "{% macro redshift__no_svv_table_info_warning() %}\n\n    {% set msg %}\n\n    Warning: The database user \"{{ target.user }}\" has insufficient permissions to\n    query the \"svv_table_info\" table. Please grant SELECT permissions on this table\n    to the \"{{ target.user }}\" user to fetch extended table details from Redshift.\n\n    {% endset %}\n\n    {{ log(msg, info=True) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__get_catalog": {"raw_sql": "{% macro redshift__get_base_catalog(information_schema, schemas) -%}\n  {%- call statement('base_catalog', fetch_result=True) -%}\n    {% set database = information_schema.database %}\n    {{ adapter.verify_database(database) }}\n\n    with late_binding as (\n      select\n        '{{ database }}'::varchar as table_database,\n        table_schema,\n        table_name,\n        'LATE BINDING VIEW'::varchar as table_type,\n        null::text as table_comment,\n\n        column_name,\n        column_index,\n        column_type,\n        null::text as column_comment\n      from pg_get_late_binding_view_cols()\n        cols(table_schema name, table_name name, column_name name,\n             column_type varchar,\n             column_index int)\n        order by \"column_index\"\n    ),\n\n    table_owners as (\n\n        select\n            '{{ database }}'::varchar as table_database,\n            schemaname as table_schema,\n            tablename as table_name,\n            tableowner as table_owner\n\n        from pg_tables\n\n        union all\n\n        select\n            '{{ database }}'::varchar as table_database,\n            schemaname as table_schema,\n            viewname as table_name,\n            viewowner as table_owner\n\n        from pg_views\n\n    ),\n\n    tables as (\n\n      select\n        table_catalog as table_database,\n        table_schema,\n        table_name,\n        table_type\n\n      from information_schema.tables\n\n    ),\n\n    table_columns as (\n\n        select\n            '{{ database }}'::varchar as table_database,\n            table_schema,\n            table_name,\n            null::varchar as table_comment,\n\n            column_name,\n            ordinal_position as column_index,\n            data_type as column_type,\n            null::varchar as column_comment\n\n\n        from information_schema.\"columns\"\n\n    ),\n\n    unioned as (\n\n        select *\n        from tables\n        join table_columns using (table_database, table_schema, table_name)\n\n        union all\n\n        select *\n        from late_binding\n\n    )\n\n    select *,\n        table_database || '.' || table_schema || '.' || table_name as table_id\n\n    from unioned\n    join table_owners using (table_database, table_schema, table_name)\n\n    where (\n        {%- for schema in schemas -%}\n          upper(table_schema) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n      )\n\n    order by \"column_index\"\n  {%- endcall -%}\n\n  {{ return(load_result('base_catalog').table) }}\n{%- endmacro %}\n\n{% macro redshift__get_extended_catalog(schemas) %}\n  {%- call statement('extended_catalog', fetch_result=True) -%}\n\n    select\n        \"database\" || '.' || \"schema\" || '.' || \"table\" as table_id,\n\n        'Encoded'::text as \"stats:encoded:label\",\n        encoded as \"stats:encoded:value\",\n        'Indicates whether any column in the table has compression encoding defined.'::text as \"stats:encoded:description\",\n        true as \"stats:encoded:include\",\n\n        'Dist Style' as \"stats:diststyle:label\",\n        diststyle as \"stats:diststyle:value\",\n        'Distribution style or distribution key column, if key distribution is defined.'::text as \"stats:diststyle:description\",\n        true as \"stats:diststyle:include\",\n\n        'Sort Key 1' as \"stats:sortkey1:label\",\n        -- handle 0xFF byte in response for interleaved sort styles\n        case\n            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text\n            else sortkey1\n        end as \"stats:sortkey1:value\",\n        'First column in the sort key.'::text as \"stats:sortkey1:description\",\n        (sortkey1 is not null) as \"stats:sortkey1:include\",\n\n        'Max Varchar' as \"stats:max_varchar:label\",\n        max_varchar as \"stats:max_varchar:value\",\n        'Size of the largest column that uses a VARCHAR data type.'::text as \"stats:max_varchar:description\",\n        true as \"stats:max_varchar:include\",\n\n        -- exclude this, as the data is strangely returned with null-byte characters\n        'Sort Key 1 Encoding' as \"stats:sortkey1_enc:label\",\n        sortkey1_enc as \"stats:sortkey1_enc:value\",\n        'Compression encoding of the first column in the sort key.' as \"stats:sortkey1_enc:description\",\n        false as \"stats:sortkey1_enc:include\",\n\n        '# Sort Keys' as \"stats:sortkey_num:label\",\n        sortkey_num as \"stats:sortkey_num:value\",\n        'Number of columns defined as sort keys.' as \"stats:sortkey_num:description\",\n        (sortkey_num > 0) as \"stats:sortkey_num:include\",\n\n        'Approximate Size' as \"stats:size:label\",\n        size / 1000000.0 as \"stats:size:value\",\n        'Approximate size of the table, calculated from a count of 1MB blocks'::text as \"stats:size:description\",\n        true as \"stats:size:include\",\n\n        'Disk Utilization' as \"stats:pct_used:label\",\n        pct_used / 100.0 as \"stats:pct_used:value\",\n        'Percent of available space that is used by the table.'::text as \"stats:pct_used:description\",\n        true as \"stats:pct_used:include\",\n\n        'Unsorted %' as \"stats:unsorted:label\",\n        unsorted / 100.0 as \"stats:unsorted:value\",\n        'Percent of unsorted rows in the table.'::text as \"stats:unsorted:description\",\n        (unsorted is not null) as \"stats:unsorted:include\",\n\n        'Stats Off' as \"stats:stats_off:label\",\n        stats_off as \"stats:stats_off:value\",\n        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as \"stats:stats_off:description\",\n        true as \"stats:stats_off:include\",\n\n        'Approximate Row Count' as \"stats:rows:label\",\n        tbl_rows as \"stats:rows:value\",\n        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as \"stats:rows:description\",\n        true as \"stats:rows:include\",\n\n        'Sort Key Skew' as \"stats:skew_sortkey1:label\",\n        skew_sortkey1 as \"stats:skew_sortkey1:value\",\n        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as \"stats:skew_sortkey1:description\",\n        (skew_sortkey1 is not null) as \"stats:skew_sortkey1:include\",\n\n        'Skew Rows' as \"stats:skew_rows:label\",\n        skew_rows as \"stats:skew_rows:value\",\n        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as \"stats:skew_rows:description\",\n        (skew_rows is not null) as \"stats:skew_rows:include\"\n\n    from svv_table_info\n    where (\n        {%- for schema in schemas -%}\n          upper(schema) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n    )\n\n  {%- endcall -%}\n\n  {{ return(load_result('extended_catalog').table) }}\n\n{% endmacro %}\n\n{% macro redshift__can_select_from(table_name) %}\n\n  {%- call statement('has_table_privilege', fetch_result=True) -%}\n\n    select has_table_privilege(current_user, '{{ table_name }}', 'SELECT') as can_select\n\n  {%- endcall -%}\n\n  {% set can_select = load_result('has_table_privilege').table[0]['can_select'] %}\n  {{ return(can_select) }}\n\n{% endmacro %}\n\n{% macro redshift__no_svv_table_info_warning() %}\n\n    {% set msg %}\n\n    Warning: The database user \"{{ target.user }}\" has insufficient permissions to\n    query the \"svv_table_info\" table. Please grant SELECT permissions on this table\n    to the \"{{ target.user }}\" user to fetch extended table details from Redshift.\n\n    {% endset %}\n\n    {{ log(msg, info=True) }}\n\n{% endmacro %}\n\n\n{% macro redshift__get_catalog(information_schema, schemas) %}\n\n    {#-- Compute a left-outer join in memory. Some Redshift queries are\n      -- leader-only, and cannot be joined to other compute-based queries #}\n\n    {% set catalog = redshift__get_base_catalog(information_schema, schemas) %}\n\n    {% set select_extended =  redshift__can_select_from('svv_table_info') %}\n    {% if select_extended %}\n        {% set extended_catalog = redshift__get_extended_catalog(schemas) %}\n        {% set catalog = catalog.join(extended_catalog, 'table_id') %}\n    {% else %}\n        {{ redshift__no_svv_table_info_warning() }}\n    {% endif %}\n\n    {{ return(catalog.exclude(['table_id'])) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__get_catalog", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/catalog.sql", "original_file_path": "macros/catalog.sql", "resource_type": "macro", "name": "redshift__get_catalog", "macro_sql": "{% macro redshift__get_catalog(information_schema, schemas) %}\n\n    {#-- Compute a left-outer join in memory. Some Redshift queries are\n      -- leader-only, and cannot be joined to other compute-based queries #}\n\n    {% set catalog = redshift__get_base_catalog(information_schema, schemas) %}\n\n    {% set select_extended =  redshift__can_select_from('svv_table_info') %}\n    {% if select_extended %}\n        {% set extended_catalog = redshift__get_extended_catalog(schemas) %}\n        {% set catalog = catalog.join(extended_catalog, 'table_id') %}\n    {% else %}\n        {{ redshift__no_svv_table_info_warning() }}\n    {% endif %}\n\n    {{ return(catalog.exclude(['table_id'])) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__get_relations": {"raw_sql": "{% macro redshift__get_relations () -%}\n  {{ return(dbt.postgres__get_relations()) }}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__get_relations", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/relations.sql", "original_file_path": "macros/relations.sql", "resource_type": "macro", "name": "redshift__get_relations", "macro_sql": "{% macro redshift__get_relations () -%}\n  {{ return(dbt.postgres__get_relations()) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.dist": {"raw_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n\n{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}\n\n\n{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}\n\n{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}\n\n{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}\n\n\n{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.dist", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "dist", "macro_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.sort": {"raw_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n\n{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}\n\n\n{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}\n\n{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}\n\n{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}\n\n\n{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.sort", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "sort", "macro_sql": "{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__create_table_as": {"raw_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n\n{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}\n\n\n{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}\n\n{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}\n\n{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}\n\n\n{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__create_table_as", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "redshift__create_table_as", "macro_sql": "{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__create_view_as": {"raw_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n\n{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}\n\n\n{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}\n\n{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}\n\n{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}\n\n\n{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__create_view_as", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "redshift__create_view_as", "macro_sql": "{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__create_schema": {"raw_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n\n{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}\n\n\n{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}\n\n{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}\n\n{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}\n\n\n{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__create_schema", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "redshift__create_schema", "macro_sql": "{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__drop_schema": {"raw_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n\n{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}\n\n\n{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}\n\n{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}\n\n{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}\n\n\n{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__drop_schema", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "redshift__drop_schema", "macro_sql": "{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__get_columns_in_relation": {"raw_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n\n{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}\n\n\n{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}\n\n{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}\n\n{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}\n\n\n{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__get_columns_in_relation", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "redshift__get_columns_in_relation", "macro_sql": "{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__list_relations_without_caching": {"raw_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n\n{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}\n\n\n{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}\n\n{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}\n\n{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}\n\n\n{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__list_relations_without_caching", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "redshift__list_relations_without_caching", "macro_sql": "{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__information_schema_name": {"raw_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n\n{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}\n\n\n{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}\n\n{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}\n\n{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}\n\n\n{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__information_schema_name", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "redshift__information_schema_name", "macro_sql": "{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__list_schemas": {"raw_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n\n{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}\n\n\n{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}\n\n{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}\n\n{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}\n\n\n{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__list_schemas", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "redshift__list_schemas", "macro_sql": "{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__check_schema_exists": {"raw_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n\n{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}\n\n\n{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}\n\n{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}\n\n{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}\n\n\n{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__check_schema_exists", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "redshift__check_schema_exists", "macro_sql": "{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__current_timestamp": {"raw_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n\n{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}\n\n\n{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}\n\n{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}\n\n{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}\n\n\n{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__current_timestamp", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "redshift__current_timestamp", "macro_sql": "{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__snapshot_get_time": {"raw_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n\n{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}\n\n\n{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}\n\n{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}\n\n{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}\n\n\n{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__snapshot_get_time", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "redshift__snapshot_get_time", "macro_sql": "{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__snapshot_string_as_time": {"raw_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n\n{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}\n\n\n{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}\n\n{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}\n\n{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}\n\n\n{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__snapshot_string_as_time", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "redshift__snapshot_string_as_time", "macro_sql": "{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__make_temp_relation": {"raw_sql": "{% macro dist(dist) %}\n  {%- if dist is not none -%}\n      {%- set dist = dist.strip().lower() -%}\n\n      {%- if dist in ['all', 'even', 'auto'] -%}\n        diststyle {{ dist }}\n      {%- else -%}\n        diststyle key distkey ({{ dist }})\n      {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro -%}\n\n\n{% macro sort(sort_type, sort) %}\n  {%- if sort is not none %}\n      {{ sort_type | default('compound', boolean=true) }} sortkey(\n      {%- if sort is string -%}\n        {%- set sort = [sort] -%}\n      {%- endif -%}\n      {%- for item in sort -%}\n        {{ item }}\n        {%- if not loop.last -%},{%- endif -%}\n      {%- endfor -%}\n      )\n  {%- endif %}\n{%- endmacro -%}\n\n\n{% macro redshift__create_table_as(temporary, relation, sql) -%}\n\n  {%- set _dist = config.get('dist') -%}\n  {%- set _sort_type = config.get(\n          'sort_type',\n          validator=validation.any['compound', 'interleaved']) -%}\n  {%- set _sort = config.get(\n          'sort',\n          validator=validation.any[list, basestring]) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n    {{ dist(_dist) }}\n    {{ sort(_sort_type, _sort) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n\n{% macro redshift__create_view_as(relation, sql) -%}\n\n  {% set bind_qualifier = '' if config.get('bind', default=True) else 'with no schema binding' %}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create view {{ relation }} as (\n    {{ sql }}\n  ) {{ bind_qualifier }};\n{% endmacro %}\n\n\n{% macro redshift__create_schema(database_name, schema_name) -%}\n  {{ postgres__create_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__drop_schema(database_name, schema_name) -%}\n  {{ postgres__drop_schema(database_name, schema_name) }}\n{% endmacro %}\n\n\n{% macro redshift__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      with bound_views as (\n        select\n          ordinal_position,\n          table_schema,\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n        from information_schema.\"columns\"\n        where table_name = '{{ relation.identifier }}'\n    ),\n\n    unbound_views as (\n      select\n        ordinal_position,\n        view_schema,\n        col_name,\n        case\n          when col_type ilike 'character varying%' then\n            'character varying'\n          when col_type ilike 'numeric%' then 'numeric'\n          else col_type\n        end as col_type,\n        case\n          when col_type like 'character%'\n          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int\n          else null\n        end as character_maximum_length,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),\n            '')::int\n          else null\n        end as numeric_precision,\n        case\n          when col_type like 'numeric%'\n          then nullif(\n            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),\n            '')::int\n          else null\n        end as numeric_scale\n\n      from pg_get_late_binding_view_cols()\n      cols(view_schema name, view_name name, col_name name,\n           col_type varchar, ordinal_position int)\n      where view_name = '{{ relation.identifier }}'\n    ),\n\n    unioned as (\n      select * from bound_views\n      union all\n      select * from unbound_views\n    )\n\n    select\n      column_name,\n      data_type,\n      character_maximum_length,\n      numeric_precision,\n      numeric_scale\n\n    from unioned\n    {% if relation.schema %}\n    where table_schema = '{{ relation.schema }}'\n    {% endif %}\n    order by ordinal_position\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro redshift__list_relations_without_caching(information_schema, schema) %}\n  {{ return(postgres__list_relations_without_caching(information_schema, schema)) }}\n{% endmacro %}\n\n\n{% macro redshift__information_schema_name(database) -%}\n  {{ return(postgres__information_schema_name(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__list_schemas(database) -%}\n  {{ return(postgres__list_schemas(database)) }}\n{%- endmacro %}\n\n\n{% macro redshift__check_schema_exists(information_schema, schema) -%}\n  {{ return(postgres__check_schema_exists(information_schema, schema)) }}\n{%- endmacro %}\n\n{% macro redshift__current_timestamp() -%}\n  getdate()\n{%- endmacro %}\n\n{% macro redshift__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp\n{%- endmacro %}\n\n\n{% macro redshift__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__make_temp_relation", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "redshift__make_temp_relation", "macro_sql": "{% macro redshift__make_temp_relation(base_relation, suffix) %}\n    {% do return(postgres__make_temp_relation(base_relation, suffix)) %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_redshift.redshift__snapshot_merge_sql": {"raw_sql": "{% macro redshift__snapshot_merge_sql(target, source, insert_cols) -%}\n    {{ postgres__snapshot_merge_sql(target, source, insert_cols) }}\n{% endmacro %}", "unique_id": "macro.dbt_redshift.redshift__snapshot_merge_sql", "package_name": "dbt_redshift", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift", "path": "macros/materializations/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshot_merge.sql", "resource_type": "macro", "name": "redshift__snapshot_merge_sql", "macro_sql": "{% macro redshift__snapshot_merge_sql(target, source, insert_cols) -%}\n    {{ postgres__snapshot_merge_sql(target, source, insert_cols) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_postgres.postgres__get_catalog": {"raw_sql": "{% macro postgres__get_catalog(information_schema, schemas) -%}\n\n  {%- call statement('catalog', fetch_result=True) -%}\n    {#\n      If the user has multiple databases set and the first one is wrong, this will fail.\n      But we won't fail in the case where there are multiple quoting-difference-only dbs, which is better.\n    #}\n    {% set database = information_schema.database %}\n    {{ adapter.verify_database(database) }}\n\n    select\n        '{{ database }}' as table_database,\n        sch.nspname as table_schema,\n        tbl.relname as table_name,\n        case tbl.relkind\n            when 'v' then 'VIEW'\n            else 'BASE TABLE'\n        end as table_type,\n        null::text as table_comment,\n        col.attname as column_name,\n        col.attnum as column_index,\n        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,\n        null::text as column_comment,\n        pg_get_userbyid(tbl.relowner) as table_owner\n\n    from pg_catalog.pg_namespace sch\n    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid\n    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid\n\n    where (\n        {%- for schema in schemas -%}\n          upper(sch.nspname) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n      )\n      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session\n      and tbl.relpersistence = 'p' -- [p]ermanent table. Other values are [u]nlogged table, [t]emporary table\n      and tbl.relkind in ('r', 'v', 'f', 'p') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table, [m]aterialized view\n      and col.attnum > 0 -- negative numbers are used for system columns such as oid\n      and not col.attisdropped -- column as not been dropped\n\n    order by\n        sch.nspname,\n        tbl.relname,\n        col.attnum\n\n  {%- endcall -%}\n\n  {{ return(load_result('catalog').table) }}\n\n{%- endmacro %}", "unique_id": "macro.dbt_postgres.postgres__get_catalog", "package_name": "dbt_postgres", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres", "path": "macros/catalog.sql", "original_file_path": "macros/catalog.sql", "resource_type": "macro", "name": "postgres__get_catalog", "macro_sql": "{% macro postgres__get_catalog(information_schema, schemas) -%}\n\n  {%- call statement('catalog', fetch_result=True) -%}\n    {#\n      If the user has multiple databases set and the first one is wrong, this will fail.\n      But we won't fail in the case where there are multiple quoting-difference-only dbs, which is better.\n    #}\n    {% set database = information_schema.database %}\n    {{ adapter.verify_database(database) }}\n\n    select\n        '{{ database }}' as table_database,\n        sch.nspname as table_schema,\n        tbl.relname as table_name,\n        case tbl.relkind\n            when 'v' then 'VIEW'\n            else 'BASE TABLE'\n        end as table_type,\n        null::text as table_comment,\n        col.attname as column_name,\n        col.attnum as column_index,\n        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,\n        null::text as column_comment,\n        pg_get_userbyid(tbl.relowner) as table_owner\n\n    from pg_catalog.pg_namespace sch\n    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid\n    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid\n\n    where (\n        {%- for schema in schemas -%}\n          upper(sch.nspname) = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n      )\n      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session\n      and tbl.relpersistence = 'p' -- [p]ermanent table. Other values are [u]nlogged table, [t]emporary table\n      and tbl.relkind in ('r', 'v', 'f', 'p') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table, [m]aterialized view\n      and col.attnum > 0 -- negative numbers are used for system columns such as oid\n      and not col.attisdropped -- column as not been dropped\n\n    order by\n        sch.nspname,\n        tbl.relname,\n        col.attnum\n\n  {%- endcall -%}\n\n  {{ return(load_result('catalog').table) }}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_postgres.postgres_get_relations": {"raw_sql": "{% macro postgres_get_relations () -%}\n\n  {#\n      -- in pg_depend, objid is the dependent, refobjid is the referenced object\n      --  > a pg_depend entry indicates that the referenced object cannot be\n      --  > dropped without also dropping the dependent object.\n  #}\n\n  {%- call statement('relations', fetch_result=True) -%}\n    with relation as (\n        select\n            pg_rewrite.ev_class as class,\n            pg_rewrite.oid as id\n        from pg_rewrite\n    ),\n    class as (\n        select\n            oid as id,\n            relname as name,\n            relnamespace as schema,\n            relkind as kind\n        from pg_class\n    ),\n    dependency as (\n        select\n            pg_depend.objid as id,\n            pg_depend.refobjid as ref\n        from pg_depend\n    ),\n    schema as (\n        select\n            pg_namespace.oid as id,\n            pg_namespace.nspname as name\n        from pg_namespace\n        where nspname != 'information_schema' and nspname not like 'pg\\_%'\n    ),\n    referenced as (\n        select\n            relation.id AS id,\n            referenced_class.name ,\n            referenced_class.schema ,\n            referenced_class.kind\n        from relation\n        join class as referenced_class on relation.class=referenced_class.id\n        where referenced_class.kind in ('r', 'v')\n    ),\n    relationships as (\n        select\n            referenced.name as referenced_name,\n            referenced.schema as referenced_schema_id,\n            dependent_class.name as dependent_name,\n            dependent_class.schema as dependent_schema_id,\n            referenced.kind as kind\n        from referenced\n        join dependency on referenced.id=dependency.id\n        join class as dependent_class on dependency.ref=dependent_class.id\n        where\n            (referenced.name != dependent_class.name or\n             referenced.schema != dependent_class.schema)\n    )\n\n    select\n        referenced_schema.name as referenced_schema,\n        relationships.referenced_name as referenced_name,\n        dependent_schema.name as dependent_schema,\n        relationships.dependent_name as dependent_name\n    from relationships\n    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id\n    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id\n    group by referenced_schema, referenced_name, dependent_schema, dependent_name\n    order by referenced_schema, referenced_name, dependent_schema, dependent_name;\n\n  {%- endcall -%}\n\n  {{ return(load_result('relations').table) }}\n{% endmacro %}", "unique_id": "macro.dbt_postgres.postgres_get_relations", "package_name": "dbt_postgres", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres", "path": "macros/relations.sql", "original_file_path": "macros/relations.sql", "resource_type": "macro", "name": "postgres_get_relations", "macro_sql": "{% macro postgres_get_relations () -%}\n\n  {#\n      -- in pg_depend, objid is the dependent, refobjid is the referenced object\n      --  > a pg_depend entry indicates that the referenced object cannot be\n      --  > dropped without also dropping the dependent object.\n  #}\n\n  {%- call statement('relations', fetch_result=True) -%}\n    with relation as (\n        select\n            pg_rewrite.ev_class as class,\n            pg_rewrite.oid as id\n        from pg_rewrite\n    ),\n    class as (\n        select\n            oid as id,\n            relname as name,\n            relnamespace as schema,\n            relkind as kind\n        from pg_class\n    ),\n    dependency as (\n        select\n            pg_depend.objid as id,\n            pg_depend.refobjid as ref\n        from pg_depend\n    ),\n    schema as (\n        select\n            pg_namespace.oid as id,\n            pg_namespace.nspname as name\n        from pg_namespace\n        where nspname != 'information_schema' and nspname not like 'pg\\_%'\n    ),\n    referenced as (\n        select\n            relation.id AS id,\n            referenced_class.name ,\n            referenced_class.schema ,\n            referenced_class.kind\n        from relation\n        join class as referenced_class on relation.class=referenced_class.id\n        where referenced_class.kind in ('r', 'v')\n    ),\n    relationships as (\n        select\n            referenced.name as referenced_name,\n            referenced.schema as referenced_schema_id,\n            dependent_class.name as dependent_name,\n            dependent_class.schema as dependent_schema_id,\n            referenced.kind as kind\n        from referenced\n        join dependency on referenced.id=dependency.id\n        join class as dependent_class on dependency.ref=dependent_class.id\n        where\n            (referenced.name != dependent_class.name or\n             referenced.schema != dependent_class.schema)\n    )\n\n    select\n        referenced_schema.name as referenced_schema,\n        relationships.referenced_name as referenced_name,\n        dependent_schema.name as dependent_schema,\n        relationships.dependent_name as dependent_name\n    from relationships\n    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id\n    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id\n    group by referenced_schema, referenced_name, dependent_schema, dependent_name\n    order by referenced_schema, referenced_name, dependent_schema, dependent_name;\n\n  {%- endcall -%}\n\n  {{ return(load_result('relations').table) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_postgres.postgres__create_table_as": {"raw_sql": "{% macro postgres__create_table_as(temporary, relation, sql) -%}\n  {%- set unlogged = config.get('unlogged', default=false) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}\n    temporary\n  {%- elif unlogged -%}\n    unlogged\n  {%- endif %} table {{ relation }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n{% macro postgres__create_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ schema_name }}\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__drop_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ schema_name }} cascade\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      select\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n      from {{ relation.information_schema('columns') }}\n      where table_name = '{{ relation.identifier }}'\n        {% if relation.schema %}\n        and table_schema = '{{ relation.schema }}'\n        {% endif %}\n      order by ordinal_position\n\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro postgres__list_relations_without_caching(information_schema, schema) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    select\n      '{{ information_schema.database }}' as database,\n      tablename as name,\n      schemaname as schema,\n      'table' as type\n    from pg_tables\n    where schemaname ilike '{{ schema }}'\n    union all\n    select\n      '{{ information_schema.database }}' as database,\n      viewname as name,\n      schemaname as schema,\n      'view' as type\n    from pg_views\n    where schemaname ilike '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('list_relations_without_caching').table) }}\n{% endmacro %}\n\n{% macro postgres__information_schema_name(database) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  information_schema\n{%- endmacro %}\n\n{% macro postgres__list_schemas(database) %}\n  {% if database -%}\n    {{ adapter.verify_database(database) }}\n  {%- endif -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    select distinct nspname from pg_namespace\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}\n\n{% macro postgres__check_schema_exists(information_schema, schema) -%}\n  {% if information_schema.database -%}\n    {{ adapter.verify_database(information_schema.database) }}\n  {%- endif -%}\n  {% call statement('check_schema_exists', fetch_result=True, auto_begin=False) %}\n    select count(*) from pg_namespace where nspname = '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('check_schema_exists').table) }}\n{% endmacro %}\n\n\n{% macro postgres__current_timestamp() -%}\n  now()\n{%- endmacro %}\n\n{% macro postgres__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp without time zone\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro postgres__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp without time zone\n{%- endmacro %}\n\n{% macro postgres__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix ~ py_current_timestring() %}\n    {% do return(base_relation.incorporate(\n                                  path={\n                                    \"identifier\": tmp_identifier,\n                                    \"schema\": none,\n                                    \"database\": none\n                                  })) -%}\n{% endmacro %}", "unique_id": "macro.dbt_postgres.postgres__create_table_as", "package_name": "dbt_postgres", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "postgres__create_table_as", "macro_sql": "{% macro postgres__create_table_as(temporary, relation, sql) -%}\n  {%- set unlogged = config.get('unlogged', default=false) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}\n    temporary\n  {%- elif unlogged -%}\n    unlogged\n  {%- endif %} table {{ relation }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_postgres.postgres__create_schema": {"raw_sql": "{% macro postgres__create_table_as(temporary, relation, sql) -%}\n  {%- set unlogged = config.get('unlogged', default=false) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}\n    temporary\n  {%- elif unlogged -%}\n    unlogged\n  {%- endif %} table {{ relation }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n{% macro postgres__create_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ schema_name }}\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__drop_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ schema_name }} cascade\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      select\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n      from {{ relation.information_schema('columns') }}\n      where table_name = '{{ relation.identifier }}'\n        {% if relation.schema %}\n        and table_schema = '{{ relation.schema }}'\n        {% endif %}\n      order by ordinal_position\n\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro postgres__list_relations_without_caching(information_schema, schema) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    select\n      '{{ information_schema.database }}' as database,\n      tablename as name,\n      schemaname as schema,\n      'table' as type\n    from pg_tables\n    where schemaname ilike '{{ schema }}'\n    union all\n    select\n      '{{ information_schema.database }}' as database,\n      viewname as name,\n      schemaname as schema,\n      'view' as type\n    from pg_views\n    where schemaname ilike '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('list_relations_without_caching').table) }}\n{% endmacro %}\n\n{% macro postgres__information_schema_name(database) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  information_schema\n{%- endmacro %}\n\n{% macro postgres__list_schemas(database) %}\n  {% if database -%}\n    {{ adapter.verify_database(database) }}\n  {%- endif -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    select distinct nspname from pg_namespace\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}\n\n{% macro postgres__check_schema_exists(information_schema, schema) -%}\n  {% if information_schema.database -%}\n    {{ adapter.verify_database(information_schema.database) }}\n  {%- endif -%}\n  {% call statement('check_schema_exists', fetch_result=True, auto_begin=False) %}\n    select count(*) from pg_namespace where nspname = '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('check_schema_exists').table) }}\n{% endmacro %}\n\n\n{% macro postgres__current_timestamp() -%}\n  now()\n{%- endmacro %}\n\n{% macro postgres__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp without time zone\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro postgres__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp without time zone\n{%- endmacro %}\n\n{% macro postgres__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix ~ py_current_timestring() %}\n    {% do return(base_relation.incorporate(\n                                  path={\n                                    \"identifier\": tmp_identifier,\n                                    \"schema\": none,\n                                    \"database\": none\n                                  })) -%}\n{% endmacro %}", "unique_id": "macro.dbt_postgres.postgres__create_schema", "package_name": "dbt_postgres", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "postgres__create_schema", "macro_sql": "{% macro postgres__create_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ schema_name }}\n  {%- endcall -%}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_postgres.postgres__drop_schema": {"raw_sql": "{% macro postgres__create_table_as(temporary, relation, sql) -%}\n  {%- set unlogged = config.get('unlogged', default=false) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}\n    temporary\n  {%- elif unlogged -%}\n    unlogged\n  {%- endif %} table {{ relation }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n{% macro postgres__create_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ schema_name }}\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__drop_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ schema_name }} cascade\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      select\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n      from {{ relation.information_schema('columns') }}\n      where table_name = '{{ relation.identifier }}'\n        {% if relation.schema %}\n        and table_schema = '{{ relation.schema }}'\n        {% endif %}\n      order by ordinal_position\n\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro postgres__list_relations_without_caching(information_schema, schema) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    select\n      '{{ information_schema.database }}' as database,\n      tablename as name,\n      schemaname as schema,\n      'table' as type\n    from pg_tables\n    where schemaname ilike '{{ schema }}'\n    union all\n    select\n      '{{ information_schema.database }}' as database,\n      viewname as name,\n      schemaname as schema,\n      'view' as type\n    from pg_views\n    where schemaname ilike '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('list_relations_without_caching').table) }}\n{% endmacro %}\n\n{% macro postgres__information_schema_name(database) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  information_schema\n{%- endmacro %}\n\n{% macro postgres__list_schemas(database) %}\n  {% if database -%}\n    {{ adapter.verify_database(database) }}\n  {%- endif -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    select distinct nspname from pg_namespace\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}\n\n{% macro postgres__check_schema_exists(information_schema, schema) -%}\n  {% if information_schema.database -%}\n    {{ adapter.verify_database(information_schema.database) }}\n  {%- endif -%}\n  {% call statement('check_schema_exists', fetch_result=True, auto_begin=False) %}\n    select count(*) from pg_namespace where nspname = '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('check_schema_exists').table) }}\n{% endmacro %}\n\n\n{% macro postgres__current_timestamp() -%}\n  now()\n{%- endmacro %}\n\n{% macro postgres__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp without time zone\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro postgres__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp without time zone\n{%- endmacro %}\n\n{% macro postgres__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix ~ py_current_timestring() %}\n    {% do return(base_relation.incorporate(\n                                  path={\n                                    \"identifier\": tmp_identifier,\n                                    \"schema\": none,\n                                    \"database\": none\n                                  })) -%}\n{% endmacro %}", "unique_id": "macro.dbt_postgres.postgres__drop_schema", "package_name": "dbt_postgres", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "postgres__drop_schema", "macro_sql": "{% macro postgres__drop_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ schema_name }} cascade\n  {%- endcall -%}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_postgres.postgres__get_columns_in_relation": {"raw_sql": "{% macro postgres__create_table_as(temporary, relation, sql) -%}\n  {%- set unlogged = config.get('unlogged', default=false) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}\n    temporary\n  {%- elif unlogged -%}\n    unlogged\n  {%- endif %} table {{ relation }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n{% macro postgres__create_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ schema_name }}\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__drop_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ schema_name }} cascade\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      select\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n      from {{ relation.information_schema('columns') }}\n      where table_name = '{{ relation.identifier }}'\n        {% if relation.schema %}\n        and table_schema = '{{ relation.schema }}'\n        {% endif %}\n      order by ordinal_position\n\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro postgres__list_relations_without_caching(information_schema, schema) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    select\n      '{{ information_schema.database }}' as database,\n      tablename as name,\n      schemaname as schema,\n      'table' as type\n    from pg_tables\n    where schemaname ilike '{{ schema }}'\n    union all\n    select\n      '{{ information_schema.database }}' as database,\n      viewname as name,\n      schemaname as schema,\n      'view' as type\n    from pg_views\n    where schemaname ilike '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('list_relations_without_caching').table) }}\n{% endmacro %}\n\n{% macro postgres__information_schema_name(database) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  information_schema\n{%- endmacro %}\n\n{% macro postgres__list_schemas(database) %}\n  {% if database -%}\n    {{ adapter.verify_database(database) }}\n  {%- endif -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    select distinct nspname from pg_namespace\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}\n\n{% macro postgres__check_schema_exists(information_schema, schema) -%}\n  {% if information_schema.database -%}\n    {{ adapter.verify_database(information_schema.database) }}\n  {%- endif -%}\n  {% call statement('check_schema_exists', fetch_result=True, auto_begin=False) %}\n    select count(*) from pg_namespace where nspname = '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('check_schema_exists').table) }}\n{% endmacro %}\n\n\n{% macro postgres__current_timestamp() -%}\n  now()\n{%- endmacro %}\n\n{% macro postgres__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp without time zone\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro postgres__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp without time zone\n{%- endmacro %}\n\n{% macro postgres__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix ~ py_current_timestring() %}\n    {% do return(base_relation.incorporate(\n                                  path={\n                                    \"identifier\": tmp_identifier,\n                                    \"schema\": none,\n                                    \"database\": none\n                                  })) -%}\n{% endmacro %}", "unique_id": "macro.dbt_postgres.postgres__get_columns_in_relation", "package_name": "dbt_postgres", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "postgres__get_columns_in_relation", "macro_sql": "{% macro postgres__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      select\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n      from {{ relation.information_schema('columns') }}\n      where table_name = '{{ relation.identifier }}'\n        {% if relation.schema %}\n        and table_schema = '{{ relation.schema }}'\n        {% endif %}\n      order by ordinal_position\n\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_postgres.postgres__list_relations_without_caching": {"raw_sql": "{% macro postgres__create_table_as(temporary, relation, sql) -%}\n  {%- set unlogged = config.get('unlogged', default=false) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}\n    temporary\n  {%- elif unlogged -%}\n    unlogged\n  {%- endif %} table {{ relation }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n{% macro postgres__create_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ schema_name }}\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__drop_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ schema_name }} cascade\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      select\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n      from {{ relation.information_schema('columns') }}\n      where table_name = '{{ relation.identifier }}'\n        {% if relation.schema %}\n        and table_schema = '{{ relation.schema }}'\n        {% endif %}\n      order by ordinal_position\n\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro postgres__list_relations_without_caching(information_schema, schema) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    select\n      '{{ information_schema.database }}' as database,\n      tablename as name,\n      schemaname as schema,\n      'table' as type\n    from pg_tables\n    where schemaname ilike '{{ schema }}'\n    union all\n    select\n      '{{ information_schema.database }}' as database,\n      viewname as name,\n      schemaname as schema,\n      'view' as type\n    from pg_views\n    where schemaname ilike '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('list_relations_without_caching').table) }}\n{% endmacro %}\n\n{% macro postgres__information_schema_name(database) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  information_schema\n{%- endmacro %}\n\n{% macro postgres__list_schemas(database) %}\n  {% if database -%}\n    {{ adapter.verify_database(database) }}\n  {%- endif -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    select distinct nspname from pg_namespace\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}\n\n{% macro postgres__check_schema_exists(information_schema, schema) -%}\n  {% if information_schema.database -%}\n    {{ adapter.verify_database(information_schema.database) }}\n  {%- endif -%}\n  {% call statement('check_schema_exists', fetch_result=True, auto_begin=False) %}\n    select count(*) from pg_namespace where nspname = '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('check_schema_exists').table) }}\n{% endmacro %}\n\n\n{% macro postgres__current_timestamp() -%}\n  now()\n{%- endmacro %}\n\n{% macro postgres__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp without time zone\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro postgres__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp without time zone\n{%- endmacro %}\n\n{% macro postgres__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix ~ py_current_timestring() %}\n    {% do return(base_relation.incorporate(\n                                  path={\n                                    \"identifier\": tmp_identifier,\n                                    \"schema\": none,\n                                    \"database\": none\n                                  })) -%}\n{% endmacro %}", "unique_id": "macro.dbt_postgres.postgres__list_relations_without_caching", "package_name": "dbt_postgres", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "postgres__list_relations_without_caching", "macro_sql": "{% macro postgres__list_relations_without_caching(information_schema, schema) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    select\n      '{{ information_schema.database }}' as database,\n      tablename as name,\n      schemaname as schema,\n      'table' as type\n    from pg_tables\n    where schemaname ilike '{{ schema }}'\n    union all\n    select\n      '{{ information_schema.database }}' as database,\n      viewname as name,\n      schemaname as schema,\n      'view' as type\n    from pg_views\n    where schemaname ilike '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('list_relations_without_caching').table) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_postgres.postgres__information_schema_name": {"raw_sql": "{% macro postgres__create_table_as(temporary, relation, sql) -%}\n  {%- set unlogged = config.get('unlogged', default=false) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}\n    temporary\n  {%- elif unlogged -%}\n    unlogged\n  {%- endif %} table {{ relation }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n{% macro postgres__create_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ schema_name }}\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__drop_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ schema_name }} cascade\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      select\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n      from {{ relation.information_schema('columns') }}\n      where table_name = '{{ relation.identifier }}'\n        {% if relation.schema %}\n        and table_schema = '{{ relation.schema }}'\n        {% endif %}\n      order by ordinal_position\n\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro postgres__list_relations_without_caching(information_schema, schema) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    select\n      '{{ information_schema.database }}' as database,\n      tablename as name,\n      schemaname as schema,\n      'table' as type\n    from pg_tables\n    where schemaname ilike '{{ schema }}'\n    union all\n    select\n      '{{ information_schema.database }}' as database,\n      viewname as name,\n      schemaname as schema,\n      'view' as type\n    from pg_views\n    where schemaname ilike '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('list_relations_without_caching').table) }}\n{% endmacro %}\n\n{% macro postgres__information_schema_name(database) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  information_schema\n{%- endmacro %}\n\n{% macro postgres__list_schemas(database) %}\n  {% if database -%}\n    {{ adapter.verify_database(database) }}\n  {%- endif -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    select distinct nspname from pg_namespace\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}\n\n{% macro postgres__check_schema_exists(information_schema, schema) -%}\n  {% if information_schema.database -%}\n    {{ adapter.verify_database(information_schema.database) }}\n  {%- endif -%}\n  {% call statement('check_schema_exists', fetch_result=True, auto_begin=False) %}\n    select count(*) from pg_namespace where nspname = '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('check_schema_exists').table) }}\n{% endmacro %}\n\n\n{% macro postgres__current_timestamp() -%}\n  now()\n{%- endmacro %}\n\n{% macro postgres__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp without time zone\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro postgres__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp without time zone\n{%- endmacro %}\n\n{% macro postgres__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix ~ py_current_timestring() %}\n    {% do return(base_relation.incorporate(\n                                  path={\n                                    \"identifier\": tmp_identifier,\n                                    \"schema\": none,\n                                    \"database\": none\n                                  })) -%}\n{% endmacro %}", "unique_id": "macro.dbt_postgres.postgres__information_schema_name", "package_name": "dbt_postgres", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "postgres__information_schema_name", "macro_sql": "{% macro postgres__information_schema_name(database) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  information_schema\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_postgres.postgres__list_schemas": {"raw_sql": "{% macro postgres__create_table_as(temporary, relation, sql) -%}\n  {%- set unlogged = config.get('unlogged', default=false) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}\n    temporary\n  {%- elif unlogged -%}\n    unlogged\n  {%- endif %} table {{ relation }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n{% macro postgres__create_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ schema_name }}\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__drop_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ schema_name }} cascade\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      select\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n      from {{ relation.information_schema('columns') }}\n      where table_name = '{{ relation.identifier }}'\n        {% if relation.schema %}\n        and table_schema = '{{ relation.schema }}'\n        {% endif %}\n      order by ordinal_position\n\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro postgres__list_relations_without_caching(information_schema, schema) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    select\n      '{{ information_schema.database }}' as database,\n      tablename as name,\n      schemaname as schema,\n      'table' as type\n    from pg_tables\n    where schemaname ilike '{{ schema }}'\n    union all\n    select\n      '{{ information_schema.database }}' as database,\n      viewname as name,\n      schemaname as schema,\n      'view' as type\n    from pg_views\n    where schemaname ilike '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('list_relations_without_caching').table) }}\n{% endmacro %}\n\n{% macro postgres__information_schema_name(database) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  information_schema\n{%- endmacro %}\n\n{% macro postgres__list_schemas(database) %}\n  {% if database -%}\n    {{ adapter.verify_database(database) }}\n  {%- endif -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    select distinct nspname from pg_namespace\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}\n\n{% macro postgres__check_schema_exists(information_schema, schema) -%}\n  {% if information_schema.database -%}\n    {{ adapter.verify_database(information_schema.database) }}\n  {%- endif -%}\n  {% call statement('check_schema_exists', fetch_result=True, auto_begin=False) %}\n    select count(*) from pg_namespace where nspname = '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('check_schema_exists').table) }}\n{% endmacro %}\n\n\n{% macro postgres__current_timestamp() -%}\n  now()\n{%- endmacro %}\n\n{% macro postgres__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp without time zone\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro postgres__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp without time zone\n{%- endmacro %}\n\n{% macro postgres__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix ~ py_current_timestring() %}\n    {% do return(base_relation.incorporate(\n                                  path={\n                                    \"identifier\": tmp_identifier,\n                                    \"schema\": none,\n                                    \"database\": none\n                                  })) -%}\n{% endmacro %}", "unique_id": "macro.dbt_postgres.postgres__list_schemas", "package_name": "dbt_postgres", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "postgres__list_schemas", "macro_sql": "{% macro postgres__list_schemas(database) %}\n  {% if database -%}\n    {{ adapter.verify_database(database) }}\n  {%- endif -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    select distinct nspname from pg_namespace\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_postgres.postgres__check_schema_exists": {"raw_sql": "{% macro postgres__create_table_as(temporary, relation, sql) -%}\n  {%- set unlogged = config.get('unlogged', default=false) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}\n    temporary\n  {%- elif unlogged -%}\n    unlogged\n  {%- endif %} table {{ relation }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n{% macro postgres__create_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ schema_name }}\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__drop_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ schema_name }} cascade\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      select\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n      from {{ relation.information_schema('columns') }}\n      where table_name = '{{ relation.identifier }}'\n        {% if relation.schema %}\n        and table_schema = '{{ relation.schema }}'\n        {% endif %}\n      order by ordinal_position\n\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro postgres__list_relations_without_caching(information_schema, schema) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    select\n      '{{ information_schema.database }}' as database,\n      tablename as name,\n      schemaname as schema,\n      'table' as type\n    from pg_tables\n    where schemaname ilike '{{ schema }}'\n    union all\n    select\n      '{{ information_schema.database }}' as database,\n      viewname as name,\n      schemaname as schema,\n      'view' as type\n    from pg_views\n    where schemaname ilike '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('list_relations_without_caching').table) }}\n{% endmacro %}\n\n{% macro postgres__information_schema_name(database) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  information_schema\n{%- endmacro %}\n\n{% macro postgres__list_schemas(database) %}\n  {% if database -%}\n    {{ adapter.verify_database(database) }}\n  {%- endif -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    select distinct nspname from pg_namespace\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}\n\n{% macro postgres__check_schema_exists(information_schema, schema) -%}\n  {% if information_schema.database -%}\n    {{ adapter.verify_database(information_schema.database) }}\n  {%- endif -%}\n  {% call statement('check_schema_exists', fetch_result=True, auto_begin=False) %}\n    select count(*) from pg_namespace where nspname = '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('check_schema_exists').table) }}\n{% endmacro %}\n\n\n{% macro postgres__current_timestamp() -%}\n  now()\n{%- endmacro %}\n\n{% macro postgres__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp without time zone\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro postgres__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp without time zone\n{%- endmacro %}\n\n{% macro postgres__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix ~ py_current_timestring() %}\n    {% do return(base_relation.incorporate(\n                                  path={\n                                    \"identifier\": tmp_identifier,\n                                    \"schema\": none,\n                                    \"database\": none\n                                  })) -%}\n{% endmacro %}", "unique_id": "macro.dbt_postgres.postgres__check_schema_exists", "package_name": "dbt_postgres", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "postgres__check_schema_exists", "macro_sql": "{% macro postgres__check_schema_exists(information_schema, schema) -%}\n  {% if information_schema.database -%}\n    {{ adapter.verify_database(information_schema.database) }}\n  {%- endif -%}\n  {% call statement('check_schema_exists', fetch_result=True, auto_begin=False) %}\n    select count(*) from pg_namespace where nspname = '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('check_schema_exists').table) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_postgres.postgres__current_timestamp": {"raw_sql": "{% macro postgres__create_table_as(temporary, relation, sql) -%}\n  {%- set unlogged = config.get('unlogged', default=false) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}\n    temporary\n  {%- elif unlogged -%}\n    unlogged\n  {%- endif %} table {{ relation }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n{% macro postgres__create_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ schema_name }}\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__drop_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ schema_name }} cascade\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      select\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n      from {{ relation.information_schema('columns') }}\n      where table_name = '{{ relation.identifier }}'\n        {% if relation.schema %}\n        and table_schema = '{{ relation.schema }}'\n        {% endif %}\n      order by ordinal_position\n\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro postgres__list_relations_without_caching(information_schema, schema) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    select\n      '{{ information_schema.database }}' as database,\n      tablename as name,\n      schemaname as schema,\n      'table' as type\n    from pg_tables\n    where schemaname ilike '{{ schema }}'\n    union all\n    select\n      '{{ information_schema.database }}' as database,\n      viewname as name,\n      schemaname as schema,\n      'view' as type\n    from pg_views\n    where schemaname ilike '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('list_relations_without_caching').table) }}\n{% endmacro %}\n\n{% macro postgres__information_schema_name(database) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  information_schema\n{%- endmacro %}\n\n{% macro postgres__list_schemas(database) %}\n  {% if database -%}\n    {{ adapter.verify_database(database) }}\n  {%- endif -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    select distinct nspname from pg_namespace\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}\n\n{% macro postgres__check_schema_exists(information_schema, schema) -%}\n  {% if information_schema.database -%}\n    {{ adapter.verify_database(information_schema.database) }}\n  {%- endif -%}\n  {% call statement('check_schema_exists', fetch_result=True, auto_begin=False) %}\n    select count(*) from pg_namespace where nspname = '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('check_schema_exists').table) }}\n{% endmacro %}\n\n\n{% macro postgres__current_timestamp() -%}\n  now()\n{%- endmacro %}\n\n{% macro postgres__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp without time zone\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro postgres__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp without time zone\n{%- endmacro %}\n\n{% macro postgres__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix ~ py_current_timestring() %}\n    {% do return(base_relation.incorporate(\n                                  path={\n                                    \"identifier\": tmp_identifier,\n                                    \"schema\": none,\n                                    \"database\": none\n                                  })) -%}\n{% endmacro %}", "unique_id": "macro.dbt_postgres.postgres__current_timestamp", "package_name": "dbt_postgres", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "postgres__current_timestamp", "macro_sql": "{% macro postgres__current_timestamp() -%}\n  now()\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_postgres.postgres__snapshot_string_as_time": {"raw_sql": "{% macro postgres__create_table_as(temporary, relation, sql) -%}\n  {%- set unlogged = config.get('unlogged', default=false) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}\n    temporary\n  {%- elif unlogged -%}\n    unlogged\n  {%- endif %} table {{ relation }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n{% macro postgres__create_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ schema_name }}\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__drop_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ schema_name }} cascade\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      select\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n      from {{ relation.information_schema('columns') }}\n      where table_name = '{{ relation.identifier }}'\n        {% if relation.schema %}\n        and table_schema = '{{ relation.schema }}'\n        {% endif %}\n      order by ordinal_position\n\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro postgres__list_relations_without_caching(information_schema, schema) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    select\n      '{{ information_schema.database }}' as database,\n      tablename as name,\n      schemaname as schema,\n      'table' as type\n    from pg_tables\n    where schemaname ilike '{{ schema }}'\n    union all\n    select\n      '{{ information_schema.database }}' as database,\n      viewname as name,\n      schemaname as schema,\n      'view' as type\n    from pg_views\n    where schemaname ilike '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('list_relations_without_caching').table) }}\n{% endmacro %}\n\n{% macro postgres__information_schema_name(database) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  information_schema\n{%- endmacro %}\n\n{% macro postgres__list_schemas(database) %}\n  {% if database -%}\n    {{ adapter.verify_database(database) }}\n  {%- endif -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    select distinct nspname from pg_namespace\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}\n\n{% macro postgres__check_schema_exists(information_schema, schema) -%}\n  {% if information_schema.database -%}\n    {{ adapter.verify_database(information_schema.database) }}\n  {%- endif -%}\n  {% call statement('check_schema_exists', fetch_result=True, auto_begin=False) %}\n    select count(*) from pg_namespace where nspname = '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('check_schema_exists').table) }}\n{% endmacro %}\n\n\n{% macro postgres__current_timestamp() -%}\n  now()\n{%- endmacro %}\n\n{% macro postgres__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp without time zone\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro postgres__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp without time zone\n{%- endmacro %}\n\n{% macro postgres__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix ~ py_current_timestring() %}\n    {% do return(base_relation.incorporate(\n                                  path={\n                                    \"identifier\": tmp_identifier,\n                                    \"schema\": none,\n                                    \"database\": none\n                                  })) -%}\n{% endmacro %}", "unique_id": "macro.dbt_postgres.postgres__snapshot_string_as_time", "package_name": "dbt_postgres", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "postgres__snapshot_string_as_time", "macro_sql": "{% macro postgres__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp without time zone\" -%}\n    {{ return(result) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_postgres.postgres__snapshot_get_time": {"raw_sql": "{% macro postgres__create_table_as(temporary, relation, sql) -%}\n  {%- set unlogged = config.get('unlogged', default=false) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}\n    temporary\n  {%- elif unlogged -%}\n    unlogged\n  {%- endif %} table {{ relation }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n{% macro postgres__create_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ schema_name }}\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__drop_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ schema_name }} cascade\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      select\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n      from {{ relation.information_schema('columns') }}\n      where table_name = '{{ relation.identifier }}'\n        {% if relation.schema %}\n        and table_schema = '{{ relation.schema }}'\n        {% endif %}\n      order by ordinal_position\n\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro postgres__list_relations_without_caching(information_schema, schema) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    select\n      '{{ information_schema.database }}' as database,\n      tablename as name,\n      schemaname as schema,\n      'table' as type\n    from pg_tables\n    where schemaname ilike '{{ schema }}'\n    union all\n    select\n      '{{ information_schema.database }}' as database,\n      viewname as name,\n      schemaname as schema,\n      'view' as type\n    from pg_views\n    where schemaname ilike '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('list_relations_without_caching').table) }}\n{% endmacro %}\n\n{% macro postgres__information_schema_name(database) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  information_schema\n{%- endmacro %}\n\n{% macro postgres__list_schemas(database) %}\n  {% if database -%}\n    {{ adapter.verify_database(database) }}\n  {%- endif -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    select distinct nspname from pg_namespace\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}\n\n{% macro postgres__check_schema_exists(information_schema, schema) -%}\n  {% if information_schema.database -%}\n    {{ adapter.verify_database(information_schema.database) }}\n  {%- endif -%}\n  {% call statement('check_schema_exists', fetch_result=True, auto_begin=False) %}\n    select count(*) from pg_namespace where nspname = '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('check_schema_exists').table) }}\n{% endmacro %}\n\n\n{% macro postgres__current_timestamp() -%}\n  now()\n{%- endmacro %}\n\n{% macro postgres__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp without time zone\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro postgres__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp without time zone\n{%- endmacro %}\n\n{% macro postgres__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix ~ py_current_timestring() %}\n    {% do return(base_relation.incorporate(\n                                  path={\n                                    \"identifier\": tmp_identifier,\n                                    \"schema\": none,\n                                    \"database\": none\n                                  })) -%}\n{% endmacro %}", "unique_id": "macro.dbt_postgres.postgres__snapshot_get_time", "package_name": "dbt_postgres", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "postgres__snapshot_get_time", "macro_sql": "{% macro postgres__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp without time zone\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_postgres.postgres__make_temp_relation": {"raw_sql": "{% macro postgres__create_table_as(temporary, relation, sql) -%}\n  {%- set unlogged = config.get('unlogged', default=false) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary -%}\n    temporary\n  {%- elif unlogged -%}\n    unlogged\n  {%- endif %} table {{ relation }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}\n\n{% macro postgres__create_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ schema_name }}\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__drop_schema(database_name, schema_name) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ schema_name }} cascade\n  {%- endcall -%}\n{% endmacro %}\n\n{% macro postgres__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      select\n          column_name,\n          data_type,\n          character_maximum_length,\n          numeric_precision,\n          numeric_scale\n\n      from {{ relation.information_schema('columns') }}\n      where table_name = '{{ relation.identifier }}'\n        {% if relation.schema %}\n        and table_schema = '{{ relation.schema }}'\n        {% endif %}\n      order by ordinal_position\n\n  {% endcall %}\n  {% set table = load_result('get_columns_in_relation').table %}\n  {{ return(sql_convert_columns_in_relation(table)) }}\n{% endmacro %}\n\n\n{% macro postgres__list_relations_without_caching(information_schema, schema) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    select\n      '{{ information_schema.database }}' as database,\n      tablename as name,\n      schemaname as schema,\n      'table' as type\n    from pg_tables\n    where schemaname ilike '{{ schema }}'\n    union all\n    select\n      '{{ information_schema.database }}' as database,\n      viewname as name,\n      schemaname as schema,\n      'view' as type\n    from pg_views\n    where schemaname ilike '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('list_relations_without_caching').table) }}\n{% endmacro %}\n\n{% macro postgres__information_schema_name(database) -%}\n  {% if database_name -%}\n    {{ adapter.verify_database(database_name) }}\n  {%- endif -%}\n  information_schema\n{%- endmacro %}\n\n{% macro postgres__list_schemas(database) %}\n  {% if database -%}\n    {{ adapter.verify_database(database) }}\n  {%- endif -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    select distinct nspname from pg_namespace\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}\n\n{% macro postgres__check_schema_exists(information_schema, schema) -%}\n  {% if information_schema.database -%}\n    {{ adapter.verify_database(information_schema.database) }}\n  {%- endif -%}\n  {% call statement('check_schema_exists', fetch_result=True, auto_begin=False) %}\n    select count(*) from pg_namespace where nspname = '{{ schema }}'\n  {% endcall %}\n  {{ return(load_result('check_schema_exists').table) }}\n{% endmacro %}\n\n\n{% macro postgres__current_timestamp() -%}\n  now()\n{%- endmacro %}\n\n{% macro postgres__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"'\" ~ timestamp ~ \"'::timestamp without time zone\" -%}\n    {{ return(result) }}\n{%- endmacro %}\n\n\n{% macro postgres__snapshot_get_time() -%}\n  {{ current_timestamp() }}::timestamp without time zone\n{%- endmacro %}\n\n{% macro postgres__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix ~ py_current_timestring() %}\n    {% do return(base_relation.incorporate(\n                                  path={\n                                    \"identifier\": tmp_identifier,\n                                    \"schema\": none,\n                                    \"database\": none\n                                  })) -%}\n{% endmacro %}", "unique_id": "macro.dbt_postgres.postgres__make_temp_relation", "package_name": "dbt_postgres", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "resource_type": "macro", "name": "postgres__make_temp_relation", "macro_sql": "{% macro postgres__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix ~ py_current_timestring() %}\n    {% do return(base_relation.incorporate(\n                                  path={\n                                    \"identifier\": tmp_identifier,\n                                    \"schema\": none,\n                                    \"database\": none\n                                  })) -%}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_postgres.postgres__snapshot_merge_sql": {"raw_sql": "{% macro postgres__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set insert_cols_csv = insert_cols | join(', ') -%}\n\n    update {{ target }}\n    set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to\n    from {{ source }} as DBT_INTERNAL_SOURCE\n    where DBT_INTERNAL_SOURCE.dbt_scd_id::text = {{ target }}.dbt_scd_id::text\n      and DBT_INTERNAL_SOURCE.dbt_change_type::text = 'update'::text\n      and {{ target }}.dbt_valid_to is null;\n\n    insert into {{ target }} ({{ insert_cols_csv }})\n    select {% for column in insert_cols -%}\n        DBT_INTERNAL_SOURCE.{{ column }} {%- if not loop.last %}, {%- endif %}\n    {%- endfor %}\n    from {{ source }} as DBT_INTERNAL_SOURCE\n    where DBT_INTERNAL_SOURCE.dbt_change_type::text = 'insert'::text;\n{% endmacro %}", "unique_id": "macro.dbt_postgres.postgres__snapshot_merge_sql", "package_name": "dbt_postgres", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres", "path": "macros/materializations/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshot_merge.sql", "resource_type": "macro", "name": "postgres__snapshot_merge_sql", "macro_sql": "{% macro postgres__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set insert_cols_csv = insert_cols | join(', ') -%}\n\n    update {{ target }}\n    set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to\n    from {{ source }} as DBT_INTERNAL_SOURCE\n    where DBT_INTERNAL_SOURCE.dbt_scd_id::text = {{ target }}.dbt_scd_id::text\n      and DBT_INTERNAL_SOURCE.dbt_change_type::text = 'update'::text\n      and {{ target }}.dbt_valid_to is null;\n\n    insert into {{ target }} ({{ insert_cols_csv }})\n    select {% for column in insert_cols -%}\n        DBT_INTERNAL_SOURCE.{{ column }} {%- if not loop.last %}, {%- endif %}\n    {%- endfor %}\n    from {{ source }} as DBT_INTERNAL_SOURCE\n    where DBT_INTERNAL_SOURCE.dbt_change_type::text = 'insert'::text;\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.except": {"raw_sql": "{% macro except() %}\n  {{ adapter_macro('dbt_utils.except') }}\n{% endmacro %}\n\n\n{% macro default__except() %}\n\n    except\n\n{% endmacro %}\n    \n{% macro bigquery__except() %}\n\n    except distinct\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.except", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/except.sql", "original_file_path": "macros/cross_db_utils/except.sql", "resource_type": "macro", "name": "except", "macro_sql": "{% macro except() %}\n  {{ adapter_macro('dbt_utils.except') }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__except": {"raw_sql": "{% macro except() %}\n  {{ adapter_macro('dbt_utils.except') }}\n{% endmacro %}\n\n\n{% macro default__except() %}\n\n    except\n\n{% endmacro %}\n    \n{% macro bigquery__except() %}\n\n    except distinct\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__except", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/except.sql", "original_file_path": "macros/cross_db_utils/except.sql", "resource_type": "macro", "name": "default__except", "macro_sql": "{% macro default__except() %}\n\n    except\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__except": {"raw_sql": "{% macro except() %}\n  {{ adapter_macro('dbt_utils.except') }}\n{% endmacro %}\n\n\n{% macro default__except() %}\n\n    except\n\n{% endmacro %}\n    \n{% macro bigquery__except() %}\n\n    except distinct\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__except", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/except.sql", "original_file_path": "macros/cross_db_utils/except.sql", "resource_type": "macro", "name": "bigquery__except", "macro_sql": "{% macro bigquery__except() %}\n\n    except distinct\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.replace": {"raw_sql": "{% macro replace(field, old_chars, new_chars) -%}\n    {{ adapter_macro('dbt_utils.replace', field, old_chars, new_chars) }}\n{% endmacro %}\n\n\n{% macro default__replace(field, old_chars, new_chars) %}\n\n    replace(\n        {{ field }},\n        {{ old_chars }},\n        {{ new_chars }}\n    )\n    \n\n{% endmacro %}", "unique_id": "macro.dbt_utils.replace", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/replace.sql", "original_file_path": "macros/cross_db_utils/replace.sql", "resource_type": "macro", "name": "replace", "macro_sql": "{% macro replace(field, old_chars, new_chars) -%}\n    {{ adapter_macro('dbt_utils.replace', field, old_chars, new_chars) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__replace": {"raw_sql": "{% macro replace(field, old_chars, new_chars) -%}\n    {{ adapter_macro('dbt_utils.replace', field, old_chars, new_chars) }}\n{% endmacro %}\n\n\n{% macro default__replace(field, old_chars, new_chars) %}\n\n    replace(\n        {{ field }},\n        {{ old_chars }},\n        {{ new_chars }}\n    )\n    \n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__replace", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/replace.sql", "original_file_path": "macros/cross_db_utils/replace.sql", "resource_type": "macro", "name": "default__replace", "macro_sql": "{% macro default__replace(field, old_chars, new_chars) %}\n\n    replace(\n        {{ field }},\n        {{ old_chars }},\n        {{ new_chars }}\n    )\n    \n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.concat": {"raw_sql": "{% macro concat(fields) %}\n  {{ adapter_macro('dbt_utils.concat', fields) }}\n{% endmacro %}\n\n\n{% macro default__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}\n\n\n{% macro alternative_concat(fields) %}\n    {{ fields|join(' || ') }}\n{% endmacro %}\n\n\n{% macro redshift__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}\n\n\n{% macro snowflake__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.concat", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/concat.sql", "original_file_path": "macros/cross_db_utils/concat.sql", "resource_type": "macro", "name": "concat", "macro_sql": "{% macro concat(fields) %}\n  {{ adapter_macro('dbt_utils.concat', fields) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__concat": {"raw_sql": "{% macro concat(fields) %}\n  {{ adapter_macro('dbt_utils.concat', fields) }}\n{% endmacro %}\n\n\n{% macro default__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}\n\n\n{% macro alternative_concat(fields) %}\n    {{ fields|join(' || ') }}\n{% endmacro %}\n\n\n{% macro redshift__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}\n\n\n{% macro snowflake__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__concat", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/concat.sql", "original_file_path": "macros/cross_db_utils/concat.sql", "resource_type": "macro", "name": "default__concat", "macro_sql": "{% macro default__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.alternative_concat": {"raw_sql": "{% macro concat(fields) %}\n  {{ adapter_macro('dbt_utils.concat', fields) }}\n{% endmacro %}\n\n\n{% macro default__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}\n\n\n{% macro alternative_concat(fields) %}\n    {{ fields|join(' || ') }}\n{% endmacro %}\n\n\n{% macro redshift__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}\n\n\n{% macro snowflake__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.alternative_concat", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/concat.sql", "original_file_path": "macros/cross_db_utils/concat.sql", "resource_type": "macro", "name": "alternative_concat", "macro_sql": "{% macro alternative_concat(fields) %}\n    {{ fields|join(' || ') }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__concat": {"raw_sql": "{% macro concat(fields) %}\n  {{ adapter_macro('dbt_utils.concat', fields) }}\n{% endmacro %}\n\n\n{% macro default__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}\n\n\n{% macro alternative_concat(fields) %}\n    {{ fields|join(' || ') }}\n{% endmacro %}\n\n\n{% macro redshift__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}\n\n\n{% macro snowflake__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.redshift__concat", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/concat.sql", "original_file_path": "macros/cross_db_utils/concat.sql", "resource_type": "macro", "name": "redshift__concat", "macro_sql": "{% macro redshift__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__concat": {"raw_sql": "{% macro concat(fields) %}\n  {{ adapter_macro('dbt_utils.concat', fields) }}\n{% endmacro %}\n\n\n{% macro default__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}\n\n\n{% macro alternative_concat(fields) %}\n    {{ fields|join(' || ') }}\n{% endmacro %}\n\n\n{% macro redshift__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}\n\n\n{% macro snowflake__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.snowflake__concat", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/concat.sql", "original_file_path": "macros/cross_db_utils/concat.sql", "resource_type": "macro", "name": "snowflake__concat", "macro_sql": "{% macro snowflake__concat(fields) %}\n    {{dbt_utils.alternative_concat(fields)}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.identifier": {"raw_sql": "{% macro identifier(value) %}\n  {{ adapter_macro('dbt_utils.identifier', value) }}\n{% endmacro %}\n\n{% macro default__identifier(value) -%}\n    \"{{ value }}\"\n{%- endmacro %}\n\n{% macro bigquery__identifier(value) -%}\n    `{{ value }}`\n{%- endmacro %}", "unique_id": "macro.dbt_utils.identifier", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/identifer.sql", "original_file_path": "macros/cross_db_utils/identifer.sql", "resource_type": "macro", "name": "identifier", "macro_sql": "{% macro identifier(value) %}\n  {{ adapter_macro('dbt_utils.identifier', value) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__identifier": {"raw_sql": "{% macro identifier(value) %}\n  {{ adapter_macro('dbt_utils.identifier', value) }}\n{% endmacro %}\n\n{% macro default__identifier(value) -%}\n    \"{{ value }}\"\n{%- endmacro %}\n\n{% macro bigquery__identifier(value) -%}\n    `{{ value }}`\n{%- endmacro %}", "unique_id": "macro.dbt_utils.default__identifier", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/identifer.sql", "original_file_path": "macros/cross_db_utils/identifer.sql", "resource_type": "macro", "name": "default__identifier", "macro_sql": "{% macro default__identifier(value) -%}\n    \"{{ value }}\"\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__identifier": {"raw_sql": "{% macro identifier(value) %}\n  {{ adapter_macro('dbt_utils.identifier', value) }}\n{% endmacro %}\n\n{% macro default__identifier(value) -%}\n    \"{{ value }}\"\n{%- endmacro %}\n\n{% macro bigquery__identifier(value) -%}\n    `{{ value }}`\n{%- endmacro %}", "unique_id": "macro.dbt_utils.bigquery__identifier", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/identifer.sql", "original_file_path": "macros/cross_db_utils/identifer.sql", "resource_type": "macro", "name": "bigquery__identifier", "macro_sql": "{% macro bigquery__identifier(value) -%}\n    `{{ value }}`\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_string": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.type_string", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "type_string", "macro_sql": "{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_string": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__type_string", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "default__type_string", "macro_sql": "{% macro default__type_string() %}\n    string\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__type_string": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.redshift__type_string", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "redshift__type_string", "macro_sql": "\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__type_string": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.postgres__type_string", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "postgres__type_string", "macro_sql": "{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__type_string": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.snowflake__type_string", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "snowflake__type_string", "macro_sql": "{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_timestamp": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.type_timestamp", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "type_timestamp", "macro_sql": "{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_timestamp": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__type_timestamp", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "default__type_timestamp", "macro_sql": "{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__type_timestamp": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.snowflake__type_timestamp", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "snowflake__type_timestamp", "macro_sql": "{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_float": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.type_float", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "type_float", "macro_sql": "{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_float": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__type_float", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "default__type_float", "macro_sql": "{% macro default__type_float() %}\n    float\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_float": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__type_float", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "bigquery__type_float", "macro_sql": "{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_numeric": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.type_numeric", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "type_numeric", "macro_sql": "{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_numeric": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__type_numeric", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "default__type_numeric", "macro_sql": "{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_numeric": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__type_numeric", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "bigquery__type_numeric", "macro_sql": "{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_bigint": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.type_bigint", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "type_bigint", "macro_sql": "{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_bigint": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__type_bigint", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "default__type_bigint", "macro_sql": "{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_bigint": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__type_bigint", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "bigquery__type_bigint", "macro_sql": "{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_int": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.type_int", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "type_int", "macro_sql": "{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_int": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__type_int", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "default__type_int", "macro_sql": "{% macro default__type_int() %}\n    int\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_int": {"raw_sql": "{# string  -------------------------------------------------     #}\n\n{% macro type_string() %}\n  {{ adapter_macro('dbt_utils.type_string') }}\n{% endmacro %}\n\n{% macro default__type_string() %}\n    string\n{% endmacro %}\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}\n\n{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}\n\n\n\n{# timestamp  -------------------------------------------------     #}\n\n{% macro type_timestamp() %}\n  {{ adapter_macro('dbt_utils.type_timestamp') }}\n{% endmacro %}\n\n{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}\n\n{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}\n\n\n{# float  -------------------------------------------------     #}\n\n{% macro type_float() %}\n  {{ adapter_macro('dbt_utils.type_float') }}\n{% endmacro %}\n\n{% macro default__type_float() %}\n    float\n{% endmacro %}\n\n{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}\n\n{# numeric  ------------------------------------------------     #}\n\n{% macro type_numeric() %}\n  {{ adapter_macro('dbt_utils.type_numeric') }}\n{% endmacro %}\n\n{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}\n\n{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}\n\n\n{# bigint  -------------------------------------------------     #}\n\n{% macro type_bigint() %}\n  {{ adapter_macro('dbt_utils.type_bigint') }}\n{% endmacro %}\n\n{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}\n\n{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}\n\n{# int  -------------------------------------------------     #}\n\n{% macro type_int() %}\n  {{ adapter_macro('dbt_utils.type_int') }}\n{% endmacro %}\n\n{% macro default__type_int() %}\n    int\n{% endmacro %}\n\n{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__type_int", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "resource_type": "macro", "name": "bigquery__type_int", "macro_sql": "{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils._is_relation": {"raw_sql": "{% macro _is_relation(obj, macro) %}\n    {%- if not (obj is mapping and obj.get('metadata', {}).get('type', '').endswith('Relation')) -%}\n        {%- do exceptions.raise_compiler_error(\"Macro \" ~ macro ~ \" expected a Relation but received the value: \" ~ obj) -%}\n    {%- endif -%}\n{% endmacro %}", "unique_id": "macro.dbt_utils._is_relation", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/_is_relation.sql", "original_file_path": "macros/cross_db_utils/_is_relation.sql", "resource_type": "macro", "name": "_is_relation", "macro_sql": "{% macro _is_relation(obj, macro) %}\n    {%- if not (obj is mapping and obj.get('metadata', {}).get('type', '').endswith('Relation')) -%}\n        {%- do exceptions.raise_compiler_error(\"Macro \" ~ macro ~ \" expected a Relation but received the value: \" ~ obj) -%}\n    {%- endif -%}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.length": {"raw_sql": "{% macro length(expression) -%}\n    {{ adapter_macro('dbt_utils.length', expression) }}\n{% endmacro %}\n\n\n{% macro default__length(expression) %}\n    \n    length(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}\n\n\n{% macro redshift__length(expression) %}\n\n    len(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}", "unique_id": "macro.dbt_utils.length", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/length.sql", "original_file_path": "macros/cross_db_utils/length.sql", "resource_type": "macro", "name": "length", "macro_sql": "{% macro length(expression) -%}\n    {{ adapter_macro('dbt_utils.length', expression) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__length": {"raw_sql": "{% macro length(expression) -%}\n    {{ adapter_macro('dbt_utils.length', expression) }}\n{% endmacro %}\n\n\n{% macro default__length(expression) %}\n    \n    length(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}\n\n\n{% macro redshift__length(expression) %}\n\n    len(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}", "unique_id": "macro.dbt_utils.default__length", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/length.sql", "original_file_path": "macros/cross_db_utils/length.sql", "resource_type": "macro", "name": "default__length", "macro_sql": "{% macro default__length(expression) %}\n    \n    length(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}\n\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__length": {"raw_sql": "{% macro length(expression) -%}\n    {{ adapter_macro('dbt_utils.length', expression) }}\n{% endmacro %}\n\n\n{% macro default__length(expression) %}\n    \n    length(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}\n\n\n{% macro redshift__length(expression) %}\n\n    len(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}", "unique_id": "macro.dbt_utils.redshift__length", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/length.sql", "original_file_path": "macros/cross_db_utils/length.sql", "resource_type": "macro", "name": "redshift__length", "macro_sql": "{% macro redshift__length(expression) %}\n\n    len(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.dateadd": {"raw_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ adapter_macro('dbt_utils.dateadd', datepart, interval, from_date_or_timestamp) }}\n{% endmacro %}\n\n\n{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n        datetime_add(\n            cast( {{ from_date_or_timestamp }} as datetime),\n        interval {{ interval }} {{ datepart }}\n        )\n\n{% endmacro %}\n\n\n{% macro postgres__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {{ from_date_or_timestamp }} + ((interval '1 {{ datepart }}') * ({{ interval }}))\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.dateadd", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "resource_type": "macro", "name": "dateadd", "macro_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ adapter_macro('dbt_utils.dateadd', datepart, interval, from_date_or_timestamp) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__dateadd": {"raw_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ adapter_macro('dbt_utils.dateadd', datepart, interval, from_date_or_timestamp) }}\n{% endmacro %}\n\n\n{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n        datetime_add(\n            cast( {{ from_date_or_timestamp }} as datetime),\n        interval {{ interval }} {{ datepart }}\n        )\n\n{% endmacro %}\n\n\n{% macro postgres__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {{ from_date_or_timestamp }} + ((interval '1 {{ datepart }}') * ({{ interval }}))\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__dateadd", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "resource_type": "macro", "name": "default__dateadd", "macro_sql": "{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__dateadd": {"raw_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ adapter_macro('dbt_utils.dateadd', datepart, interval, from_date_or_timestamp) }}\n{% endmacro %}\n\n\n{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n        datetime_add(\n            cast( {{ from_date_or_timestamp }} as datetime),\n        interval {{ interval }} {{ datepart }}\n        )\n\n{% endmacro %}\n\n\n{% macro postgres__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {{ from_date_or_timestamp }} + ((interval '1 {{ datepart }}') * ({{ interval }}))\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__dateadd", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "resource_type": "macro", "name": "bigquery__dateadd", "macro_sql": "{% macro bigquery__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n        datetime_add(\n            cast( {{ from_date_or_timestamp }} as datetime),\n        interval {{ interval }} {{ datepart }}\n        )\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__dateadd": {"raw_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ adapter_macro('dbt_utils.dateadd', datepart, interval, from_date_or_timestamp) }}\n{% endmacro %}\n\n\n{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n        datetime_add(\n            cast( {{ from_date_or_timestamp }} as datetime),\n        interval {{ interval }} {{ datepart }}\n        )\n\n{% endmacro %}\n\n\n{% macro postgres__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {{ from_date_or_timestamp }} + ((interval '1 {{ datepart }}') * ({{ interval }}))\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.postgres__dateadd", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "resource_type": "macro", "name": "postgres__dateadd", "macro_sql": "{% macro postgres__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {{ from_date_or_timestamp }} + ((interval '1 {{ datepart }}') * ({{ interval }}))\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.intersect": {"raw_sql": "{% macro intersect() %}\n  {{ adapter_macro('dbt_utils.intersect') }}\n{% endmacro %}\n\n\n{% macro default__intersect() %}\n\n    intersect\n\n{% endmacro %}\n\n{% macro bigquery__intersect() %}\n\n    intersect distinct\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.intersect", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/intersect.sql", "original_file_path": "macros/cross_db_utils/intersect.sql", "resource_type": "macro", "name": "intersect", "macro_sql": "{% macro intersect() %}\n  {{ adapter_macro('dbt_utils.intersect') }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__intersect": {"raw_sql": "{% macro intersect() %}\n  {{ adapter_macro('dbt_utils.intersect') }}\n{% endmacro %}\n\n\n{% macro default__intersect() %}\n\n    intersect\n\n{% endmacro %}\n\n{% macro bigquery__intersect() %}\n\n    intersect distinct\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__intersect", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/intersect.sql", "original_file_path": "macros/cross_db_utils/intersect.sql", "resource_type": "macro", "name": "default__intersect", "macro_sql": "{% macro default__intersect() %}\n\n    intersect\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__intersect": {"raw_sql": "{% macro intersect() %}\n  {{ adapter_macro('dbt_utils.intersect') }}\n{% endmacro %}\n\n\n{% macro default__intersect() %}\n\n    intersect\n\n{% endmacro %}\n\n{% macro bigquery__intersect() %}\n\n    intersect distinct\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__intersect", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/intersect.sql", "original_file_path": "macros/cross_db_utils/intersect.sql", "resource_type": "macro", "name": "bigquery__intersect", "macro_sql": "{% macro bigquery__intersect() %}\n\n    intersect distinct\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.right": {"raw_sql": "{% macro right(string_text, length_expression) -%}\n    {{ adapter_macro('dbt_utils.right', string_text, length_expression) }}\n{% endmacro %}\n\n{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n    \n{%- endmacro -%}\n\n{% macro bigquery__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        substr(\n            {{ string_text }},\n            -1 * ({{ length_expression }})\n        )\n    end\n\n{%- endmacro -%}\n\n{% macro snowflake__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        right(\n            {{ string_text }},\n            {{ length_expression }}\n        )\n    end\n\n{%- endmacro -%}", "unique_id": "macro.dbt_utils.right", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "resource_type": "macro", "name": "right", "macro_sql": "{% macro right(string_text, length_expression) -%}\n    {{ adapter_macro('dbt_utils.right', string_text, length_expression) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__right": {"raw_sql": "{% macro right(string_text, length_expression) -%}\n    {{ adapter_macro('dbt_utils.right', string_text, length_expression) }}\n{% endmacro %}\n\n{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n    \n{%- endmacro -%}\n\n{% macro bigquery__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        substr(\n            {{ string_text }},\n            -1 * ({{ length_expression }})\n        )\n    end\n\n{%- endmacro -%}\n\n{% macro snowflake__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        right(\n            {{ string_text }},\n            {{ length_expression }}\n        )\n    end\n\n{%- endmacro -%}", "unique_id": "macro.dbt_utils.default__right", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "resource_type": "macro", "name": "default__right", "macro_sql": "{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n    \n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__right": {"raw_sql": "{% macro right(string_text, length_expression) -%}\n    {{ adapter_macro('dbt_utils.right', string_text, length_expression) }}\n{% endmacro %}\n\n{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n    \n{%- endmacro -%}\n\n{% macro bigquery__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        substr(\n            {{ string_text }},\n            -1 * ({{ length_expression }})\n        )\n    end\n\n{%- endmacro -%}\n\n{% macro snowflake__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        right(\n            {{ string_text }},\n            {{ length_expression }}\n        )\n    end\n\n{%- endmacro -%}", "unique_id": "macro.dbt_utils.bigquery__right", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "resource_type": "macro", "name": "bigquery__right", "macro_sql": "{% macro bigquery__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        substr(\n            {{ string_text }},\n            -1 * ({{ length_expression }})\n        )\n    end\n\n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__right": {"raw_sql": "{% macro right(string_text, length_expression) -%}\n    {{ adapter_macro('dbt_utils.right', string_text, length_expression) }}\n{% endmacro %}\n\n{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n    \n{%- endmacro -%}\n\n{% macro bigquery__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        substr(\n            {{ string_text }},\n            -1 * ({{ length_expression }})\n        )\n    end\n\n{%- endmacro -%}\n\n{% macro snowflake__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        right(\n            {{ string_text }},\n            {{ length_expression }}\n        )\n    end\n\n{%- endmacro -%}", "unique_id": "macro.dbt_utils.snowflake__right", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "resource_type": "macro", "name": "snowflake__right", "macro_sql": "{% macro snowflake__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        right(\n            {{ string_text }},\n            {{ length_expression }}\n        )\n    end\n\n{%- endmacro -%}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.datediff": {"raw_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ adapter_macro('dbt_utils.datediff', first_date, second_date, datepart) }}\n{% endmacro %}\n\n\n{% macro default__datediff(first_date, second_date, datepart) %}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__datediff(first_date, second_date, datepart) %}\n\n    datetime_diff(\n        cast({{second_date}} as datetime),\n        cast({{first_date}} as datetime),\n        {{datepart}}\n    ) \n\n{% endmacro %}\n\n\n{% macro postgres__datediff(first_date, second_date, datepart) %}\n\n    {{ exceptions.raise_compiler_error(\"macro datediff not implemented for this adapter\") }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.datediff", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "resource_type": "macro", "name": "datediff", "macro_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ adapter_macro('dbt_utils.datediff', first_date, second_date, datepart) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__datediff": {"raw_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ adapter_macro('dbt_utils.datediff', first_date, second_date, datepart) }}\n{% endmacro %}\n\n\n{% macro default__datediff(first_date, second_date, datepart) %}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__datediff(first_date, second_date, datepart) %}\n\n    datetime_diff(\n        cast({{second_date}} as datetime),\n        cast({{first_date}} as datetime),\n        {{datepart}}\n    ) \n\n{% endmacro %}\n\n\n{% macro postgres__datediff(first_date, second_date, datepart) %}\n\n    {{ exceptions.raise_compiler_error(\"macro datediff not implemented for this adapter\") }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__datediff", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "resource_type": "macro", "name": "default__datediff", "macro_sql": "{% macro default__datediff(first_date, second_date, datepart) %}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__datediff": {"raw_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ adapter_macro('dbt_utils.datediff', first_date, second_date, datepart) }}\n{% endmacro %}\n\n\n{% macro default__datediff(first_date, second_date, datepart) %}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__datediff(first_date, second_date, datepart) %}\n\n    datetime_diff(\n        cast({{second_date}} as datetime),\n        cast({{first_date}} as datetime),\n        {{datepart}}\n    ) \n\n{% endmacro %}\n\n\n{% macro postgres__datediff(first_date, second_date, datepart) %}\n\n    {{ exceptions.raise_compiler_error(\"macro datediff not implemented for this adapter\") }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__datediff", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "resource_type": "macro", "name": "bigquery__datediff", "macro_sql": "{% macro bigquery__datediff(first_date, second_date, datepart) %}\n\n    datetime_diff(\n        cast({{second_date}} as datetime),\n        cast({{first_date}} as datetime),\n        {{datepart}}\n    ) \n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__datediff": {"raw_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ adapter_macro('dbt_utils.datediff', first_date, second_date, datepart) }}\n{% endmacro %}\n\n\n{% macro default__datediff(first_date, second_date, datepart) %}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__datediff(first_date, second_date, datepart) %}\n\n    datetime_diff(\n        cast({{second_date}} as datetime),\n        cast({{first_date}} as datetime),\n        {{datepart}}\n    ) \n\n{% endmacro %}\n\n\n{% macro postgres__datediff(first_date, second_date, datepart) %}\n\n    {{ exceptions.raise_compiler_error(\"macro datediff not implemented for this adapter\") }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.postgres__datediff", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "resource_type": "macro", "name": "postgres__datediff", "macro_sql": "{% macro postgres__datediff(first_date, second_date, datepart) %}\n\n    {{ exceptions.raise_compiler_error(\"macro datediff not implemented for this adapter\") }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.safe_cast": {"raw_sql": "{% macro safe_cast(field, type) %}\n  {{ adapter_macro('dbt_utils.safe_cast', field, type) }}\n{% endmacro %}\n\n\n{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro snowflake__safe_cast(field, type) %}\n    try_cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro bigquery__safe_cast(field, type) %}\n    safe_cast({{field}} as {{type}})\n{% endmacro %}", "unique_id": "macro.dbt_utils.safe_cast", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "resource_type": "macro", "name": "safe_cast", "macro_sql": "{% macro safe_cast(field, type) %}\n  {{ adapter_macro('dbt_utils.safe_cast', field, type) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__safe_cast": {"raw_sql": "{% macro safe_cast(field, type) %}\n  {{ adapter_macro('dbt_utils.safe_cast', field, type) }}\n{% endmacro %}\n\n\n{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro snowflake__safe_cast(field, type) %}\n    try_cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro bigquery__safe_cast(field, type) %}\n    safe_cast({{field}} as {{type}})\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__safe_cast", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "resource_type": "macro", "name": "default__safe_cast", "macro_sql": "{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__safe_cast": {"raw_sql": "{% macro safe_cast(field, type) %}\n  {{ adapter_macro('dbt_utils.safe_cast', field, type) }}\n{% endmacro %}\n\n\n{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro snowflake__safe_cast(field, type) %}\n    try_cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro bigquery__safe_cast(field, type) %}\n    safe_cast({{field}} as {{type}})\n{% endmacro %}", "unique_id": "macro.dbt_utils.snowflake__safe_cast", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "resource_type": "macro", "name": "snowflake__safe_cast", "macro_sql": "{% macro snowflake__safe_cast(field, type) %}\n    try_cast({{field}} as {{type}})\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__safe_cast": {"raw_sql": "{% macro safe_cast(field, type) %}\n  {{ adapter_macro('dbt_utils.safe_cast', field, type) }}\n{% endmacro %}\n\n\n{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro snowflake__safe_cast(field, type) %}\n    try_cast({{field}} as {{type}})\n{% endmacro %}\n\n\n{% macro bigquery__safe_cast(field, type) %}\n    safe_cast({{field}} as {{type}})\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__safe_cast", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "resource_type": "macro", "name": "bigquery__safe_cast", "macro_sql": "{% macro bigquery__safe_cast(field, type) %}\n    safe_cast({{field}} as {{type}})\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.hash": {"raw_sql": "{% macro hash(field) -%}\n  {{ adapter_macro('dbt_utils.hash', field) }}\n{%- endmacro %}\n\n\n{% macro default__hash(field) -%}\n    md5(cast({{field}} as {{dbt_utils.type_string()}}))\n{%- endmacro %}\n\n\n{% macro bigquery__hash(field) -%}\n    to_hex({{dbt_utils.default__hash(field)}})\n{%- endmacro %}", "unique_id": "macro.dbt_utils.hash", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/hash.sql", "original_file_path": "macros/cross_db_utils/hash.sql", "resource_type": "macro", "name": "hash", "macro_sql": "{% macro hash(field) -%}\n  {{ adapter_macro('dbt_utils.hash', field) }}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__hash": {"raw_sql": "{% macro hash(field) -%}\n  {{ adapter_macro('dbt_utils.hash', field) }}\n{%- endmacro %}\n\n\n{% macro default__hash(field) -%}\n    md5(cast({{field}} as {{dbt_utils.type_string()}}))\n{%- endmacro %}\n\n\n{% macro bigquery__hash(field) -%}\n    to_hex({{dbt_utils.default__hash(field)}})\n{%- endmacro %}", "unique_id": "macro.dbt_utils.default__hash", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/hash.sql", "original_file_path": "macros/cross_db_utils/hash.sql", "resource_type": "macro", "name": "default__hash", "macro_sql": "{% macro default__hash(field) -%}\n    md5(cast({{field}} as {{dbt_utils.type_string()}}))\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__hash": {"raw_sql": "{% macro hash(field) -%}\n  {{ adapter_macro('dbt_utils.hash', field) }}\n{%- endmacro %}\n\n\n{% macro default__hash(field) -%}\n    md5(cast({{field}} as {{dbt_utils.type_string()}}))\n{%- endmacro %}\n\n\n{% macro bigquery__hash(field) -%}\n    to_hex({{dbt_utils.default__hash(field)}})\n{%- endmacro %}", "unique_id": "macro.dbt_utils.bigquery__hash", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/hash.sql", "original_file_path": "macros/cross_db_utils/hash.sql", "resource_type": "macro", "name": "bigquery__hash", "macro_sql": "{% macro bigquery__hash(field) -%}\n    to_hex({{dbt_utils.default__hash(field)}})\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.position": {"raw_sql": "{% macro position(substring_text, string_text) -%}\n    {{ adapter_macro('dbt_utils.position', substring_text, string_text) }}\n{% endmacro %}\n\n\n{% macro default__position(substring_text, string_text) %}\n\n    position(\n        {{ substring_text }} in {{ string_text }}\n    )\n    \n{%- endmacro -%}\n\n{% macro bigquery__position(substring_text, string_text) %}\n\n    strpos(\n        {{ string_text }},\n        {{ substring_text }}\n        \n    )\n    \n{%- endmacro -%}", "unique_id": "macro.dbt_utils.position", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/position.sql", "original_file_path": "macros/cross_db_utils/position.sql", "resource_type": "macro", "name": "position", "macro_sql": "{% macro position(substring_text, string_text) -%}\n    {{ adapter_macro('dbt_utils.position', substring_text, string_text) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__position": {"raw_sql": "{% macro position(substring_text, string_text) -%}\n    {{ adapter_macro('dbt_utils.position', substring_text, string_text) }}\n{% endmacro %}\n\n\n{% macro default__position(substring_text, string_text) %}\n\n    position(\n        {{ substring_text }} in {{ string_text }}\n    )\n    \n{%- endmacro -%}\n\n{% macro bigquery__position(substring_text, string_text) %}\n\n    strpos(\n        {{ string_text }},\n        {{ substring_text }}\n        \n    )\n    \n{%- endmacro -%}", "unique_id": "macro.dbt_utils.default__position", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/position.sql", "original_file_path": "macros/cross_db_utils/position.sql", "resource_type": "macro", "name": "default__position", "macro_sql": "{% macro default__position(substring_text, string_text) %}\n\n    position(\n        {{ substring_text }} in {{ string_text }}\n    )\n    \n{%- endmacro -%}\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__position": {"raw_sql": "{% macro position(substring_text, string_text) -%}\n    {{ adapter_macro('dbt_utils.position', substring_text, string_text) }}\n{% endmacro %}\n\n\n{% macro default__position(substring_text, string_text) %}\n\n    position(\n        {{ substring_text }} in {{ string_text }}\n    )\n    \n{%- endmacro -%}\n\n{% macro bigquery__position(substring_text, string_text) %}\n\n    strpos(\n        {{ string_text }},\n        {{ substring_text }}\n        \n    )\n    \n{%- endmacro -%}", "unique_id": "macro.dbt_utils.bigquery__position", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/position.sql", "original_file_path": "macros/cross_db_utils/position.sql", "resource_type": "macro", "name": "bigquery__position", "macro_sql": "{% macro bigquery__position(substring_text, string_text) %}\n\n    strpos(\n        {{ string_text }},\n        {{ substring_text }}\n        \n    )\n    \n{%- endmacro -%}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.string_literal": {"raw_sql": "{% macro string_literal(value) %}\n  {{ adapter_macro('dbt_utils.string_literal', value) }}\n{% endmacro %}\n\n{% macro default__string_literal(value) -%}\n    '{{ value }}'\n{%- endmacro %}", "unique_id": "macro.dbt_utils.string_literal", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/literal.sql", "original_file_path": "macros/cross_db_utils/literal.sql", "resource_type": "macro", "name": "string_literal", "macro_sql": "{% macro string_literal(value) %}\n  {{ adapter_macro('dbt_utils.string_literal', value) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__string_literal": {"raw_sql": "{% macro string_literal(value) %}\n  {{ adapter_macro('dbt_utils.string_literal', value) }}\n{% endmacro %}\n\n{% macro default__string_literal(value) -%}\n    '{{ value }}'\n{%- endmacro %}", "unique_id": "macro.dbt_utils.default__string_literal", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/literal.sql", "original_file_path": "macros/cross_db_utils/literal.sql", "resource_type": "macro", "name": "default__string_literal", "macro_sql": "{% macro default__string_literal(value) -%}\n    '{{ value }}'\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.current_timestamp": {"raw_sql": "{% macro current_timestamp() %}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{% endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() %}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{% endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "current_timestamp", "macro_sql": "{% macro current_timestamp() %}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__current_timestamp": {"raw_sql": "{% macro current_timestamp() %}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{% endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() %}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{% endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__current_timestamp": {"raw_sql": "{% macro current_timestamp() %}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{% endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() %}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{% endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.redshift__current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "redshift__current_timestamp", "macro_sql": "{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__current_timestamp": {"raw_sql": "{% macro current_timestamp() %}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{% endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() %}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{% endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "bigquery__current_timestamp", "macro_sql": "{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.current_timestamp_in_utc": {"raw_sql": "{% macro current_timestamp() %}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{% endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() %}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{% endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "current_timestamp_in_utc", "macro_sql": "{% macro current_timestamp_in_utc() %}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__current_timestamp_in_utc": {"raw_sql": "{% macro current_timestamp() %}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{% endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() %}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{% endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "default__current_timestamp_in_utc", "macro_sql": "{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__current_timestamp_in_utc": {"raw_sql": "{% macro current_timestamp() %}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{% endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() %}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{% endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.snowflake__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "snowflake__current_timestamp_in_utc", "macro_sql": "{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__current_timestamp_in_utc": {"raw_sql": "{% macro current_timestamp() %}\n  {{ adapter_macro('dbt_utils.current_timestamp') }}\n{% endmacro %}\n\n{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}\n\n{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}\n\n\n\n{% macro current_timestamp_in_utc() %}\n  {{ adapter_macro('dbt_utils.current_timestamp_in_utc') }}\n{% endmacro %}\n\n{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}\n\n{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}\n\n{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "unique_id": "macro.dbt_utils.postgres__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "resource_type": "macro", "name": "postgres__current_timestamp_in_utc", "macro_sql": "{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.width_bucket": {"raw_sql": "{% macro width_bucket(expr, min_value, max_value, num_buckets) %}\n  {{ adapter_macro('dbt_utils.width_bucket', expr, min_value, max_value, num_buckets) }}\n{% endmacro %}\n\n\n{% macro default__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is eaxtly at the bucket egde\n        case\n            when\n                mod(\n                    {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }},\n                    {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                ) = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro redshift__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is exactly at the bucket edge\n        case\n            when\n                {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }} %\n                {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                 = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro snowflake__width_bucket(expr, min_value, max_value, num_buckets) %}\n    width_bucket({{ expr }}, {{ min_value }}, {{ max_value }}, {{ num_buckets }} )\n{% endmacro %}", "unique_id": "macro.dbt_utils.width_bucket", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "resource_type": "macro", "name": "width_bucket", "macro_sql": "{% macro width_bucket(expr, min_value, max_value, num_buckets) %}\n  {{ adapter_macro('dbt_utils.width_bucket', expr, min_value, max_value, num_buckets) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__width_bucket": {"raw_sql": "{% macro width_bucket(expr, min_value, max_value, num_buckets) %}\n  {{ adapter_macro('dbt_utils.width_bucket', expr, min_value, max_value, num_buckets) }}\n{% endmacro %}\n\n\n{% macro default__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is eaxtly at the bucket egde\n        case\n            when\n                mod(\n                    {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }},\n                    {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                ) = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro redshift__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is exactly at the bucket edge\n        case\n            when\n                {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }} %\n                {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                 = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro snowflake__width_bucket(expr, min_value, max_value, num_buckets) %}\n    width_bucket({{ expr }}, {{ min_value }}, {{ max_value }}, {{ num_buckets }} )\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__width_bucket", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "resource_type": "macro", "name": "default__width_bucket", "macro_sql": "{% macro default__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is eaxtly at the bucket egde\n        case\n            when\n                mod(\n                    {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }},\n                    {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                ) = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__width_bucket": {"raw_sql": "{% macro width_bucket(expr, min_value, max_value, num_buckets) %}\n  {{ adapter_macro('dbt_utils.width_bucket', expr, min_value, max_value, num_buckets) }}\n{% endmacro %}\n\n\n{% macro default__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is eaxtly at the bucket egde\n        case\n            when\n                mod(\n                    {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }},\n                    {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                ) = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro redshift__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is exactly at the bucket edge\n        case\n            when\n                {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }} %\n                {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                 = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro snowflake__width_bucket(expr, min_value, max_value, num_buckets) %}\n    width_bucket({{ expr }}, {{ min_value }}, {{ max_value }}, {{ num_buckets }} )\n{% endmacro %}", "unique_id": "macro.dbt_utils.redshift__width_bucket", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "resource_type": "macro", "name": "redshift__width_bucket", "macro_sql": "{% macro redshift__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is exactly at the bucket edge\n        case\n            when\n                {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }} %\n                {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                 = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__width_bucket": {"raw_sql": "{% macro width_bucket(expr, min_value, max_value, num_buckets) %}\n  {{ adapter_macro('dbt_utils.width_bucket', expr, min_value, max_value, num_buckets) }}\n{% endmacro %}\n\n\n{% macro default__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is eaxtly at the bucket egde\n        case\n            when\n                mod(\n                    {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }},\n                    {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                ) = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro redshift__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is exactly at the bucket edge\n        case\n            when\n                {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }} %\n                {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                 = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro snowflake__width_bucket(expr, min_value, max_value, num_buckets) %}\n    width_bucket({{ expr }}, {{ min_value }}, {{ max_value }}, {{ num_buckets }} )\n{% endmacro %}", "unique_id": "macro.dbt_utils.snowflake__width_bucket", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "resource_type": "macro", "name": "snowflake__width_bucket", "macro_sql": "{% macro snowflake__width_bucket(expr, min_value, max_value, num_buckets) %}\n    width_bucket({{ expr }}, {{ min_value }}, {{ max_value }}, {{ num_buckets }} )\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.last_day": {"raw_sql": "/*\nThis function has been tested with dateparts of month and quarters. Further\ntesting is required to validate that it will work on other dateparts.\n*/\n\n{% macro last_day(date, datepart) %}\n  {{ adapter_macro('dbt_utils.last_day', date, datepart) }}\n{% endmacro %}\n\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt_utils.dateadd('day', '-1',\n        dbt_utils.dateadd(datepart, '1', dbt_utils.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n\n{% macro default__last_day(date, datepart) -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n{%- endmacro %}\n\n\n{% macro postgres__last_day(date, datepart) -%}\n\n    {%- if datepart == 'quarter' -%}\n    {{ exceptions.raise_compiler_error(\n        \"dbt_utils.last_day is not supported for datepart 'quarter' on this adapter\") }}\n    {%- else -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.last_day", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "resource_type": "macro", "name": "last_day", "macro_sql": "{% macro last_day(date, datepart) %}\n  {{ adapter_macro('dbt_utils.last_day', date, datepart) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default_last_day": {"raw_sql": "/*\nThis function has been tested with dateparts of month and quarters. Further\ntesting is required to validate that it will work on other dateparts.\n*/\n\n{% macro last_day(date, datepart) %}\n  {{ adapter_macro('dbt_utils.last_day', date, datepart) }}\n{% endmacro %}\n\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt_utils.dateadd('day', '-1',\n        dbt_utils.dateadd(datepart, '1', dbt_utils.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n\n{% macro default__last_day(date, datepart) -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n{%- endmacro %}\n\n\n{% macro postgres__last_day(date, datepart) -%}\n\n    {%- if datepart == 'quarter' -%}\n    {{ exceptions.raise_compiler_error(\n        \"dbt_utils.last_day is not supported for datepart 'quarter' on this adapter\") }}\n    {%- else -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.default_last_day", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "resource_type": "macro", "name": "default_last_day", "macro_sql": "\n\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt_utils.dateadd('day', '-1',\n        dbt_utils.dateadd(datepart, '1', dbt_utils.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n\n", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__last_day": {"raw_sql": "/*\nThis function has been tested with dateparts of month and quarters. Further\ntesting is required to validate that it will work on other dateparts.\n*/\n\n{% macro last_day(date, datepart) %}\n  {{ adapter_macro('dbt_utils.last_day', date, datepart) }}\n{% endmacro %}\n\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt_utils.dateadd('day', '-1',\n        dbt_utils.dateadd(datepart, '1', dbt_utils.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n\n{% macro default__last_day(date, datepart) -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n{%- endmacro %}\n\n\n{% macro postgres__last_day(date, datepart) -%}\n\n    {%- if datepart == 'quarter' -%}\n    {{ exceptions.raise_compiler_error(\n        \"dbt_utils.last_day is not supported for datepart 'quarter' on this adapter\") }}\n    {%- else -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.default__last_day", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "resource_type": "macro", "name": "default__last_day", "macro_sql": "{% macro default__last_day(date, datepart) -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__last_day": {"raw_sql": "/*\nThis function has been tested with dateparts of month and quarters. Further\ntesting is required to validate that it will work on other dateparts.\n*/\n\n{% macro last_day(date, datepart) %}\n  {{ adapter_macro('dbt_utils.last_day', date, datepart) }}\n{% endmacro %}\n\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt_utils.dateadd('day', '-1',\n        dbt_utils.dateadd(datepart, '1', dbt_utils.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n\n{% macro default__last_day(date, datepart) -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n{%- endmacro %}\n\n\n{% macro postgres__last_day(date, datepart) -%}\n\n    {%- if datepart == 'quarter' -%}\n    {{ exceptions.raise_compiler_error(\n        \"dbt_utils.last_day is not supported for datepart 'quarter' on this adapter\") }}\n    {%- else -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.postgres__last_day", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "resource_type": "macro", "name": "postgres__last_day", "macro_sql": "{% macro postgres__last_day(date, datepart) -%}\n\n    {%- if datepart == 'quarter' -%}\n    {{ exceptions.raise_compiler_error(\n        \"dbt_utils.last_day is not supported for datepart 'quarter' on this adapter\") }}\n    {%- else -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n    {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.split_part": {"raw_sql": "{% macro split_part(string_text, delimiter_text, part_number) %}\n  {{ adapter_macro('dbt_utils.split_part', string_text, delimiter_text, part_number) }}\n{% endmacro %}\n\n\n{% macro default__split_part(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n        {{ part_number }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__split_part(string_text, delimiter_text, part_number) %}\n\n    split(\n        {{ string_text }},\n        {{ delimiter_text }}\n        )[safe_offset({{ part_number - 1 }})]\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.split_part", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/split_part.sql", "original_file_path": "macros/cross_db_utils/split_part.sql", "resource_type": "macro", "name": "split_part", "macro_sql": "{% macro split_part(string_text, delimiter_text, part_number) %}\n  {{ adapter_macro('dbt_utils.split_part', string_text, delimiter_text, part_number) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__split_part": {"raw_sql": "{% macro split_part(string_text, delimiter_text, part_number) %}\n  {{ adapter_macro('dbt_utils.split_part', string_text, delimiter_text, part_number) }}\n{% endmacro %}\n\n\n{% macro default__split_part(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n        {{ part_number }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__split_part(string_text, delimiter_text, part_number) %}\n\n    split(\n        {{ string_text }},\n        {{ delimiter_text }}\n        )[safe_offset({{ part_number - 1 }})]\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__split_part", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/split_part.sql", "original_file_path": "macros/cross_db_utils/split_part.sql", "resource_type": "macro", "name": "default__split_part", "macro_sql": "{% macro default__split_part(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n        {{ part_number }}\n        )\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__split_part": {"raw_sql": "{% macro split_part(string_text, delimiter_text, part_number) %}\n  {{ adapter_macro('dbt_utils.split_part', string_text, delimiter_text, part_number) }}\n{% endmacro %}\n\n\n{% macro default__split_part(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n        {{ part_number }}\n        )\n\n{% endmacro %}\n\n\n{% macro bigquery__split_part(string_text, delimiter_text, part_number) %}\n\n    split(\n        {{ string_text }},\n        {{ delimiter_text }}\n        )[safe_offset({{ part_number - 1 }})]\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__split_part", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/split_part.sql", "original_file_path": "macros/cross_db_utils/split_part.sql", "resource_type": "macro", "name": "bigquery__split_part", "macro_sql": "{% macro bigquery__split_part(string_text, delimiter_text, part_number) %}\n\n    split(\n        {{ string_text }},\n        {{ delimiter_text }}\n        )[safe_offset({{ part_number - 1 }})]\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.date_trunc": {"raw_sql": "{% macro date_trunc(datepart, date) %}\n  {{ adapter_macro('dbt_utils.date_trunc', datepart, date) }}\n{% endmacro %}\n\n{% macro default__date_trunc(datepart, date) %}\n    date_trunc('{{datepart}}', {{date}})\n{% endmacro %}\n\n{% macro bigquery__date_trunc(datepart, date) %}\n    timestamp_trunc(\n        cast({{date}} as timestamp), \n        {{datepart}}\n    )\n    \n\n{% endmacro %}", "unique_id": "macro.dbt_utils.date_trunc", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/date_trunc.sql", "original_file_path": "macros/cross_db_utils/date_trunc.sql", "resource_type": "macro", "name": "date_trunc", "macro_sql": "{% macro date_trunc(datepart, date) %}\n  {{ adapter_macro('dbt_utils.date_trunc', datepart, date) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__date_trunc": {"raw_sql": "{% macro date_trunc(datepart, date) %}\n  {{ adapter_macro('dbt_utils.date_trunc', datepart, date) }}\n{% endmacro %}\n\n{% macro default__date_trunc(datepart, date) %}\n    date_trunc('{{datepart}}', {{date}})\n{% endmacro %}\n\n{% macro bigquery__date_trunc(datepart, date) %}\n    timestamp_trunc(\n        cast({{date}} as timestamp), \n        {{datepart}}\n    )\n    \n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__date_trunc", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/date_trunc.sql", "original_file_path": "macros/cross_db_utils/date_trunc.sql", "resource_type": "macro", "name": "default__date_trunc", "macro_sql": "{% macro default__date_trunc(datepart, date) %}\n    date_trunc('{{datepart}}', {{date}})\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__date_trunc": {"raw_sql": "{% macro date_trunc(datepart, date) %}\n  {{ adapter_macro('dbt_utils.date_trunc', datepart, date) }}\n{% endmacro %}\n\n{% macro default__date_trunc(datepart, date) %}\n    date_trunc('{{datepart}}', {{date}})\n{% endmacro %}\n\n{% macro bigquery__date_trunc(datepart, date) %}\n    timestamp_trunc(\n        cast({{date}} as timestamp), \n        {{datepart}}\n    )\n    \n\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__date_trunc", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/cross_db_utils/date_trunc.sql", "original_file_path": "macros/cross_db_utils/date_trunc.sql", "resource_type": "macro", "name": "bigquery__date_trunc", "macro_sql": "{% macro bigquery__date_trunc(datepart, date) %}\n    timestamp_trunc(\n        cast({{date}} as timestamp), \n        {{datepart}}\n    )\n    \n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_period_boundaries": {"raw_sql": "{% macro get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n  {% call statement('period_boundaries', fetch_result=True) -%}\n    with data as (\n      select\n          coalesce(max(\"{{timestamp_field}}\"), '{{start_date}}')::timestamp as start_timestamp,\n          coalesce(\n            {{dbt_utils.dateadd('millisecond',\n                                -1,\n                                \"nullif('\" ~ stop_date ~ \"','')::timestamp\")}},\n            {{dbt_utils.current_timestamp()}}\n          ) as stop_timestamp\n      from \"{{target_schema}}\".\"{{target_table}}\"\n    )\n\n    select\n      start_timestamp,\n      stop_timestamp,\n      {{dbt_utils.datediff('start_timestamp',\n                           'stop_timestamp',\n                           period)}}  + 1 as num_periods\n    from data\n  {%- endcall %}\n\n{%- endmacro %}\n\n{% macro get_period_sql(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n  {%- set period_filter -%}\n    (\"{{timestamp_field}}\" >  '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' and\n     \"{{timestamp_field}}\" <= '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' + interval '1 {{period}}' and\n     \"{{timestamp_field}}\" <  '{{stop_timestamp}}'::timestamp)\n  {%- endset -%}\n\n  {%- set filtered_sql = sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\n\n  select\n    {{target_cols_csv}}\n  from (\n    {{filtered_sql}}\n  )\n\n{%- endmacro %}\n\n{% materialization insert_by_period, default -%}\n  {%- set timestamp_field = config.require('timestamp_field') -%}\n  {%- set start_date = config.require('start_date') -%}\n  {%- set stop_date = config.get('stop_date') or '' -%}}\n  {%- set period = config.get('period') or 'week' -%}\n\n  {%- if sql.find('__PERIOD_FILTER__') == -1 -%}\n    {%- set error_message -%}\n      Model '{{ model.unique_id }}' does not include the required string '__PERIOD_FILTER__' in its sql\n    {%- endset -%}\n    {{ exceptions.raise_compiler_error(error_message) }}\n  {%- endif -%}\n\n  {%- set identifier = model['name'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, type='table') -%}\n\n  {%- set non_destructive_mode = (flags.NON_DESTRUCTIVE == True) -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\n\n  {%- set should_truncate = (non_destructive_mode and full_refresh_mode and exists_as_table) -%}\n  {%- set should_drop = (not should_truncate and (full_refresh_mode or exists_not_as_table)) -%}\n  {%- set force_create = (flags.FULL_REFRESH and not flags.NON_DESTRUCTIVE) -%}\n\n  -- setup\n  {% if old_relation is none -%}\n    -- noop\n  {%- elif should_truncate -%}\n    {{adapter.truncate_relation(old_relation)}}\n  {%- elif should_drop -%}\n    {{adapter.drop_relation(old_relation)}}\n    {%- set old_relation = none -%}\n  {%- endif %}\n\n  {{run_hooks(pre_hooks, inside_transaction=False)}}\n\n  -- `begin` happens here, so `commit` after it to finish the transaction\n  {{run_hooks(pre_hooks, inside_transaction=True)}}\n  {% call statement() -%}\n    begin; -- make extra sure we've closed out the transaction\n    commit;\n  {%- endcall %}\n\n  -- build model\n  {% if force_create or old_relation is none -%}\n    {# Create an empty target table -#}\n    {% call statement('main') -%}\n      {%- set empty_sql = sql | replace(\"__PERIOD_FILTER__\", 'false') -%}\n      {{create_table_as(False, target_relation, empty_sql)}};\n    {%- endcall %}\n  {%- endif %}\n\n  {% set _ = dbt_utils.get_period_boundaries(schema,\n                                              identifier,\n                                              timestamp_field,\n                                              start_date,\n                                              stop_date,\n                                              period) %}\n  {%- set start_timestamp = load_result('period_boundaries')['data'][0][0] | string -%}\n  {%- set stop_timestamp = load_result('period_boundaries')['data'][0][1] | string -%}\n  {%- set num_periods = load_result('period_boundaries')['data'][0][2] | int -%}\n\n  {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\n  {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\n  {%- set loop_vars = {'sum_rows_inserted': 0} -%}\n\n  -- commit each period as a separate transaction\n  {% for i in range(num_periods) -%}\n    {%- set msg = \"Running for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) -%}\n    {{ dbt_utils.log_info(msg) }}\n\n    {%- set tmp_identifier = model['name'] ~ '__dbt_incremental_period' ~ i ~ '_tmp' -%}\n    {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                               schema=schema, type='table') -%}\n    {% call statement() -%}\n      {% set tmp_table_sql = dbt_utils.get_period_sql(target_cols_csv,\n                                                       sql,\n                                                       timestamp_field,\n                                                       period,\n                                                       start_timestamp,\n                                                       stop_timestamp,\n                                                       i) %}\n      {{dbt.create_table_as(True, tmp_relation, tmp_table_sql)}}\n    {%- endcall %}\n\n    {{adapter.expand_target_column_types(from_relation=tmp_relation,\n                                         to_relation=target_relation)}}\n    {%- set name = 'main-' ~ i -%}\n    {% call statement(name, fetch_result=True) -%}\n      insert into {{target_relation}} ({{target_cols_csv}})\n      (\n          select\n              {{target_cols_csv}}\n          from {{tmp_relation.include(schema=False)}}\n      );\n    {%- endcall %}\n    {%- set rows_inserted = (load_result('main-' ~ i)['status'].split(\" \"))[2] | int -%}\n    {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\n    {%- if loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %} {% endif -%}\n\n    {%- set msg = \"Ran for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) ~ \"; \" ~ rows_inserted ~ \" records inserted\" -%}\n    {{ dbt_utils.log_info(msg) }}\n\n  {%- endfor %}\n\n  {% call statement() -%}\n    begin;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=True)}}\n\n  {% call statement() -%}\n    commit;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=False)}}\n\n  {%- set status_string = \"INSERT \" ~ loop_vars['sum_rows_inserted'] -%}\n\n  {% call noop_statement(name='main', status=status_string) -%}\n    -- no-op\n  {%- endcall %}\n\n{%- endmaterialization %}", "unique_id": "macro.dbt_utils.get_period_boundaries", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "resource_type": "macro", "name": "get_period_boundaries", "macro_sql": "{% macro get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n  {% call statement('period_boundaries', fetch_result=True) -%}\n    with data as (\n      select\n          coalesce(max(\"{{timestamp_field}}\"), '{{start_date}}')::timestamp as start_timestamp,\n          coalesce(\n            {{dbt_utils.dateadd('millisecond',\n                                -1,\n                                \"nullif('\" ~ stop_date ~ \"','')::timestamp\")}},\n            {{dbt_utils.current_timestamp()}}\n          ) as stop_timestamp\n      from \"{{target_schema}}\".\"{{target_table}}\"\n    )\n\n    select\n      start_timestamp,\n      stop_timestamp,\n      {{dbt_utils.datediff('start_timestamp',\n                           'stop_timestamp',\n                           period)}}  + 1 as num_periods\n    from data\n  {%- endcall %}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_period_sql": {"raw_sql": "{% macro get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n  {% call statement('period_boundaries', fetch_result=True) -%}\n    with data as (\n      select\n          coalesce(max(\"{{timestamp_field}}\"), '{{start_date}}')::timestamp as start_timestamp,\n          coalesce(\n            {{dbt_utils.dateadd('millisecond',\n                                -1,\n                                \"nullif('\" ~ stop_date ~ \"','')::timestamp\")}},\n            {{dbt_utils.current_timestamp()}}\n          ) as stop_timestamp\n      from \"{{target_schema}}\".\"{{target_table}}\"\n    )\n\n    select\n      start_timestamp,\n      stop_timestamp,\n      {{dbt_utils.datediff('start_timestamp',\n                           'stop_timestamp',\n                           period)}}  + 1 as num_periods\n    from data\n  {%- endcall %}\n\n{%- endmacro %}\n\n{% macro get_period_sql(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n  {%- set period_filter -%}\n    (\"{{timestamp_field}}\" >  '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' and\n     \"{{timestamp_field}}\" <= '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' + interval '1 {{period}}' and\n     \"{{timestamp_field}}\" <  '{{stop_timestamp}}'::timestamp)\n  {%- endset -%}\n\n  {%- set filtered_sql = sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\n\n  select\n    {{target_cols_csv}}\n  from (\n    {{filtered_sql}}\n  )\n\n{%- endmacro %}\n\n{% materialization insert_by_period, default -%}\n  {%- set timestamp_field = config.require('timestamp_field') -%}\n  {%- set start_date = config.require('start_date') -%}\n  {%- set stop_date = config.get('stop_date') or '' -%}}\n  {%- set period = config.get('period') or 'week' -%}\n\n  {%- if sql.find('__PERIOD_FILTER__') == -1 -%}\n    {%- set error_message -%}\n      Model '{{ model.unique_id }}' does not include the required string '__PERIOD_FILTER__' in its sql\n    {%- endset -%}\n    {{ exceptions.raise_compiler_error(error_message) }}\n  {%- endif -%}\n\n  {%- set identifier = model['name'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, type='table') -%}\n\n  {%- set non_destructive_mode = (flags.NON_DESTRUCTIVE == True) -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\n\n  {%- set should_truncate = (non_destructive_mode and full_refresh_mode and exists_as_table) -%}\n  {%- set should_drop = (not should_truncate and (full_refresh_mode or exists_not_as_table)) -%}\n  {%- set force_create = (flags.FULL_REFRESH and not flags.NON_DESTRUCTIVE) -%}\n\n  -- setup\n  {% if old_relation is none -%}\n    -- noop\n  {%- elif should_truncate -%}\n    {{adapter.truncate_relation(old_relation)}}\n  {%- elif should_drop -%}\n    {{adapter.drop_relation(old_relation)}}\n    {%- set old_relation = none -%}\n  {%- endif %}\n\n  {{run_hooks(pre_hooks, inside_transaction=False)}}\n\n  -- `begin` happens here, so `commit` after it to finish the transaction\n  {{run_hooks(pre_hooks, inside_transaction=True)}}\n  {% call statement() -%}\n    begin; -- make extra sure we've closed out the transaction\n    commit;\n  {%- endcall %}\n\n  -- build model\n  {% if force_create or old_relation is none -%}\n    {# Create an empty target table -#}\n    {% call statement('main') -%}\n      {%- set empty_sql = sql | replace(\"__PERIOD_FILTER__\", 'false') -%}\n      {{create_table_as(False, target_relation, empty_sql)}};\n    {%- endcall %}\n  {%- endif %}\n\n  {% set _ = dbt_utils.get_period_boundaries(schema,\n                                              identifier,\n                                              timestamp_field,\n                                              start_date,\n                                              stop_date,\n                                              period) %}\n  {%- set start_timestamp = load_result('period_boundaries')['data'][0][0] | string -%}\n  {%- set stop_timestamp = load_result('period_boundaries')['data'][0][1] | string -%}\n  {%- set num_periods = load_result('period_boundaries')['data'][0][2] | int -%}\n\n  {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\n  {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\n  {%- set loop_vars = {'sum_rows_inserted': 0} -%}\n\n  -- commit each period as a separate transaction\n  {% for i in range(num_periods) -%}\n    {%- set msg = \"Running for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) -%}\n    {{ dbt_utils.log_info(msg) }}\n\n    {%- set tmp_identifier = model['name'] ~ '__dbt_incremental_period' ~ i ~ '_tmp' -%}\n    {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                               schema=schema, type='table') -%}\n    {% call statement() -%}\n      {% set tmp_table_sql = dbt_utils.get_period_sql(target_cols_csv,\n                                                       sql,\n                                                       timestamp_field,\n                                                       period,\n                                                       start_timestamp,\n                                                       stop_timestamp,\n                                                       i) %}\n      {{dbt.create_table_as(True, tmp_relation, tmp_table_sql)}}\n    {%- endcall %}\n\n    {{adapter.expand_target_column_types(from_relation=tmp_relation,\n                                         to_relation=target_relation)}}\n    {%- set name = 'main-' ~ i -%}\n    {% call statement(name, fetch_result=True) -%}\n      insert into {{target_relation}} ({{target_cols_csv}})\n      (\n          select\n              {{target_cols_csv}}\n          from {{tmp_relation.include(schema=False)}}\n      );\n    {%- endcall %}\n    {%- set rows_inserted = (load_result('main-' ~ i)['status'].split(\" \"))[2] | int -%}\n    {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\n    {%- if loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %} {% endif -%}\n\n    {%- set msg = \"Ran for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) ~ \"; \" ~ rows_inserted ~ \" records inserted\" -%}\n    {{ dbt_utils.log_info(msg) }}\n\n  {%- endfor %}\n\n  {% call statement() -%}\n    begin;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=True)}}\n\n  {% call statement() -%}\n    commit;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=False)}}\n\n  {%- set status_string = \"INSERT \" ~ loop_vars['sum_rows_inserted'] -%}\n\n  {% call noop_statement(name='main', status=status_string) -%}\n    -- no-op\n  {%- endcall %}\n\n{%- endmaterialization %}", "unique_id": "macro.dbt_utils.get_period_sql", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "resource_type": "macro", "name": "get_period_sql", "macro_sql": "{% macro get_period_sql(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n  {%- set period_filter -%}\n    (\"{{timestamp_field}}\" >  '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' and\n     \"{{timestamp_field}}\" <= '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' + interval '1 {{period}}' and\n     \"{{timestamp_field}}\" <  '{{stop_timestamp}}'::timestamp)\n  {%- endset -%}\n\n  {%- set filtered_sql = sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\n\n  select\n    {{target_cols_csv}}\n  from (\n    {{filtered_sql}}\n  )\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.materialization_insert_by_period_default": {"raw_sql": "{% macro get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n  {% call statement('period_boundaries', fetch_result=True) -%}\n    with data as (\n      select\n          coalesce(max(\"{{timestamp_field}}\"), '{{start_date}}')::timestamp as start_timestamp,\n          coalesce(\n            {{dbt_utils.dateadd('millisecond',\n                                -1,\n                                \"nullif('\" ~ stop_date ~ \"','')::timestamp\")}},\n            {{dbt_utils.current_timestamp()}}\n          ) as stop_timestamp\n      from \"{{target_schema}}\".\"{{target_table}}\"\n    )\n\n    select\n      start_timestamp,\n      stop_timestamp,\n      {{dbt_utils.datediff('start_timestamp',\n                           'stop_timestamp',\n                           period)}}  + 1 as num_periods\n    from data\n  {%- endcall %}\n\n{%- endmacro %}\n\n{% macro get_period_sql(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n  {%- set period_filter -%}\n    (\"{{timestamp_field}}\" >  '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' and\n     \"{{timestamp_field}}\" <= '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' + interval '1 {{period}}' and\n     \"{{timestamp_field}}\" <  '{{stop_timestamp}}'::timestamp)\n  {%- endset -%}\n\n  {%- set filtered_sql = sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\n\n  select\n    {{target_cols_csv}}\n  from (\n    {{filtered_sql}}\n  )\n\n{%- endmacro %}\n\n{% materialization insert_by_period, default -%}\n  {%- set timestamp_field = config.require('timestamp_field') -%}\n  {%- set start_date = config.require('start_date') -%}\n  {%- set stop_date = config.get('stop_date') or '' -%}}\n  {%- set period = config.get('period') or 'week' -%}\n\n  {%- if sql.find('__PERIOD_FILTER__') == -1 -%}\n    {%- set error_message -%}\n      Model '{{ model.unique_id }}' does not include the required string '__PERIOD_FILTER__' in its sql\n    {%- endset -%}\n    {{ exceptions.raise_compiler_error(error_message) }}\n  {%- endif -%}\n\n  {%- set identifier = model['name'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, type='table') -%}\n\n  {%- set non_destructive_mode = (flags.NON_DESTRUCTIVE == True) -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\n\n  {%- set should_truncate = (non_destructive_mode and full_refresh_mode and exists_as_table) -%}\n  {%- set should_drop = (not should_truncate and (full_refresh_mode or exists_not_as_table)) -%}\n  {%- set force_create = (flags.FULL_REFRESH and not flags.NON_DESTRUCTIVE) -%}\n\n  -- setup\n  {% if old_relation is none -%}\n    -- noop\n  {%- elif should_truncate -%}\n    {{adapter.truncate_relation(old_relation)}}\n  {%- elif should_drop -%}\n    {{adapter.drop_relation(old_relation)}}\n    {%- set old_relation = none -%}\n  {%- endif %}\n\n  {{run_hooks(pre_hooks, inside_transaction=False)}}\n\n  -- `begin` happens here, so `commit` after it to finish the transaction\n  {{run_hooks(pre_hooks, inside_transaction=True)}}\n  {% call statement() -%}\n    begin; -- make extra sure we've closed out the transaction\n    commit;\n  {%- endcall %}\n\n  -- build model\n  {% if force_create or old_relation is none -%}\n    {# Create an empty target table -#}\n    {% call statement('main') -%}\n      {%- set empty_sql = sql | replace(\"__PERIOD_FILTER__\", 'false') -%}\n      {{create_table_as(False, target_relation, empty_sql)}};\n    {%- endcall %}\n  {%- endif %}\n\n  {% set _ = dbt_utils.get_period_boundaries(schema,\n                                              identifier,\n                                              timestamp_field,\n                                              start_date,\n                                              stop_date,\n                                              period) %}\n  {%- set start_timestamp = load_result('period_boundaries')['data'][0][0] | string -%}\n  {%- set stop_timestamp = load_result('period_boundaries')['data'][0][1] | string -%}\n  {%- set num_periods = load_result('period_boundaries')['data'][0][2] | int -%}\n\n  {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\n  {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\n  {%- set loop_vars = {'sum_rows_inserted': 0} -%}\n\n  -- commit each period as a separate transaction\n  {% for i in range(num_periods) -%}\n    {%- set msg = \"Running for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) -%}\n    {{ dbt_utils.log_info(msg) }}\n\n    {%- set tmp_identifier = model['name'] ~ '__dbt_incremental_period' ~ i ~ '_tmp' -%}\n    {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                               schema=schema, type='table') -%}\n    {% call statement() -%}\n      {% set tmp_table_sql = dbt_utils.get_period_sql(target_cols_csv,\n                                                       sql,\n                                                       timestamp_field,\n                                                       period,\n                                                       start_timestamp,\n                                                       stop_timestamp,\n                                                       i) %}\n      {{dbt.create_table_as(True, tmp_relation, tmp_table_sql)}}\n    {%- endcall %}\n\n    {{adapter.expand_target_column_types(from_relation=tmp_relation,\n                                         to_relation=target_relation)}}\n    {%- set name = 'main-' ~ i -%}\n    {% call statement(name, fetch_result=True) -%}\n      insert into {{target_relation}} ({{target_cols_csv}})\n      (\n          select\n              {{target_cols_csv}}\n          from {{tmp_relation.include(schema=False)}}\n      );\n    {%- endcall %}\n    {%- set rows_inserted = (load_result('main-' ~ i)['status'].split(\" \"))[2] | int -%}\n    {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\n    {%- if loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %} {% endif -%}\n\n    {%- set msg = \"Ran for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) ~ \"; \" ~ rows_inserted ~ \" records inserted\" -%}\n    {{ dbt_utils.log_info(msg) }}\n\n  {%- endfor %}\n\n  {% call statement() -%}\n    begin;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=True)}}\n\n  {% call statement() -%}\n    commit;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=False)}}\n\n  {%- set status_string = \"INSERT \" ~ loop_vars['sum_rows_inserted'] -%}\n\n  {% call noop_statement(name='main', status=status_string) -%}\n    -- no-op\n  {%- endcall %}\n\n{%- endmaterialization %}", "unique_id": "macro.dbt_utils.materialization_insert_by_period_default", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "resource_type": "macro", "name": "materialization_insert_by_period_default", "macro_sql": "{% materialization insert_by_period, default -%}\n  {%- set timestamp_field = config.require('timestamp_field') -%}\n  {%- set start_date = config.require('start_date') -%}\n  {%- set stop_date = config.get('stop_date') or '' -%}}\n  {%- set period = config.get('period') or 'week' -%}\n\n  {%- if sql.find('__PERIOD_FILTER__') == -1 -%}\n    {%- set error_message -%}\n      Model '{{ model.unique_id }}' does not include the required string '__PERIOD_FILTER__' in its sql\n    {%- endset -%}\n    {{ exceptions.raise_compiler_error(error_message) }}\n  {%- endif -%}\n\n  {%- set identifier = model['name'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, type='table') -%}\n\n  {%- set non_destructive_mode = (flags.NON_DESTRUCTIVE == True) -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\n\n  {%- set should_truncate = (non_destructive_mode and full_refresh_mode and exists_as_table) -%}\n  {%- set should_drop = (not should_truncate and (full_refresh_mode or exists_not_as_table)) -%}\n  {%- set force_create = (flags.FULL_REFRESH and not flags.NON_DESTRUCTIVE) -%}\n\n  -- setup\n  {% if old_relation is none -%}\n    -- noop\n  {%- elif should_truncate -%}\n    {{adapter.truncate_relation(old_relation)}}\n  {%- elif should_drop -%}\n    {{adapter.drop_relation(old_relation)}}\n    {%- set old_relation = none -%}\n  {%- endif %}\n\n  {{run_hooks(pre_hooks, inside_transaction=False)}}\n\n  -- `begin` happens here, so `commit` after it to finish the transaction\n  {{run_hooks(pre_hooks, inside_transaction=True)}}\n  {% call statement() -%}\n    begin; -- make extra sure we've closed out the transaction\n    commit;\n  {%- endcall %}\n\n  -- build model\n  {% if force_create or old_relation is none -%}\n    {# Create an empty target table -#}\n    {% call statement('main') -%}\n      {%- set empty_sql = sql | replace(\"__PERIOD_FILTER__\", 'false') -%}\n      {{create_table_as(False, target_relation, empty_sql)}};\n    {%- endcall %}\n  {%- endif %}\n\n  {% set _ = dbt_utils.get_period_boundaries(schema,\n                                              identifier,\n                                              timestamp_field,\n                                              start_date,\n                                              stop_date,\n                                              period) %}\n  {%- set start_timestamp = load_result('period_boundaries')['data'][0][0] | string -%}\n  {%- set stop_timestamp = load_result('period_boundaries')['data'][0][1] | string -%}\n  {%- set num_periods = load_result('period_boundaries')['data'][0][2] | int -%}\n\n  {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\n  {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\n  {%- set loop_vars = {'sum_rows_inserted': 0} -%}\n\n  -- commit each period as a separate transaction\n  {% for i in range(num_periods) -%}\n    {%- set msg = \"Running for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) -%}\n    {{ dbt_utils.log_info(msg) }}\n\n    {%- set tmp_identifier = model['name'] ~ '__dbt_incremental_period' ~ i ~ '_tmp' -%}\n    {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                               schema=schema, type='table') -%}\n    {% call statement() -%}\n      {% set tmp_table_sql = dbt_utils.get_period_sql(target_cols_csv,\n                                                       sql,\n                                                       timestamp_field,\n                                                       period,\n                                                       start_timestamp,\n                                                       stop_timestamp,\n                                                       i) %}\n      {{dbt.create_table_as(True, tmp_relation, tmp_table_sql)}}\n    {%- endcall %}\n\n    {{adapter.expand_target_column_types(from_relation=tmp_relation,\n                                         to_relation=target_relation)}}\n    {%- set name = 'main-' ~ i -%}\n    {% call statement(name, fetch_result=True) -%}\n      insert into {{target_relation}} ({{target_cols_csv}})\n      (\n          select\n              {{target_cols_csv}}\n          from {{tmp_relation.include(schema=False)}}\n      );\n    {%- endcall %}\n    {%- set rows_inserted = (load_result('main-' ~ i)['status'].split(\" \"))[2] | int -%}\n    {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\n    {%- if loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %} {% endif -%}\n\n    {%- set msg = \"Ran for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) ~ \"; \" ~ rows_inserted ~ \" records inserted\" -%}\n    {{ dbt_utils.log_info(msg) }}\n\n  {%- endfor %}\n\n  {% call statement() -%}\n    begin;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=True)}}\n\n  {% call statement() -%}\n    commit;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=False)}}\n\n  {%- set status_string = \"INSERT \" ~ loop_vars['sum_rows_inserted'] -%}\n\n  {% call noop_statement(name='main', status=status_string) -%}\n    -- no-op\n  {%- endcall %}\n\n{%- endmaterialization %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.pretty_log_format": {"raw_sql": "{% macro pretty_log_format(message) %}\n\n    {{ return( dbt_utils.pretty_time() ~ ' + ' ~ message) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.pretty_log_format", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/logger/pretty_log_format.sql", "original_file_path": "macros/logger/pretty_log_format.sql", "resource_type": "macro", "name": "pretty_log_format", "macro_sql": "{% macro pretty_log_format(message) %}\n\n    {{ return( dbt_utils.pretty_time() ~ ' + ' ~ message) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.pretty_time": {"raw_sql": "{% macro pretty_time(format='%H:%M:%S') %}\n\n    {{ return(modules.datetime.datetime.now().strftime(format)) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.pretty_time", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/logger/pretty_time.sql", "original_file_path": "macros/logger/pretty_time.sql", "resource_type": "macro", "name": "pretty_time", "macro_sql": "{% macro pretty_time(format='%H:%M:%S') %}\n\n    {{ return(modules.datetime.datetime.now().strftime(format)) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.log_info": {"raw_sql": "{% macro log_info(message) %}\n\n    {{ log(dbt_utils.pretty_log_format(message), info=True) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.log_info", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/logger/log_info.sql", "original_file_path": "macros/logger/log_info.sql", "resource_type": "macro", "name": "log_info", "macro_sql": "{% macro log_info(message) %}\n\n    {{ log(dbt_utils.pretty_log_format(message), info=True) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_intervals_between": {"raw_sql": "{% macro get_intervals_between(start_date, end_date, datepart) -%}\n\n    {%- call statement('get_intervals_between', fetch_result=True) %}\n\n        select {{dbt_utils.datediff(start_date, end_date, datepart)}}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_intervals_between') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values[0]) }}\n    {%- else -%}\n        {{ return(1) }}\n    {%- endif -%}\n\n{%- endmacro %}\n\n\n\n\n{% macro date_spine(datepart, start_date, end_date) %}\n\n/*\ncall as follows:\n\ndate_spine(\n    \"day\",\n    \"to_date('01/01/2016', 'mm/dd/yyyy')\",\n    \"dateadd(week, 1, current_date)\"\n)\n\n*/\n\nwith rawdata as (\n\n    {{dbt_utils.generate_series(\n        dbt_utils.get_intervals_between(start_date, end_date, datepart)\n    )}}\n\n),\n\nall_periods as (\n\n    select (\n        {{\n            dbt_utils.dateadd(\n                datepart,\n                \"row_number() over (order by 1) - 1\",\n                start_date\n            )\n        }}\n    ) as date_{{datepart}}\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_{{datepart}} <= {{ end_date }}\n\n)\n\nselect * from filtered\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.get_intervals_between", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/datetime/date_spine.sql", "original_file_path": "macros/datetime/date_spine.sql", "resource_type": "macro", "name": "get_intervals_between", "macro_sql": "{% macro get_intervals_between(start_date, end_date, datepart) -%}\n\n    {%- call statement('get_intervals_between', fetch_result=True) %}\n\n        select {{dbt_utils.datediff(start_date, end_date, datepart)}}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_intervals_between') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values[0]) }}\n    {%- else -%}\n        {{ return(1) }}\n    {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.date_spine": {"raw_sql": "{% macro get_intervals_between(start_date, end_date, datepart) -%}\n\n    {%- call statement('get_intervals_between', fetch_result=True) %}\n\n        select {{dbt_utils.datediff(start_date, end_date, datepart)}}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_intervals_between') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values[0]) }}\n    {%- else -%}\n        {{ return(1) }}\n    {%- endif -%}\n\n{%- endmacro %}\n\n\n\n\n{% macro date_spine(datepart, start_date, end_date) %}\n\n/*\ncall as follows:\n\ndate_spine(\n    \"day\",\n    \"to_date('01/01/2016', 'mm/dd/yyyy')\",\n    \"dateadd(week, 1, current_date)\"\n)\n\n*/\n\nwith rawdata as (\n\n    {{dbt_utils.generate_series(\n        dbt_utils.get_intervals_between(start_date, end_date, datepart)\n    )}}\n\n),\n\nall_periods as (\n\n    select (\n        {{\n            dbt_utils.dateadd(\n                datepart,\n                \"row_number() over (order by 1) - 1\",\n                start_date\n            )\n        }}\n    ) as date_{{datepart}}\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_{{datepart}} <= {{ end_date }}\n\n)\n\nselect * from filtered\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.date_spine", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/datetime/date_spine.sql", "original_file_path": "macros/datetime/date_spine.sql", "resource_type": "macro", "name": "date_spine", "macro_sql": "{% macro date_spine(datepart, start_date, end_date) %}\n\n/*\ncall as follows:\n\ndate_spine(\n    \"day\",\n    \"to_date('01/01/2016', 'mm/dd/yyyy')\",\n    \"dateadd(week, 1, current_date)\"\n)\n\n*/\n\nwith rawdata as (\n\n    {{dbt_utils.generate_series(\n        dbt_utils.get_intervals_between(start_date, end_date, datepart)\n    )}}\n\n),\n\nall_periods as (\n\n    select (\n        {{\n            dbt_utils.dateadd(\n                datepart,\n                \"row_number() over (order by 1) - 1\",\n                start_date\n            )\n        }}\n    ) as date_{{datepart}}\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_{{datepart}} <= {{ end_date }}\n\n)\n\nselect * from filtered\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_url_host": {"raw_sql": "{% macro get_url_host(field) -%}\n\n{%- set parsed = \n    dbt_utils.split_part(\n        dbt_utils.split_part(\n            dbt_utils.replace(\n                dbt_utils.replace(field, \"'http://'\", \"''\"\n                ), \"'https://'\", \"''\"\n            ), \"'/'\", 1\n        ), \"'?'\", 1\n    )\n    \n-%}\n\n     \n    {{ dbt_utils.safe_cast(\n        parsed,\n        dbt_utils.type_string()\n        )}}\n        \n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.get_url_host", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/web/get_url_host.sql", "original_file_path": "macros/web/get_url_host.sql", "resource_type": "macro", "name": "get_url_host", "macro_sql": "{% macro get_url_host(field) -%}\n\n{%- set parsed = \n    dbt_utils.split_part(\n        dbt_utils.split_part(\n            dbt_utils.replace(\n                dbt_utils.replace(field, \"'http://'\", \"''\"\n                ), \"'https://'\", \"''\"\n            ), \"'/'\", 1\n        ), \"'?'\", 1\n    )\n    \n-%}\n\n     \n    {{ dbt_utils.safe_cast(\n        parsed,\n        dbt_utils.type_string()\n        )}}\n        \n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_url_path": {"raw_sql": "{% macro get_url_path(field) -%}\n\n    {%- set stripped_url = \n        dbt_utils.replace(\n            dbt_utils.replace(field, \"'http://'\", \"''\"), \"'https://'\", \"''\")\n    -%}\n\n    {%- set first_slash_pos -%}\n        coalesce(\n            nullif({{dbt_utils.position(\"'/'\", stripped_url)}}, 0),\n            {{dbt_utils.position(\"'?'\", stripped_url)}} - 1\n            )\n    {%- endset -%}\n\n    {%- set parsed_path =\n        dbt_utils.split_part(\n            dbt_utils.right(\n                stripped_url, \n                dbt_utils.length(stripped_url) ~ \"-\" ~ first_slash_pos\n                ), \n            \"'?'\", 1\n            )\n    -%}\n\n    {{ dbt_utils.safe_cast(\n        parsed_path,\n        dbt_utils.type_string()\n    )}}\n    \n{%- endmacro %}", "unique_id": "macro.dbt_utils.get_url_path", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/web/get_url_path.sql", "original_file_path": "macros/web/get_url_path.sql", "resource_type": "macro", "name": "get_url_path", "macro_sql": "{% macro get_url_path(field) -%}\n\n    {%- set stripped_url = \n        dbt_utils.replace(\n            dbt_utils.replace(field, \"'http://'\", \"''\"), \"'https://'\", \"''\")\n    -%}\n\n    {%- set first_slash_pos -%}\n        coalesce(\n            nullif({{dbt_utils.position(\"'/'\", stripped_url)}}, 0),\n            {{dbt_utils.position(\"'?'\", stripped_url)}} - 1\n            )\n    {%- endset -%}\n\n    {%- set parsed_path =\n        dbt_utils.split_part(\n            dbt_utils.right(\n                stripped_url, \n                dbt_utils.length(stripped_url) ~ \"-\" ~ first_slash_pos\n                ), \n            \"'?'\", 1\n            )\n    -%}\n\n    {{ dbt_utils.safe_cast(\n        parsed_path,\n        dbt_utils.type_string()\n    )}}\n    \n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_url_parameter": {"raw_sql": "{% macro get_url_parameter(field, url_parameter) -%}\n\n{%- set formatted_url_parameter = \"'\" + url_parameter + \"='\" -%}\n\n{%- set split = dbt_utils.split_part(dbt_utils.split_part(field, formatted_url_parameter, 2), \"'&'\", 1) -%}\n\nnullif({{ split }},'')\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.get_url_parameter", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/web/get_url_parameter.sql", "original_file_path": "macros/web/get_url_parameter.sql", "resource_type": "macro", "name": "get_url_parameter", "macro_sql": "{% macro get_url_parameter(field, url_parameter) -%}\n\n{%- set formatted_url_parameter = \"'\" + url_parameter + \"='\" -%}\n\n{%- set split = dbt_utils.split_part(dbt_utils.split_part(field, formatted_url_parameter, 2), \"'&'\", 1) -%}\n\nnullif({{ split }},'')\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.haversine_distance": {"raw_sql": "{#\nThis calculates the distance between two sets of latitude and longitude.\nThe formula is from the following blog post:\nhttp://daynebatten.com/2015/09/latitude-longitude-distance-sql/\n\nThe arguments should be float type. \n#}\n\n{% macro haversine_distance(lat1,lon1,lat2,lon2) -%}\n\n    2 * 3961 * asin(sqrt((sin(radians(({{lat2}} - {{lat1}}) / 2))) ^ 2 +\n    cos(radians({{lat1}})) * cos(radians({{lat2}})) *\n    (sin(radians(({{lon2}} - {{lon1}}) / 2))) ^ 2))\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.haversine_distance", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/geo/haversine_distance.sql", "original_file_path": "macros/geo/haversine_distance.sql", "resource_type": "macro", "name": "haversine_distance", "macro_sql": "{% macro haversine_distance(lat1,lon1,lat2,lon2) -%}\n\n    2 * 3961 * asin(sqrt((sin(radians(({{lat2}} - {{lat1}}) / 2))) ^ 2 +\n    cos(radians({{lat1}})) * cos(radians({{lat2}})) *\n    (sin(radians(({{lon2}} - {{lon1}}) / 2))) ^ 2))\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_equal_rowcount": {"raw_sql": "{% macro test_equal_rowcount(model) %}\n\n{% set compare_model = kwargs.get('compare_model', kwargs.get('arg')) %}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\nwith a as (\n\n    select count(*) as count_a from {{ model }}\n\n),\nb as (\n\n    select count(*) as count_b from {{ compare_model }}\n\n),\nfinal as (\n\n    select abs(\n            (select count_a from a) -\n            (select count_b from b)\n            )\n        as diff_count\n\n)\n\nselect diff_count from final\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_equal_rowcount", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/schema_tests/equal_rowcount.sql", "original_file_path": "macros/schema_tests/equal_rowcount.sql", "resource_type": "macro", "name": "test_equal_rowcount", "macro_sql": "{% macro test_equal_rowcount(model) %}\n\n{% set compare_model = kwargs.get('compare_model', kwargs.get('arg')) %}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\nwith a as (\n\n    select count(*) as count_a from {{ model }}\n\n),\nb as (\n\n    select count(*) as count_b from {{ compare_model }}\n\n),\nfinal as (\n\n    select abs(\n            (select count_a from a) -\n            (select count_b from b)\n            )\n        as diff_count\n\n)\n\nselect diff_count from final\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_relationships_where": {"raw_sql": "{% macro test_relationships_where(model, to, field) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n{% set from_condition = kwargs.get('from_condition', \"true\") %}\n{% set to_condition = kwargs.get('to_condition', \"true\") %}\n\nwith left_table as (\n\n  select\n    {{column_name}} as id\n\n  from {{model}}\n\n  where {{column_name}} is not null\n    and {{from_condition}}\n\n),\n\nright_table as (\n\n  select\n    {{field}} as id\n\n  from {{to}}\n\n  where {{field}} is not null\n    and {{to_condition}}\n\n),\n\nexceptions as (\n\n  select\n    left_table.id,\n    right_table.id as right_id\n\n  from left_table\n\n  left join right_table\n         on left_table.id = right_table.id\n\n  where right_table.id is null\n\n)\n\nselect count(*) from exceptions\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_relationships_where", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/schema_tests/relationships_where.sql", "original_file_path": "macros/schema_tests/relationships_where.sql", "resource_type": "macro", "name": "test_relationships_where", "macro_sql": "{% macro test_relationships_where(model, to, field) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n{% set from_condition = kwargs.get('from_condition', \"true\") %}\n{% set to_condition = kwargs.get('to_condition', \"true\") %}\n\nwith left_table as (\n\n  select\n    {{column_name}} as id\n\n  from {{model}}\n\n  where {{column_name}} is not null\n    and {{from_condition}}\n\n),\n\nright_table as (\n\n  select\n    {{field}} as id\n\n  from {{to}}\n\n  where {{field}} is not null\n    and {{to_condition}}\n\n),\n\nexceptions as (\n\n  select\n    left_table.id,\n    right_table.id as right_id\n\n  from left_table\n\n  left join right_table\n         on left_table.id = right_table.id\n\n  where right_table.id is null\n\n)\n\nselect count(*) from exceptions\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_recency": {"raw_sql": "{% macro test_recency(model, datepart, interval) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('field')) %}\n\nselect\n    case when count(*) > 0 then 0\n    else 1\n    end as error_result\nfrom {{model}}\nwhere {{column_name}} >=\n    {{dbt_utils.dateadd(datepart, interval * -1, dbt_utils.current_timestamp())}}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_recency", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/schema_tests/recency.sql", "original_file_path": "macros/schema_tests/recency.sql", "resource_type": "macro", "name": "test_recency", "macro_sql": "{% macro test_recency(model, datepart, interval) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('field')) %}\n\nselect\n    case when count(*) > 0 then 0\n    else 1\n    end as error_result\nfrom {{model}}\nwhere {{column_name}} >=\n    {{dbt_utils.dateadd(datepart, interval * -1, dbt_utils.current_timestamp())}}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_not_constant": {"raw_sql": "{% macro test_not_constant(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\n\nfrom (\n\n    select\n          count(distinct {{ column_name }})\n\n    from {{ model }}\n\n    having count(distinct {{ column_name }}) = 1\n\n    ) validation_errors\n\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_not_constant", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/schema_tests/not_constant.sql", "original_file_path": "macros/schema_tests/not_constant.sql", "resource_type": "macro", "name": "test_not_constant", "macro_sql": "{% macro test_not_constant(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\n\nfrom (\n\n    select\n          count(distinct {{ column_name }})\n\n    from {{ model }}\n\n    having count(distinct {{ column_name }}) = 1\n\n    ) validation_errors\n\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_at_least_one": {"raw_sql": "{% macro test_at_least_one(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\nfrom (\n    select\n\n      count({{ column_name }})\n\n    from {{ model }}\n\n    having count({{ column_name }}) = 0\n\n) validation_errors\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_at_least_one", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/schema_tests/at_least_one.sql", "original_file_path": "macros/schema_tests/at_least_one.sql", "resource_type": "macro", "name": "test_at_least_one", "macro_sql": "{% macro test_at_least_one(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*)\nfrom (\n    select\n\n      count({{ column_name }})\n\n    from {{ model }}\n\n    having count({{ column_name }}) = 0\n\n) validation_errors\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_unique_combination_of_columns": {"raw_sql": "{% macro test_unique_combination_of_columns(model) %}\n\n{%- set columns = kwargs.get('combination_of_columns', kwargs.get('arg')) %}\n\n{%- set columns_csv=columns | join(', ') %}\n\nwith validation_errors as (\n\n    select\n        {{ columns_csv }}\n    from {{ model }}\n\n    group by {{ columns_csv }}\n    having count(*) > 1\n\n)\n\nselect count(*)\nfrom validation_errors\n\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_unique_combination_of_columns", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/schema_tests/unique_combination_of_columns.sql", "original_file_path": "macros/schema_tests/unique_combination_of_columns.sql", "resource_type": "macro", "name": "test_unique_combination_of_columns", "macro_sql": "{% macro test_unique_combination_of_columns(model) %}\n\n{%- set columns = kwargs.get('combination_of_columns', kwargs.get('arg')) %}\n\n{%- set columns_csv=columns | join(', ') %}\n\nwith validation_errors as (\n\n    select\n        {{ columns_csv }}\n    from {{ model }}\n\n    group by {{ columns_csv }}\n    having count(*) > 1\n\n)\n\nselect count(*)\nfrom validation_errors\n\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_cardinality_equality": {"raw_sql": "{% macro test_cardinality_equality(model, to, field) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n\n\nwith table_a as (\nselect\n  {{ column_name }},\n  count(*) as num_rows\nfrom {{ model }}\ngroup by 1\n),\n\ntable_b as (\nselect\n  {{ field }},\n  count(*) as num_rows\nfrom {{ to }}\ngroup by 1\n),\n\nexcept_a as (\n  select *\n  from table_a\n  {{ dbt_utils.except() }}\n  select *\n  from table_b\n),\n\nexcept_b as (\n  select *\n  from table_b\n  {{ dbt_utils.except() }}\n  select *\n  from table_a\n),\n\nunioned as (\n  select *\n  from except_a\n  union all\n  select *\n  from except_b\n)\n\nselect count(*)\nfrom unioned\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_cardinality_equality", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/schema_tests/cardinality_equality.sql", "original_file_path": "macros/schema_tests/cardinality_equality.sql", "resource_type": "macro", "name": "test_cardinality_equality", "macro_sql": "{% macro test_cardinality_equality(model, to, field) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n\n\nwith table_a as (\nselect\n  {{ column_name }},\n  count(*) as num_rows\nfrom {{ model }}\ngroup by 1\n),\n\ntable_b as (\nselect\n  {{ field }},\n  count(*) as num_rows\nfrom {{ to }}\ngroup by 1\n),\n\nexcept_a as (\n  select *\n  from table_a\n  {{ dbt_utils.except() }}\n  select *\n  from table_b\n),\n\nexcept_b as (\n  select *\n  from table_b\n  {{ dbt_utils.except() }}\n  select *\n  from table_a\n),\n\nunioned as (\n  select *\n  from except_a\n  union all\n  select *\n  from except_b\n)\n\nselect count(*)\nfrom unioned\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_expression_is_true": {"raw_sql": "{% macro test_expression_is_true(model, condition='true') %}\n\n{% set expression = kwargs.get('expression', kwargs.get('arg')) %}\n\nwith meet_condition as (\n\n    select * from {{ model }} where {{ condition }}\n\n),\nvalidation_errors as (\n\n    select\n        *\n    from meet_condition\n    where not({{expression}})\n\n)\n\nselect count(*)\nfrom validation_errors\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_expression_is_true", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/schema_tests/expression_is_true.sql", "original_file_path": "macros/schema_tests/expression_is_true.sql", "resource_type": "macro", "name": "test_expression_is_true", "macro_sql": "{% macro test_expression_is_true(model, condition='true') %}\n\n{% set expression = kwargs.get('expression', kwargs.get('arg')) %}\n\nwith meet_condition as (\n\n    select * from {{ model }} where {{ condition }}\n\n),\nvalidation_errors as (\n\n    select\n        *\n    from meet_condition\n    where not({{expression}})\n\n)\n\nselect count(*)\nfrom validation_errors\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_equality": {"raw_sql": "{% macro test_equality(model) %}\n\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\n-- setup\n{%- do dbt_utils._is_relation(model, 'test_equality') -%}\n{% set compare_model = kwargs.get('compare_model', kwargs.get('arg')) %}\n{% set compare_columns = kwargs.get('compare_columns', adapter.get_columns_in_relation(model) | map(attribute='quoted') ) %}\n{% set compare_cols_csv = compare_columns | join(', ') %}\n\nwith a as (\n\n    select * from {{ model }}\n\n),\n\nb as (\n\n    select * from {{ compare_model }}\n\n),\n\na_minus_b as (\n\n    select {{compare_cols_csv}} from a\n    {{ dbt_utils.except() }}\n    select {{compare_cols_csv}} from b\n\n),\n\nb_minus_a as (\n\n    select {{compare_cols_csv}} from b\n    {{ dbt_utils.except() }}\n    select {{compare_cols_csv}} from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_equality", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/schema_tests/equality.sql", "original_file_path": "macros/schema_tests/equality.sql", "resource_type": "macro", "name": "test_equality", "macro_sql": "{% macro test_equality(model) %}\n\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\n-- setup\n{%- do dbt_utils._is_relation(model, 'test_equality') -%}\n{% set compare_model = kwargs.get('compare_model', kwargs.get('arg')) %}\n{% set compare_columns = kwargs.get('compare_columns', adapter.get_columns_in_relation(model) | map(attribute='quoted') ) %}\n{% set compare_cols_csv = compare_columns | join(', ') %}\n\nwith a as (\n\n    select * from {{ model }}\n\n),\n\nb as (\n\n    select * from {{ compare_model }}\n\n),\n\na_minus_b as (\n\n    select {{compare_cols_csv}} from a\n    {{ dbt_utils.except() }}\n    select {{compare_cols_csv}} from b\n\n),\n\nb_minus_a as (\n\n    select {{compare_cols_csv}} from b\n    {{ dbt_utils.except() }}\n    select {{compare_cols_csv}} from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_mutually_exclusive_ranges": {"raw_sql": "{% macro test_mutually_exclusive_ranges(model, lower_bound_column, upper_bound_column, partition_by=None, gaps='allowed') %}\n\n{% if gaps == 'not_allowed' %}\n    {% set allow_gaps_operator='=' %}\n    {% set allow_gaps_operator_in_words='equal_to' %}\n{% elif gaps == 'allowed' %}\n    {% set allow_gaps_operator='<=' %}\n    {% set allow_gaps_operator_in_words='less_than_or_equal_to' %}\n{% elif gaps == 'required' %}\n    {% set allow_gaps_operator='<' %}\n    {% set allow_gaps_operator_in_words='less_than' %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\n        \"`gaps` argument for mutually_exclusive_ranges test must be one of ['not_allowed', 'allowed', 'required'] Got: '\" ~ gaps ~\"'.'\"\n    ) }}\n\n{% endif %}\n\n{% set partition_clause=\"partition by \" ~ partition_by if partition_by else '' %}\n\nwith window_functions as (\n\n    select\n        {% if partition_by %}\n        {{ partition_by }},\n        {% endif %}\n        {{ lower_bound_column }} as lower_bound,\n        {{ upper_bound_column }} as upper_bound,\n\n        lead({{ lower_bound_column }}) over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }}\n        ) as next_lower_bound,\n\n        row_number() over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }} desc\n        ) = 1 as is_last_record\n\n    from {{ model }}\n\n),\n\ncalc as (\n    -- We want to return records where one of our assumptions fails, so we'll use\n    -- the `not` function with `and` statements so we can write our assumptions nore cleanly\n    select\n        *,\n\n        -- For each record: lower_bound should be < upper_bound.\n        -- Coalesce it to return an error on the null case (implicit assumption\n        -- these columns are not_null)\n        coalesce(\n            lower_bound < upper_bound,\n            false\n        ) as lower_bound_less_than_upper_bound,\n\n        -- For each record: upper_bound {{ allow_gaps_operator }} the next lower_bound.\n        -- Coalesce it to handle null cases for the last record.\n        coalesce(\n            upper_bound {{ allow_gaps_operator }} next_lower_bound,\n            is_last_record,\n            false\n        ) as upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n\n    from window_functions\n\n),\n\nvalidation_errors as (\n\n    select\n        *\n    from calc\n\n    where not(\n        -- THE FOLLOWING SHOULD BE TRUE --\n        lower_bound_less_than_upper_bound\n        and upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n    )\n)\n\nselect count(*) from validation_errors\n{% endmacro %}", "unique_id": "macro.dbt_utils.test_mutually_exclusive_ranges", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/schema_tests/mutually_exclusive_ranges.sql", "original_file_path": "macros/schema_tests/mutually_exclusive_ranges.sql", "resource_type": "macro", "name": "test_mutually_exclusive_ranges", "macro_sql": "{% macro test_mutually_exclusive_ranges(model, lower_bound_column, upper_bound_column, partition_by=None, gaps='allowed') %}\n\n{% if gaps == 'not_allowed' %}\n    {% set allow_gaps_operator='=' %}\n    {% set allow_gaps_operator_in_words='equal_to' %}\n{% elif gaps == 'allowed' %}\n    {% set allow_gaps_operator='<=' %}\n    {% set allow_gaps_operator_in_words='less_than_or_equal_to' %}\n{% elif gaps == 'required' %}\n    {% set allow_gaps_operator='<' %}\n    {% set allow_gaps_operator_in_words='less_than' %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\n        \"`gaps` argument for mutually_exclusive_ranges test must be one of ['not_allowed', 'allowed', 'required'] Got: '\" ~ gaps ~\"'.'\"\n    ) }}\n\n{% endif %}\n\n{% set partition_clause=\"partition by \" ~ partition_by if partition_by else '' %}\n\nwith window_functions as (\n\n    select\n        {% if partition_by %}\n        {{ partition_by }},\n        {% endif %}\n        {{ lower_bound_column }} as lower_bound,\n        {{ upper_bound_column }} as upper_bound,\n\n        lead({{ lower_bound_column }}) over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }}\n        ) as next_lower_bound,\n\n        row_number() over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }} desc\n        ) = 1 as is_last_record\n\n    from {{ model }}\n\n),\n\ncalc as (\n    -- We want to return records where one of our assumptions fails, so we'll use\n    -- the `not` function with `and` statements so we can write our assumptions nore cleanly\n    select\n        *,\n\n        -- For each record: lower_bound should be < upper_bound.\n        -- Coalesce it to return an error on the null case (implicit assumption\n        -- these columns are not_null)\n        coalesce(\n            lower_bound < upper_bound,\n            false\n        ) as lower_bound_less_than_upper_bound,\n\n        -- For each record: upper_bound {{ allow_gaps_operator }} the next lower_bound.\n        -- Coalesce it to handle null cases for the last record.\n        coalesce(\n            upper_bound {{ allow_gaps_operator }} next_lower_bound,\n            is_last_record,\n            false\n        ) as upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n\n    from window_functions\n\n),\n\nvalidation_errors as (\n\n    select\n        *\n    from calc\n\n    where not(\n        -- THE FOLLOWING SHOULD BE TRUE --\n        lower_bound_less_than_upper_bound\n        and upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n    )\n)\n\nselect count(*) from validation_errors\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.nullcheck_table": {"raw_sql": "{% macro nullcheck_table(relation) %}\n\n  {%- do dbt_utils._is_relation(relation, 'nullcheck_table') -%}\n  {% set cols = adapter.get_columns_in_relation(relation) %}\n\n  select {{ dbt_utils.nullcheck(cols) }}\n  from {{relation}}\n  \n{% endmacro %}", "unique_id": "macro.dbt_utils.nullcheck_table", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/nullcheck_table.sql", "original_file_path": "macros/sql/nullcheck_table.sql", "resource_type": "macro", "name": "nullcheck_table", "macro_sql": "{% macro nullcheck_table(relation) %}\n\n  {%- do dbt_utils._is_relation(relation, 'nullcheck_table') -%}\n  {% set cols = adapter.get_columns_in_relation(relation) %}\n\n  select {{ dbt_utils.nullcheck(cols) }}\n  from {{relation}}\n  \n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_powers_of_two": {"raw_sql": "{% macro get_powers_of_two(upper_bound) %}\n\n    {% if upper_bound <= 0 %}\n    {{ exceptions.raise_compiler_error(\"upper bound must be positive\") }}\n    {% endif %}\n\n    {% for _ in range(1, 100) %}\n       {% if upper_bound <= 2 ** loop.index %}{{ return(loop.index) }}{% endif %}\n    {% endfor %}\n\n{% endmacro %}\n\n\n{% macro generate_series(upper_bound) %}\n\n    {% set n = dbt_utils.get_powers_of_two(upper_bound) %}\n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    {% for i in range(n) %}\n    p{{i}}.generated_number * pow(2, {{i}})\n    {% if not loop.last %} + {% endif %}\n    {% endfor %}\n    + 1\n    as generated_number\n\n    from\n\n    {% for i in range(n) %}\n    p as p{{i}}\n    {% if not loop.last %} cross join {% endif %}\n    {% endfor %}\n\n    )\n\n    select *\n    from unioned\n    where generated_number <= {{upper_bound}}\n    order by generated_number\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.get_powers_of_two", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/generate_series.sql", "original_file_path": "macros/sql/generate_series.sql", "resource_type": "macro", "name": "get_powers_of_two", "macro_sql": "{% macro get_powers_of_two(upper_bound) %}\n\n    {% if upper_bound <= 0 %}\n    {{ exceptions.raise_compiler_error(\"upper bound must be positive\") }}\n    {% endif %}\n\n    {% for _ in range(1, 100) %}\n       {% if upper_bound <= 2 ** loop.index %}{{ return(loop.index) }}{% endif %}\n    {% endfor %}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.generate_series": {"raw_sql": "{% macro get_powers_of_two(upper_bound) %}\n\n    {% if upper_bound <= 0 %}\n    {{ exceptions.raise_compiler_error(\"upper bound must be positive\") }}\n    {% endif %}\n\n    {% for _ in range(1, 100) %}\n       {% if upper_bound <= 2 ** loop.index %}{{ return(loop.index) }}{% endif %}\n    {% endfor %}\n\n{% endmacro %}\n\n\n{% macro generate_series(upper_bound) %}\n\n    {% set n = dbt_utils.get_powers_of_two(upper_bound) %}\n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    {% for i in range(n) %}\n    p{{i}}.generated_number * pow(2, {{i}})\n    {% if not loop.last %} + {% endif %}\n    {% endfor %}\n    + 1\n    as generated_number\n\n    from\n\n    {% for i in range(n) %}\n    p as p{{i}}\n    {% if not loop.last %} cross join {% endif %}\n    {% endfor %}\n\n    )\n\n    select *\n    from unioned\n    where generated_number <= {{upper_bound}}\n    order by generated_number\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.generate_series", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/generate_series.sql", "original_file_path": "macros/sql/generate_series.sql", "resource_type": "macro", "name": "generate_series", "macro_sql": "{% macro generate_series(upper_bound) %}\n\n    {% set n = dbt_utils.get_powers_of_two(upper_bound) %}\n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    {% for i in range(n) %}\n    p{{i}}.generated_number * pow(2, {{i}})\n    {% if not loop.last %} + {% endif %}\n    {% endfor %}\n    + 1\n    as generated_number\n\n    from\n\n    {% for i in range(n) %}\n    p as p{{i}}\n    {% if not loop.last %} cross join {% endif %}\n    {% endfor %}\n\n    )\n\n    select *\n    from unioned\n    where generated_number <= {{upper_bound}}\n    order by generated_number\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_relations_by_prefix": {"raw_sql": "{% macro get_relations_by_prefix(schema, prefix, exclude='', database=target.database) %}\n\n    {%- call statement('get_tables', fetch_result=True) %}\n\n      {{ dbt_utils.get_tables_by_prefix_sql(schema, prefix, exclude, database) }}\n\n    {%- endcall -%}\n\n    {%- set table_list = load_result('get_tables') -%}\n\n    {%- if table_list and table_list['table'] -%}\n        {%- set tbl_relations = [] -%}\n        {%- for row in table_list['table'] -%}\n            {%- set tbl_relation = api.Relation.create(database, row.table_schema, row.table_name) -%}\n            {%- do tbl_relations.append(tbl_relation) -%}\n        {%- endfor -%}\n\n        {{ return(tbl_relations) }}\n    {%- else -%}\n        {{ return([]) }}\n    {%- endif -%}\n\n{% endmacro %}\n\n{% macro get_tables_by_prefix(schema, prefix, exclude='', database=target.database) %}\n    {% if execute %}\n        {{ log(\"Warning: the `get_tables_by_prefix` macro is no longer supported and will be deprecated in a future release of dbt-utils. Use the `get_relations_by_prefix` macro instead\", info=True) }}\n    {% endif %}\n\n\n    {{ return(dbt_utils.get_relations_by_prefix(schema, prefix, exclude, database)) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.get_relations_by_prefix", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/get_relations_by_prefix.sql", "original_file_path": "macros/sql/get_relations_by_prefix.sql", "resource_type": "macro", "name": "get_relations_by_prefix", "macro_sql": "{% macro get_relations_by_prefix(schema, prefix, exclude='', database=target.database) %}\n\n    {%- call statement('get_tables', fetch_result=True) %}\n\n      {{ dbt_utils.get_tables_by_prefix_sql(schema, prefix, exclude, database) }}\n\n    {%- endcall -%}\n\n    {%- set table_list = load_result('get_tables') -%}\n\n    {%- if table_list and table_list['table'] -%}\n        {%- set tbl_relations = [] -%}\n        {%- for row in table_list['table'] -%}\n            {%- set tbl_relation = api.Relation.create(database, row.table_schema, row.table_name) -%}\n            {%- do tbl_relations.append(tbl_relation) -%}\n        {%- endfor -%}\n\n        {{ return(tbl_relations) }}\n    {%- else -%}\n        {{ return([]) }}\n    {%- endif -%}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_tables_by_prefix": {"raw_sql": "{% macro get_relations_by_prefix(schema, prefix, exclude='', database=target.database) %}\n\n    {%- call statement('get_tables', fetch_result=True) %}\n\n      {{ dbt_utils.get_tables_by_prefix_sql(schema, prefix, exclude, database) }}\n\n    {%- endcall -%}\n\n    {%- set table_list = load_result('get_tables') -%}\n\n    {%- if table_list and table_list['table'] -%}\n        {%- set tbl_relations = [] -%}\n        {%- for row in table_list['table'] -%}\n            {%- set tbl_relation = api.Relation.create(database, row.table_schema, row.table_name) -%}\n            {%- do tbl_relations.append(tbl_relation) -%}\n        {%- endfor -%}\n\n        {{ return(tbl_relations) }}\n    {%- else -%}\n        {{ return([]) }}\n    {%- endif -%}\n\n{% endmacro %}\n\n{% macro get_tables_by_prefix(schema, prefix, exclude='', database=target.database) %}\n    {% if execute %}\n        {{ log(\"Warning: the `get_tables_by_prefix` macro is no longer supported and will be deprecated in a future release of dbt-utils. Use the `get_relations_by_prefix` macro instead\", info=True) }}\n    {% endif %}\n\n\n    {{ return(dbt_utils.get_relations_by_prefix(schema, prefix, exclude, database)) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.get_tables_by_prefix", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/get_relations_by_prefix.sql", "original_file_path": "macros/sql/get_relations_by_prefix.sql", "resource_type": "macro", "name": "get_tables_by_prefix", "macro_sql": "{% macro get_tables_by_prefix(schema, prefix, exclude='', database=target.database) %}\n    {% if execute %}\n        {{ log(\"Warning: the `get_tables_by_prefix` macro is no longer supported and will be deprecated in a future release of dbt-utils. Use the `get_relations_by_prefix` macro instead\", info=True) }}\n    {% endif %}\n\n\n    {{ return(dbt_utils.get_relations_by_prefix(schema, prefix, exclude, database)) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_tables_by_prefix_sql": {"raw_sql": "{% macro get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    {{ adapter_macro('dbt_utils.get_tables_by_prefix_sql', schema, prefix, exclude, database) }}\n{% endmacro %}\n\n{% macro default__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n\n        select distinct \n            table_schema as \"table_schema\", table_name as \"table_name\"\n        from {{database}}.information_schema.tables\n        where table_schema ilike '{{ schema }}'\n        and table_name ilike '{{ prefix }}%'\n        and table_name not ilike '{{ exclude }}'\n\n{% endmacro %}\n\n\n{% macro bigquery__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    \n        select distinct\n            dataset_id as table_schema, table_id as table_name\n\n        from {{adapter.quote(database)}}.{{schema}}.__TABLES_SUMMARY__\n        where dataset_id = '{{schema}}'\n            and lower(table_id) like lower ('{{prefix}}%')\n            and lower(table_id) not like lower ('{{exclude}}')\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.get_tables_by_prefix_sql", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/get_tables_by_prefix_sql.sql", "original_file_path": "macros/sql/get_tables_by_prefix_sql.sql", "resource_type": "macro", "name": "get_tables_by_prefix_sql", "macro_sql": "{% macro get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    {{ adapter_macro('dbt_utils.get_tables_by_prefix_sql', schema, prefix, exclude, database) }}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_tables_by_prefix_sql": {"raw_sql": "{% macro get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    {{ adapter_macro('dbt_utils.get_tables_by_prefix_sql', schema, prefix, exclude, database) }}\n{% endmacro %}\n\n{% macro default__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n\n        select distinct \n            table_schema as \"table_schema\", table_name as \"table_name\"\n        from {{database}}.information_schema.tables\n        where table_schema ilike '{{ schema }}'\n        and table_name ilike '{{ prefix }}%'\n        and table_name not ilike '{{ exclude }}'\n\n{% endmacro %}\n\n\n{% macro bigquery__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    \n        select distinct\n            dataset_id as table_schema, table_id as table_name\n\n        from {{adapter.quote(database)}}.{{schema}}.__TABLES_SUMMARY__\n        where dataset_id = '{{schema}}'\n            and lower(table_id) like lower ('{{prefix}}%')\n            and lower(table_id) not like lower ('{{exclude}}')\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.default__get_tables_by_prefix_sql", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/get_tables_by_prefix_sql.sql", "original_file_path": "macros/sql/get_tables_by_prefix_sql.sql", "resource_type": "macro", "name": "default__get_tables_by_prefix_sql", "macro_sql": "{% macro default__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n\n        select distinct \n            table_schema as \"table_schema\", table_name as \"table_name\"\n        from {{database}}.information_schema.tables\n        where table_schema ilike '{{ schema }}'\n        and table_name ilike '{{ prefix }}%'\n        and table_name not ilike '{{ exclude }}'\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__get_tables_by_prefix_sql": {"raw_sql": "{% macro get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    {{ adapter_macro('dbt_utils.get_tables_by_prefix_sql', schema, prefix, exclude, database) }}\n{% endmacro %}\n\n{% macro default__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n\n        select distinct \n            table_schema as \"table_schema\", table_name as \"table_name\"\n        from {{database}}.information_schema.tables\n        where table_schema ilike '{{ schema }}'\n        and table_name ilike '{{ prefix }}%'\n        and table_name not ilike '{{ exclude }}'\n\n{% endmacro %}\n\n\n{% macro bigquery__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    \n        select distinct\n            dataset_id as table_schema, table_id as table_name\n\n        from {{adapter.quote(database)}}.{{schema}}.__TABLES_SUMMARY__\n        where dataset_id = '{{schema}}'\n            and lower(table_id) like lower ('{{prefix}}%')\n            and lower(table_id) not like lower ('{{exclude}}')\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.bigquery__get_tables_by_prefix_sql", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/get_tables_by_prefix_sql.sql", "original_file_path": "macros/sql/get_tables_by_prefix_sql.sql", "resource_type": "macro", "name": "bigquery__get_tables_by_prefix_sql", "macro_sql": "{% macro bigquery__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    \n        select distinct\n            dataset_id as table_schema, table_id as table_name\n\n        from {{adapter.quote(database)}}.{{schema}}.__TABLES_SUMMARY__\n        where dataset_id = '{{schema}}'\n            and lower(table_id) like lower ('{{prefix}}%')\n            and lower(table_id) not like lower ('{{exclude}}')\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.star": {"raw_sql": "{% macro star(from, relation_alias=False, except=[]) -%}\n\n    {%- do dbt_utils._is_relation(from, 'star') -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n\n    {%- set include_cols = [] %}\n    {%- set cols = adapter.get_columns_in_relation(from) -%}\n    {%- for col in cols -%}\n\n        {%- if col.column not in except -%}\n            {% set _ = include_cols.append(col.column) %}\n\n        {%- endif %}\n    {%- endfor %}\n\n    {%- for col in include_cols %}\n\n        {%- if relation_alias %}{{ relation_alias }}.{% else %}{% endif %}{{ dbt_utils.identifier(col)|trim }}\n        {%- if not loop.last %},{{ '\\n' }}{% endif %}\n\n    {%- endfor -%}\n{%- endmacro %}", "unique_id": "macro.dbt_utils.star", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/star.sql", "original_file_path": "macros/sql/star.sql", "resource_type": "macro", "name": "star", "macro_sql": "{% macro star(from, relation_alias=False, except=[]) -%}\n\n    {%- do dbt_utils._is_relation(from, 'star') -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n\n    {%- set include_cols = [] %}\n    {%- set cols = adapter.get_columns_in_relation(from) -%}\n    {%- for col in cols -%}\n\n        {%- if col.column not in except -%}\n            {% set _ = include_cols.append(col.column) %}\n\n        {%- endif %}\n    {%- endfor %}\n\n    {%- for col in include_cols %}\n\n        {%- if relation_alias %}{{ relation_alias }}.{% else %}{% endif %}{{ dbt_utils.identifier(col)|trim }}\n        {%- if not loop.last %},{{ '\\n' }}{% endif %}\n\n    {%- endfor -%}\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.unpivot": {"raw_sql": "{#\nPivot values from columns to rows. Similar to pandas DataFrame melt() function.\n\nExample Usage: {{ unpivot(relation=ref('users'), cast_to='integer', exclude=['id','created_at']) }}\n\nArguments:\n    relation: Relation object, required.\n    cast_to: The datatype to cast all unpivoted columns to. Default is varchar.\n    exclude: A list of columns to keep but exclude from the unpivot operation. Default is none.\n    remove: A list of columns to remove from the resulting table. Default is none.\n    field_name: Destination table column name for the source table column names.\n    value_name: Destination table column name for the pivoted values\n#}\n\n{% macro unpivot(relation=none, cast_to='varchar', exclude=none, remove=none, field_name='field_name', value_name='value', table=none) -%}\n\n    {% if execute and table %}\n        {{ log(\"Warning: the `unpivot` macro no longer accepts a `table` parameter. This parameter will be deprecated in a future release of dbt-utils. Use the `relation` parameter instead\", info=True) }}\n    {% endif %}\n\n    {% if relation and table %}\n        {{ exceptions.raise_compiler_error(\"Error: both the `relation` and `table` parameters were provided to `unpivot` macro. Choose one only (we recommend `relation`).\") }}\n    {% elif not relation and table %}\n        {% set relation=table %}\n    {% elif not relation and not table %}\n        {{ exceptions.raise_compiler_error(\"Error: argument `relation` is required for `unpivot` macro.\") }}\n    {% endif %}\n\n  {%- set exclude = exclude if exclude is not none else [] %}\n  {%- set remove = remove if remove is not none else [] %}\n\n  {%- set include_cols = [] %}\n\n  {%- set table_columns = {} %}\n\n  {%- do table_columns.update({relation: []}) %}\n\n  {%- do dbt_utils._is_relation(relation, 'unpivot') -%}\n  {%- set cols = adapter.get_columns_in_relation(relation) %}\n\n  {%- for col in cols -%}\n    {%- if col.column.lower() not in remove|map('lower') and col.column.lower() not in exclude|map('lower') -%}\n      {% do include_cols.append(col) %}\n    {%- endif %}\n  {%- endfor %}\n\n\n  {%- for col in include_cols -%}\n    select\n      {%- for exclude_col in exclude %}\n        {{ exclude_col }},\n      {%- endfor %}\n\n      cast('{{ col.column }}' as {{ dbt_utils.type_string() }}) as {{ field_name }},\n      cast({{ col.column }} as {{ cast_to }}) as {{ value_name }}\n\n    from {{ relation }}\n\n    {% if not loop.last -%}\n      union all\n    {% endif -%}\n  {%- endfor -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.unpivot", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/unpivot.sql", "original_file_path": "macros/sql/unpivot.sql", "resource_type": "macro", "name": "unpivot", "macro_sql": "{% macro unpivot(relation=none, cast_to='varchar', exclude=none, remove=none, field_name='field_name', value_name='value', table=none) -%}\n\n    {% if execute and table %}\n        {{ log(\"Warning: the `unpivot` macro no longer accepts a `table` parameter. This parameter will be deprecated in a future release of dbt-utils. Use the `relation` parameter instead\", info=True) }}\n    {% endif %}\n\n    {% if relation and table %}\n        {{ exceptions.raise_compiler_error(\"Error: both the `relation` and `table` parameters were provided to `unpivot` macro. Choose one only (we recommend `relation`).\") }}\n    {% elif not relation and table %}\n        {% set relation=table %}\n    {% elif not relation and not table %}\n        {{ exceptions.raise_compiler_error(\"Error: argument `relation` is required for `unpivot` macro.\") }}\n    {% endif %}\n\n  {%- set exclude = exclude if exclude is not none else [] %}\n  {%- set remove = remove if remove is not none else [] %}\n\n  {%- set include_cols = [] %}\n\n  {%- set table_columns = {} %}\n\n  {%- do table_columns.update({relation: []}) %}\n\n  {%- do dbt_utils._is_relation(relation, 'unpivot') -%}\n  {%- set cols = adapter.get_columns_in_relation(relation) %}\n\n  {%- for col in cols -%}\n    {%- if col.column.lower() not in remove|map('lower') and col.column.lower() not in exclude|map('lower') -%}\n      {% do include_cols.append(col) %}\n    {%- endif %}\n  {%- endfor %}\n\n\n  {%- for col in include_cols -%}\n    select\n      {%- for exclude_col in exclude %}\n        {{ exclude_col }},\n      {%- endfor %}\n\n      cast('{{ col.column }}' as {{ dbt_utils.type_string() }}) as {{ field_name }},\n      cast({{ col.column }} as {{ cast_to }}) as {{ value_name }}\n\n    from {{ relation }}\n\n    {% if not loop.last -%}\n      union all\n    {% endif -%}\n  {%- endfor -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.union_relations": {"raw_sql": "{% macro union_relations(relations, column_override=none, include=[], exclude=[], source_column_name=none) -%}\n\n    {%- if exclude and include -%}\n        {{ exceptions.raise_compiler_error(\"Both an exclude and include list were provided to the `union` macro. Only one is allowed\") }}\n    {%- endif -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n\n    {%- set column_override = column_override if column_override is not none else {} %}\n    {%- set source_column_name = source_column_name if source_column_name is not none else '_dbt_source_relation' %}\n\n    {%- set relation_columns = {} %}\n    {%- set column_superset = {} %}\n\n    {%- for relation in relations -%}\n\n        {%- do relation_columns.update({relation: []}) %}\n\n        {%- do dbt_utils._is_relation(relation, 'union_relations') -%}\n        {%- set cols = adapter.get_columns_in_relation(relation) %}\n        {%- for col in cols -%}\n\n        {#- If an exclude list was provided and the column is in the list, do nothing #}\n        {%- if exclude and col.column in exclude %}\n\n        {#- If an include list was provided and the column is not in the list, do nothing -#}\n        {%- elif include and col.column not in include %}\n\n        {#- Otherwise add the column to the column superset #}\n        {% else %}\n\n            {# update the list of columns in this relation #}\n            {%- do relation_columns[relation].append(col.column) %}\n\n            {%- if col.column in column_superset -%}\n\n                {%- set stored = column_superset[col.column] %}\n                {%- if col.is_string() and stored.is_string() and col.string_size() > stored.string_size() -%}\n\n                    {%- do column_superset.update({col.column: col}) %}\n\n                {%- endif %}\n\n            {%- else -%}\n\n                {%- do column_superset.update({col.column: col}) %}\n\n            {%- endif -%}\n\n        {%- endif -%}\n\n        {%- endfor %}\n    {%- endfor %}\n\n    {%- set ordered_column_names = column_superset.keys() %}\n\n    {%- for relation in relations -%}\n\n        (\n            select\n\n                cast({{ dbt_utils.string_literal(relation) }} as {{ dbt_utils.type_string() }}) as {{ source_column_name }},\n\n                {% for col_name in ordered_column_names -%}\n\n                    {%- set col = column_superset[col_name] %}\n                    {%- set col_type = column_override.get(col.column, col.data_type) %}\n                    {%- set col_name = adapter.quote(col_name) if col_name in relation_columns[relation] else 'null' %}\n                    cast({{ col_name }} as {{ col_type }}) as {{ col.quoted }} {% if not loop.last %},{% endif %}\n                {%- endfor %}\n\n            from {{ relation }}\n        )\n\n        {% if not loop.last %} union all {% endif %}\n\n    {%- endfor %}\n\n{%- endmacro %}\n\n{% macro union_tables(tables, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_table') -%}\n\n    {% if execute %}\n        {{ log(\"Warning: the `union_tables` macro is no longer supported and will be deprecated in a future release of dbt-utils. Use the `union_relations` macro instead\", info=True) }}\n    {% endif %}\n\n    {{ return(dbt_utils.union_relations(tables, column_override, include, exclude, source_column_name)) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.union_relations", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/union.sql", "original_file_path": "macros/sql/union.sql", "resource_type": "macro", "name": "union_relations", "macro_sql": "{% macro union_relations(relations, column_override=none, include=[], exclude=[], source_column_name=none) -%}\n\n    {%- if exclude and include -%}\n        {{ exceptions.raise_compiler_error(\"Both an exclude and include list were provided to the `union` macro. Only one is allowed\") }}\n    {%- endif -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n\n    {%- set column_override = column_override if column_override is not none else {} %}\n    {%- set source_column_name = source_column_name if source_column_name is not none else '_dbt_source_relation' %}\n\n    {%- set relation_columns = {} %}\n    {%- set column_superset = {} %}\n\n    {%- for relation in relations -%}\n\n        {%- do relation_columns.update({relation: []}) %}\n\n        {%- do dbt_utils._is_relation(relation, 'union_relations') -%}\n        {%- set cols = adapter.get_columns_in_relation(relation) %}\n        {%- for col in cols -%}\n\n        {#- If an exclude list was provided and the column is in the list, do nothing #}\n        {%- if exclude and col.column in exclude %}\n\n        {#- If an include list was provided and the column is not in the list, do nothing -#}\n        {%- elif include and col.column not in include %}\n\n        {#- Otherwise add the column to the column superset #}\n        {% else %}\n\n            {# update the list of columns in this relation #}\n            {%- do relation_columns[relation].append(col.column) %}\n\n            {%- if col.column in column_superset -%}\n\n                {%- set stored = column_superset[col.column] %}\n                {%- if col.is_string() and stored.is_string() and col.string_size() > stored.string_size() -%}\n\n                    {%- do column_superset.update({col.column: col}) %}\n\n                {%- endif %}\n\n            {%- else -%}\n\n                {%- do column_superset.update({col.column: col}) %}\n\n            {%- endif -%}\n\n        {%- endif -%}\n\n        {%- endfor %}\n    {%- endfor %}\n\n    {%- set ordered_column_names = column_superset.keys() %}\n\n    {%- for relation in relations -%}\n\n        (\n            select\n\n                cast({{ dbt_utils.string_literal(relation) }} as {{ dbt_utils.type_string() }}) as {{ source_column_name }},\n\n                {% for col_name in ordered_column_names -%}\n\n                    {%- set col = column_superset[col_name] %}\n                    {%- set col_type = column_override.get(col.column, col.data_type) %}\n                    {%- set col_name = adapter.quote(col_name) if col_name in relation_columns[relation] else 'null' %}\n                    cast({{ col_name }} as {{ col_type }}) as {{ col.quoted }} {% if not loop.last %},{% endif %}\n                {%- endfor %}\n\n            from {{ relation }}\n        )\n\n        {% if not loop.last %} union all {% endif %}\n\n    {%- endfor %}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.union_tables": {"raw_sql": "{% macro union_relations(relations, column_override=none, include=[], exclude=[], source_column_name=none) -%}\n\n    {%- if exclude and include -%}\n        {{ exceptions.raise_compiler_error(\"Both an exclude and include list were provided to the `union` macro. Only one is allowed\") }}\n    {%- endif -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n\n    {%- set column_override = column_override if column_override is not none else {} %}\n    {%- set source_column_name = source_column_name if source_column_name is not none else '_dbt_source_relation' %}\n\n    {%- set relation_columns = {} %}\n    {%- set column_superset = {} %}\n\n    {%- for relation in relations -%}\n\n        {%- do relation_columns.update({relation: []}) %}\n\n        {%- do dbt_utils._is_relation(relation, 'union_relations') -%}\n        {%- set cols = adapter.get_columns_in_relation(relation) %}\n        {%- for col in cols -%}\n\n        {#- If an exclude list was provided and the column is in the list, do nothing #}\n        {%- if exclude and col.column in exclude %}\n\n        {#- If an include list was provided and the column is not in the list, do nothing -#}\n        {%- elif include and col.column not in include %}\n\n        {#- Otherwise add the column to the column superset #}\n        {% else %}\n\n            {# update the list of columns in this relation #}\n            {%- do relation_columns[relation].append(col.column) %}\n\n            {%- if col.column in column_superset -%}\n\n                {%- set stored = column_superset[col.column] %}\n                {%- if col.is_string() and stored.is_string() and col.string_size() > stored.string_size() -%}\n\n                    {%- do column_superset.update({col.column: col}) %}\n\n                {%- endif %}\n\n            {%- else -%}\n\n                {%- do column_superset.update({col.column: col}) %}\n\n            {%- endif -%}\n\n        {%- endif -%}\n\n        {%- endfor %}\n    {%- endfor %}\n\n    {%- set ordered_column_names = column_superset.keys() %}\n\n    {%- for relation in relations -%}\n\n        (\n            select\n\n                cast({{ dbt_utils.string_literal(relation) }} as {{ dbt_utils.type_string() }}) as {{ source_column_name }},\n\n                {% for col_name in ordered_column_names -%}\n\n                    {%- set col = column_superset[col_name] %}\n                    {%- set col_type = column_override.get(col.column, col.data_type) %}\n                    {%- set col_name = adapter.quote(col_name) if col_name in relation_columns[relation] else 'null' %}\n                    cast({{ col_name }} as {{ col_type }}) as {{ col.quoted }} {% if not loop.last %},{% endif %}\n                {%- endfor %}\n\n            from {{ relation }}\n        )\n\n        {% if not loop.last %} union all {% endif %}\n\n    {%- endfor %}\n\n{%- endmacro %}\n\n{% macro union_tables(tables, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_table') -%}\n\n    {% if execute %}\n        {{ log(\"Warning: the `union_tables` macro is no longer supported and will be deprecated in a future release of dbt-utils. Use the `union_relations` macro instead\", info=True) }}\n    {% endif %}\n\n    {{ return(dbt_utils.union_relations(tables, column_override, include, exclude, source_column_name)) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.union_tables", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/union.sql", "original_file_path": "macros/sql/union.sql", "resource_type": "macro", "name": "union_tables", "macro_sql": "{% macro union_tables(tables, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_table') -%}\n\n    {% if execute %}\n        {{ log(\"Warning: the `union_tables` macro is no longer supported and will be deprecated in a future release of dbt-utils. Use the `union_relations` macro instead\", info=True) }}\n    {% endif %}\n\n    {{ return(dbt_utils.union_relations(tables, column_override, include, exclude, source_column_name)) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.group_by": {"raw_sql": "{%- macro group_by(n) -%}\n\n  group by {% for i in range(1, n + 1) -%}\n      {{ i }}{{ ',' if not loop.last }}   \n   {%- endfor -%}\n\n{%- endmacro -%}", "unique_id": "macro.dbt_utils.group_by", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/groupby.sql", "original_file_path": "macros/sql/groupby.sql", "resource_type": "macro", "name": "group_by", "macro_sql": "{%- macro group_by(n) -%}\n\n  group by {% for i in range(1, n + 1) -%}\n      {{ i }}{{ ',' if not loop.last }}   \n   {%- endfor -%}\n\n{%- endmacro -%}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.surrogate_key": {"raw_sql": "{%- macro surrogate_key() -%}\n\n{% set fields = [] %}\n\n{%- for field in varargs -%}\n\n    {% set _ = fields.append(\n        \"coalesce(cast(\" ~ field ~ \" as \" ~ dbt_utils.type_string() ~ \"), '')\"\n    ) %}\n\n    {% if not loop.last %}\n        {% set _ = fields.append(\"'-'\") %}\n    {% endif %}\n\n{%- endfor -%}\n\n{{dbt_utils.hash(dbt_utils.concat(fields))}}\n\n{%- endmacro -%}", "unique_id": "macro.dbt_utils.surrogate_key", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/surrogate_key.sql", "original_file_path": "macros/sql/surrogate_key.sql", "resource_type": "macro", "name": "surrogate_key", "macro_sql": "{%- macro surrogate_key() -%}\n\n{% set fields = [] %}\n\n{%- for field in varargs -%}\n\n    {% set _ = fields.append(\n        \"coalesce(cast(\" ~ field ~ \" as \" ~ dbt_utils.type_string() ~ \"), '')\"\n    ) %}\n\n    {% if not loop.last %}\n        {% set _ = fields.append(\"'-'\") %}\n    {% endif %}\n\n{%- endfor -%}\n\n{{dbt_utils.hash(dbt_utils.concat(fields))}}\n\n{%- endmacro -%}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.nullcheck": {"raw_sql": "{% macro nullcheck(cols) %}\n{%- for col in cols %}\n\n    {% if col.is_string() -%}\n\n    nullif({{col.name}},'') as {{col.name}}\n\n    {%- else -%}\n\n    {{col.name}}\n\n    {%- endif -%}\n\n{%- if not loop.last -%} , {%- endif -%}\n\n{%- endfor -%}\n{% endmacro %}", "unique_id": "macro.dbt_utils.nullcheck", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/nullcheck.sql", "original_file_path": "macros/sql/nullcheck.sql", "resource_type": "macro", "name": "nullcheck", "macro_sql": "{% macro nullcheck(cols) %}\n{%- for col in cols %}\n\n    {% if col.is_string() -%}\n\n    nullif({{col.name}},'') as {{col.name}}\n\n    {%- else -%}\n\n    {{col.name}}\n\n    {%- endif -%}\n\n{%- if not loop.last -%} , {%- endif -%}\n\n{%- endfor -%}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_column_values": {"raw_sql": "{#\nThis macro fetches the unique values for `column` in the table `table`\n\nArguments:\n    table: A model `ref`, or a schema.table string for the table to query (Required)\n    column: The column to query for unique values\n    max_records: If provided, the maximum number of unique records to return (default: none)\n\nReturns:\n    A list of distinct values for the specified columns\n#}\n\n{% macro get_column_values(table, column, max_records=none, default=none) -%}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n{#--  #}\n\n    {%- set target_relation = adapter.get_relation(database=table.database,\n                                          schema=table.schema,\n                                         identifier=table.identifier) -%}\n\n    {%- call statement('get_column_values', fetch_result=true) %}\n\n        {%- if not target_relation and default is none -%}\n\n          {{ exceptions.raise_compiler_error(\"In get_column_values(): relation \" ~ table ~ \" does not exist and no default value was provided.\") }}\n\n        {%- elif not target_relation and default is not none -%}\n\n          {{ log(\"Relation \" ~ table ~ \" does not exist. Returning the default value: \" ~ default) }}\n\n          {{ return(default) }}\n\n        {%- else -%}\n\n            select\n                {{ column }} as value\n\n            from {{ target_relation }}\n            group by 1\n            order by count(*) desc\n\n            {% if max_records is not none %}\n            limit {{ max_records }}\n            {% endif %}\n\n        {% endif %}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_column_values') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values) }}\n    {%- else -%}\n        {{ return(default) }}\n    {%- endif -%}\n\n{%- endmacro %}", "unique_id": "macro.dbt_utils.get_column_values", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/get_column_values.sql", "original_file_path": "macros/sql/get_column_values.sql", "resource_type": "macro", "name": "get_column_values", "macro_sql": "{% macro get_column_values(table, column, max_records=none, default=none) -%}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n{#--  #}\n\n    {%- set target_relation = adapter.get_relation(database=table.database,\n                                          schema=table.schema,\n                                         identifier=table.identifier) -%}\n\n    {%- call statement('get_column_values', fetch_result=true) %}\n\n        {%- if not target_relation and default is none -%}\n\n          {{ exceptions.raise_compiler_error(\"In get_column_values(): relation \" ~ table ~ \" does not exist and no default value was provided.\") }}\n\n        {%- elif not target_relation and default is not none -%}\n\n          {{ log(\"Relation \" ~ table ~ \" does not exist. Returning the default value: \" ~ default) }}\n\n          {{ return(default) }}\n\n        {%- else -%}\n\n            select\n                {{ column }} as value\n\n            from {{ target_relation }}\n            group by 1\n            order by count(*) desc\n\n            {% if max_records is not none %}\n            limit {{ max_records }}\n            {% endif %}\n\n        {% endif %}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_column_values') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values) }}\n    {%- else -%}\n        {{ return(default) }}\n    {%- endif -%}\n\n{%- endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.pivot": {"raw_sql": "{#\nPivot values from rows to columns.\n\nExample:\n\n    Input: `public.test`\n\n    | size | color |\n    |------+-------|\n    | S    | red   |\n    | S    | blue  |\n    | S    | red   |\n    | M    | red   |\n\n    select\n      size,\n      {{ dbt_utils.pivot('color', dbt_utils.get_column_values('public.test',\n                                                              'color')) }}\n    from public.test\n    group by size\n\n    Output:\n\n    | size | red | blue |\n    |------+-----+------|\n    | S    | 2   | 1    |\n    | M    | 1   | 0    |\n\nArguments:\n    column: Column name, required\n    values: List of row values to turn into columns, required\n    alias: Whether to create column aliases, default is True\n    agg: SQL aggregation function, default is sum\n    cmp: SQL value comparison, default is =\n    prefix: Column alias prefix, default is blank\n    suffix: Column alias postfix, default is blank\n    then_value: Value to use if comparison succeeds, default is 1\n    else_value: Value to use if comparison fails, default is 0\n    quote_identifiers: Whether to surround column aliases with double quotes, default is true\n#}\n\n{% macro pivot(column,\n               values,\n               alias=True,\n               agg='sum',\n               cmp='=',\n               prefix='',\n               suffix='',\n               then_value=1,\n               else_value=0,\n               quote_identifiers=True) %}\n  {% for v in values %}\n    {{ agg }}(\n      case\n      when {{ column }} {{ cmp }} '{{ v }}'\n        then {{ then_value }}\n      else {{ else_value }}\n      end\n    )\n    {% if alias %}\n      {% if quote_identifiers %}\n            as {{ adapter.quote(prefix ~ v ~ suffix) }}\n      {% else %}\n        as {{prefix ~ v ~ suffix }}\n      {% endif %}\n    {% endif %}\n    {% if not loop.last %},{% endif %}\n  {% endfor %}\n{% endmacro %}", "unique_id": "macro.dbt_utils.pivot", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/pivot.sql", "original_file_path": "macros/sql/pivot.sql", "resource_type": "macro", "name": "pivot", "macro_sql": "{% macro pivot(column,\n               values,\n               alias=True,\n               agg='sum',\n               cmp='=',\n               prefix='',\n               suffix='',\n               then_value=1,\n               else_value=0,\n               quote_identifiers=True) %}\n  {% for v in values %}\n    {{ agg }}(\n      case\n      when {{ column }} {{ cmp }} '{{ v }}'\n        then {{ then_value }}\n      else {{ else_value }}\n      end\n    )\n    {% if alias %}\n      {% if quote_identifiers %}\n            as {{ adapter.quote(prefix ~ v ~ suffix) }}\n      {% else %}\n        as {{prefix ~ v ~ suffix }}\n      {% endif %}\n    {% endif %}\n    {% if not loop.last %},{% endif %}\n  {% endfor %}\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_query_results_as_dict": {"raw_sql": "{% macro get_query_results_as_dict(query) %}\n{# This macro returns a dictionary of the form {column_name: (tuple_of_results)} #}\n\n    {%- call statement('get_query_results', fetch_result=True,auto_begin=false) -%}\n\n        {{ query }}\n\n    {%- endcall -%}\n\n    {% set sql_results={} %}\n\n    {%- if execute -%}\n        {% set sql_results_table = load_result('get_query_results').table.columns %}\n        {% for column_name, column in sql_results_table.items() %}\n            {% do sql_results.update({column_name: column.values()}) %}\n        {% endfor %}\n    {%- endif -%}\n\n    {{ return(sql_results) }}\n\n{% endmacro %}", "unique_id": "macro.dbt_utils.get_query_results_as_dict", "package_name": "dbt_utils", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils", "path": "macros/sql/get_query_results_as_dict.sql", "original_file_path": "macros/sql/get_query_results_as_dict.sql", "resource_type": "macro", "name": "get_query_results_as_dict", "macro_sql": "{% macro get_query_results_as_dict(query) %}\n{# This macro returns a dictionary of the form {column_name: (tuple_of_results)} #}\n\n    {%- call statement('get_query_results', fetch_result=True,auto_begin=false) -%}\n\n        {{ query }}\n\n    {%- endcall -%}\n\n    {% set sql_results={} %}\n\n    {%- if execute -%}\n        {% set sql_results_table = load_result('get_query_results').table.columns %}\n        {% for column_name, column in sql_results_table.items() %}\n            {% do sql_results.update({column_name: column.values()}) %}\n        {% endfor %}\n    {%- endif -%}\n\n    {{ return(sql_results) }}\n\n{% endmacro %}", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "patch_path": null, "arguments": []}}, "docs": {"dbt.__overview__": {"unique_id": "dbt.__overview__", "package_name": "dbt", "root_path": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project", "path": "overview.md", "original_file_path": "docs/overview.md", "file_contents": "{% docs __overview__ %}\n\n### Welcome!\n\nWelcome to the auto-generated documentation for your dbt project!\n\n### Navigation\n\nYou can use the `Project` and `Database` navigation tabs on the left side of the window to explore the models\nin your project.\n\n#### Project Tab\nThe `Project` tab mirrors the directory structure of your dbt project. In this tab, you can see all of the\nmodels defined in your dbt project, as well as models imported from dbt packages.\n\n#### Database Tab\nThe `Database` tab also exposes your models, but in a format that looks more like a database explorer. This view\nshows relations (tables and views) grouped into database schemas. Note that ephemeral models are _not_ shown\nin this interface, as they do not exist in the database.\n\n### Graph Exploration\nYou can click the blue icon on the bottom-right corner of the page to view the lineage graph of your models.\n\nOn model pages, you'll see the immediate parents and children of the model you're exploring. By clicking the `Expand`\nbutton at the top-right of this lineage pane, you'll be able to see all of the models that are used to build,\nor are built from, the model you're exploring.\n\nOnce expanded, you'll be able to use the `--models` and `--exclude` model selection syntax to filter the\nmodels in the graph. For more information on model selection, check out the [dbt docs](https://docs.getdbt.com/docs/model-selection-syntax).\n\nNote that you can also right-click on models to interactively filter and explore the graph.\n\n---\n\n### More information\n\n- [What is dbt](https://docs.getdbt.com/docs/overview)?\n- Read the [dbt viewpoint](https://docs.getdbt.com/docs/viewpoint)\n- [Installation](https://docs.getdbt.com/docs/installation)\n- Join the [chat](https://slack.getdbt.com/) on Slack for live questions and support.\n\n{% enddocs %}", "name": "__overview__", "block_contents": "### Welcome!\n\nWelcome to the auto-generated documentation for your dbt project!\n\n### Navigation\n\nYou can use the `Project` and `Database` navigation tabs on the left side of the window to explore the models\nin your project.\n\n#### Project Tab\nThe `Project` tab mirrors the directory structure of your dbt project. In this tab, you can see all of the\nmodels defined in your dbt project, as well as models imported from dbt packages.\n\n#### Database Tab\nThe `Database` tab also exposes your models, but in a format that looks more like a database explorer. This view\nshows relations (tables and views) grouped into database schemas. Note that ephemeral models are _not_ shown\nin this interface, as they do not exist in the database.\n\n### Graph Exploration\nYou can click the blue icon on the bottom-right corner of the page to view the lineage graph of your models.\n\nOn model pages, you'll see the immediate parents and children of the model you're exploring. By clicking the `Expand`\nbutton at the top-right of this lineage pane, you'll be able to see all of the models that are used to build,\nor are built from, the model you're exploring.\n\nOnce expanded, you'll be able to use the `--models` and `--exclude` model selection syntax to filter the\nmodels in the graph. For more information on model selection, check out the [dbt docs](https://docs.getdbt.com/docs/model-selection-syntax).\n\nNote that you can also right-click on models to interactively filter and explore the graph.\n\n---\n\n### More information\n\n- [What is dbt](https://docs.getdbt.com/docs/overview)?\n- Read the [dbt viewpoint](https://docs.getdbt.com/docs/viewpoint)\n- [Installation](https://docs.getdbt.com/docs/installation)\n- Join the [chat](https://slack.getdbt.com/) on Slack for live questions and support."}, "segment.segment_web_user_stitching": {"unique_id": "segment.segment_web_user_stitching", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "sessionization/docs.md", "original_file_path": "models/sessionization/docs.md", "file_contents": "{% docs segment_web_user_stitching %}\n\nThis model performs \"user stitching\" on top of web event data. User stitching is the process of tying all events associated with a cookie to the same user_id, and solves a common problem in event analytics that users are only identified part way through their activity stream. This model returns a single user_id for every anonymous_id, and is later joined in to build a `blended_user_id` field, that acts as the primary user identifier for all sessions.\n\n{% enddocs %}", "name": "segment_web_user_stitching", "block_contents": "This model performs \"user stitching\" on top of web event data. User stitching is the process of tying all events associated with a cookie to the same user_id, and solves a common problem in event analytics that users are only identified part way through their activity stream. This model returns a single user_id for every anonymous_id, and is later joined in to build a `blended_user_id` field, that acts as the primary user identifier for all sessions."}, "segment.segment_web_page_views__sessionized": {"unique_id": "segment.segment_web_page_views__sessionized", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "sessionization/docs.md", "original_file_path": "models/sessionization/docs.md", "file_contents": "{% docs segment_web_page_views__sessionized %}\n\nThe purpose of this model is to assign a `session_id` to page views. The business logic of how this is done is that any period of inactivity of 30 minutes or more resets the session, and any subsequent page views are assigned a new `session_id`.\n\nThe implementation of this logic is rather involved, and requires multiple CTEs. Comments have been added to the source to describe the purpose of the CTEs that are more esoteric.\n\n{% enddocs %}", "name": "segment_web_page_views__sessionized", "block_contents": "The purpose of this model is to assign a `session_id` to page views. The business logic of how this is done is that any period of inactivity of 30 minutes or more resets the session, and any subsequent page views are assigned a new `session_id`.\n\nThe implementation of this logic is rather involved, and requires multiple CTEs. Comments have been added to the source to describe the purpose of the CTEs that are more esoteric."}, "segment.segment_web_sessions__initial": {"unique_id": "segment.segment_web_sessions__initial", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "sessionization/docs.md", "original_file_path": "models/sessionization/docs.md", "file_contents": "{% docs segment_web_sessions__initial %}\n\nThis model performs the aggregation of page views into sessions. The `session_id` having already been calculated in `segment_web_page_views__sessionized`, this model simply calls a bunch of window functions to grab the first or last value of a given field and store it at the session level. \n\n{% enddocs %}", "name": "segment_web_sessions__initial", "block_contents": "This model performs the aggregation of page views into sessions. The `session_id` having already been calculated in `segment_web_page_views__sessionized`, this model simply calls a bunch of window functions to grab the first or last value of a given field and store it at the session level."}, "segment.segment_web_sessions__stitched": {"unique_id": "segment.segment_web_sessions__stitched", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "sessionization/docs.md", "original_file_path": "models/sessionization/docs.md", "file_contents": "{% docs segment_web_sessions__stitched %}\n\nThis model joins initial session data with user stitching to get the field `blended_user_id`, the id for a user across all devices that they can be identified on. This logic is broken out from other models because, while incremental, it will frequently need to be rebuilt from scratch: this is because the user stitching process can change the `blended_user_id` values for historical sessions.\n\nIt is recommended to typically run this model in its default configuration (incrementally) but on some regular basis to do a `dbt run --full-refresh --models segment_web_sessions__stitched+` so that this model and downstream models get rebuilt.\n\n{% enddocs %}", "name": "segment_web_sessions__stitched", "block_contents": "This model joins initial session data with user stitching to get the field `blended_user_id`, the id for a user across all devices that they can be identified on. This logic is broken out from other models because, while incremental, it will frequently need to be rebuilt from scratch: this is because the user stitching process can change the `blended_user_id` values for historical sessions.\n\nIt is recommended to typically run this model in its default configuration (incrementally) but on some regular basis to do a `dbt run --full-refresh --models segment_web_sessions__stitched+` so that this model and downstream models get rebuilt."}, "segment.segment_web_sessions": {"unique_id": "segment.segment_web_sessions", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "sessionization/docs.md", "original_file_path": "models/sessionization/docs.md", "file_contents": "{% docs segment_web_sessions %}\n\nThe purpose of this model is to expose a single web session, derived from Segment web events. Sessions are the most common way that analysis of web visitor behavior is conducted, and although Segment doesn't natively output session data, this model uses standard logic to create sessions out of page view events. \n\nA session is meant to represent a single instance of web activity where a user is actively browsing a website. In this case, we are demarcating sessions by 30 minute windows of inactivity: if there is 30 minutes of inactivity between two page views, the second page view begins a new session. Additionally, page views across different devices will always be tied to different sessions.\n\nThe logic implemented in this particular model is responsible for incrementally calculating a user's session number; the core sessionization logic is done in upstream models.\n\n{% enddocs %}", "name": "segment_web_sessions", "block_contents": "The purpose of this model is to expose a single web session, derived from Segment web events. Sessions are the most common way that analysis of web visitor behavior is conducted, and although Segment doesn't natively output session data, this model uses standard logic to create sessions out of page view events. \n\nA session is meant to represent a single instance of web activity where a user is actively browsing a website. In this case, we are demarcating sessions by 30 minute windows of inactivity: if there is 30 minutes of inactivity between two page views, the second page view begins a new session. Additionally, page views across different devices will always be tied to different sessions.\n\nThe logic implemented in this particular model is responsible for incrementally calculating a user's session number; the core sessionization logic is done in upstream models."}, "segment.segment_web_page_views": {"unique_id": "segment.segment_web_page_views", "package_name": "segment", "root_path": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment", "path": "base/docs.md", "original_file_path": "models/base/docs.md", "file_contents": "{% docs segment_web_page_views %}\n\nThis is a base model for Segment's web page views table. It does some straightforward renaming and parsing of Segment raw data in this table.\n\n{% enddocs %}", "name": "segment_web_page_views", "block_contents": "This is a base model for Segment's web page views table. It does some straightforward renaming and parsing of Segment raw data in this table."}}, "disabled": [], "generated_at": "2020-03-26T18:15:26.790894Z", "parent_map": {"seed.segment_integration_tests.example_segment_pages": [], "model.segment.segment_web_user_stitching": ["model.segment.segment_web_page_views"], "model.segment.segment_web_sessions": ["model.segment.segment_web_sessions__stitched"], "model.segment.segment_web_sessions__stitched": ["model.segment.segment_web_sessions__initial", "model.segment.segment_web_user_stitching"], "model.segment.segment_web_sessions__initial": ["model.segment.segment_web_page_views__sessionized", "seed.segment.referrer_mapping"], "model.segment.segment_web_page_views__sessionized": ["model.segment.segment_web_page_views", "model.segment.segment_web_page_views"], "model.segment.segment_web_page_views": ["seed.segment_integration_tests.example_segment_pages"], "analysis.segment.audience_overview": ["model.segment.segment_web_sessions"], "seed.segment.referrer_mapping": [], "test.segment.unique_segment_web_user_stitching_anonymous_id": ["model.segment.segment_web_user_stitching"], "test.segment.not_null_segment_web_user_stitching_anonymous_id": ["model.segment.segment_web_user_stitching"], "test.segment.unique_segment_web_page_views__sessionized_page_view_id": ["model.segment.segment_web_page_views__sessionized"], "test.segment.not_null_segment_web_page_views__sessionized_page_view_id": ["model.segment.segment_web_page_views__sessionized"], "test.segment.unique_segment_web_sessions__initial_session_id": ["model.segment.segment_web_sessions__initial"], "test.segment.not_null_segment_web_sessions__initial_session_id": ["model.segment.segment_web_sessions__initial"], "test.segment.unique_segment_web_sessions__stitched_session_id": ["model.segment.segment_web_sessions__stitched"], "test.segment.not_null_segment_web_sessions__stitched_session_id": ["model.segment.segment_web_sessions__stitched"], "test.segment.unique_segment_web_sessions_session_id": ["model.segment.segment_web_sessions"], "test.segment.not_null_segment_web_sessions_session_id": ["model.segment.segment_web_sessions"], "test.segment.unique_segment_web_page_views_page_view_id": ["model.segment.segment_web_page_views"], "test.segment.not_null_segment_web_page_views_page_view_id": ["model.segment.segment_web_page_views"]}, "child_map": {"seed.segment_integration_tests.example_segment_pages": ["model.segment.segment_web_page_views"], "model.segment.segment_web_user_stitching": ["model.segment.segment_web_sessions__stitched", "test.segment.not_null_segment_web_user_stitching_anonymous_id", "test.segment.unique_segment_web_user_stitching_anonymous_id"], "model.segment.segment_web_sessions": ["analysis.segment.audience_overview", "test.segment.not_null_segment_web_sessions_session_id", "test.segment.unique_segment_web_sessions_session_id"], "model.segment.segment_web_sessions__stitched": ["model.segment.segment_web_sessions", "test.segment.not_null_segment_web_sessions__stitched_session_id", "test.segment.unique_segment_web_sessions__stitched_session_id"], "model.segment.segment_web_sessions__initial": ["model.segment.segment_web_sessions__stitched", "test.segment.not_null_segment_web_sessions__initial_session_id", "test.segment.unique_segment_web_sessions__initial_session_id"], "model.segment.segment_web_page_views__sessionized": ["model.segment.segment_web_sessions__initial", "test.segment.not_null_segment_web_page_views__sessionized_page_view_id", "test.segment.unique_segment_web_page_views__sessionized_page_view_id"], "model.segment.segment_web_page_views": ["model.segment.segment_web_page_views__sessionized", "model.segment.segment_web_page_views__sessionized", "model.segment.segment_web_user_stitching", "test.segment.not_null_segment_web_page_views_page_view_id", "test.segment.unique_segment_web_page_views_page_view_id"], "analysis.segment.audience_overview": [], "seed.segment.referrer_mapping": ["model.segment.segment_web_sessions__initial"], "test.segment.unique_segment_web_user_stitching_anonymous_id": [], "test.segment.not_null_segment_web_user_stitching_anonymous_id": [], "test.segment.unique_segment_web_page_views__sessionized_page_view_id": [], "test.segment.not_null_segment_web_page_views__sessionized_page_view_id": [], "test.segment.unique_segment_web_sessions__initial_session_id": [], "test.segment.not_null_segment_web_sessions__initial_session_id": [], "test.segment.unique_segment_web_sessions__stitched_session_id": [], "test.segment.not_null_segment_web_sessions__stitched_session_id": [], "test.segment.unique_segment_web_sessions_session_id": [], "test.segment.not_null_segment_web_sessions_session_id": [], "test.segment.unique_segment_web_page_views_page_view_id": [], "test.segment.not_null_segment_web_page_views_page_view_id": []}, "metadata": {"project_id": "768dcdf231b0a90a3c9fa9041a5dd572", "user_id": "34fae700-1411-475d-8280-18826dfec8d0", "send_anonymous_usage_stats": true, "adapter_type": "redshift"}, "files": {"/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/core.sql": {"path": {"searched_path": "macros", "relative_path": "core.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "9dde6e3cf4b01799f44b1c6d4f23e77f471567a1cbbeab763da5032f0d102821"}, "nodes": [], "docs": [], "macros": ["macro.dbt.statement", "macro.dbt.noop_statement"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/helpers.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/helpers.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "f29316a03082e0c4e9e0b9cc5d73af75206c9db845d01b1e2068d7bb2ab58090"}, "nodes": [], "docs": [], "macros": ["macro.dbt.run_hooks", "macro.dbt.column_list", "macro.dbt.column_list_for_create_table", "macro.dbt.make_hook_config", "macro.dbt.before_begin", "macro.dbt.in_transaction", "macro.dbt.after_commit", "macro.dbt.drop_relation_if_exists", "macro.dbt.load_relation"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/snapshot/snapshot_merge.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/snapshot/snapshot_merge.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "5c6f5982ea4f6a4efe7106b9706c78197d355ef5a50d9ca1c254ba9fe8b5d114"}, "nodes": [], "docs": [], "macros": ["macro.dbt.snapshot_merge_sql", "macro.dbt.default__snapshot_merge_sql"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/snapshot/strategies.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/snapshot/strategies.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "3f88751a98bef086ae59d67a8090e28140aebad8c3c4dbbf7fd462e422d808da"}, "nodes": [], "docs": [], "macros": ["macro.dbt.strategy_dispatch", "macro.dbt.snapshot_hash_arguments", "macro.dbt.default__snapshot_hash_arguments", "macro.dbt.snapshot_get_time", "macro.dbt.default__snapshot_get_time", "macro.dbt.snapshot_timestamp_strategy", "macro.dbt.snapshot_string_as_time", "macro.dbt.default__snapshot_string_as_time", "macro.dbt.snapshot_check_all_get_existing_columns", "macro.dbt.snapshot_check_strategy"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/snapshot/snapshot.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/snapshot/snapshot.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "3f8c4854169daa7257c62bb2ecf4ee532d0e87b59ed2151382e6c4728b259cce"}, "nodes": [], "docs": [], "macros": ["macro.dbt.create_columns", "macro.dbt.default__create_columns", "macro.dbt.post_snapshot", "macro.dbt.default__post_snapshot", "macro.dbt.snapshot_staging_table_inserts", "macro.dbt.snapshot_staging_table_updates", "macro.dbt.build_snapshot_table", "macro.dbt.get_or_create_relation", "macro.dbt.build_snapshot_staging_table", "macro.dbt.materialization_snapshot_default"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/seed/seed.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/seed/seed.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "3108894047b1bbf22594ec0e7e1cc9769c58bf3caa4f699b6827aa67dcdbc5dd"}, "nodes": [], "docs": [], "macros": ["macro.dbt.create_csv_table", "macro.dbt.reset_csv_table", "macro.dbt.load_csv_rows", "macro.dbt.default__create_csv_table", "macro.dbt.default__reset_csv_table", "macro.dbt.get_seed_column_quoted_csv", "macro.dbt.basic_load_csv_rows", "macro.dbt.default__load_csv_rows", "macro.dbt.materialization_seed_default"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/incremental/helpers.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/incremental/helpers.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "c37f9127e9c8a575db6ac76470aa8e4bea07d5d8c714511349a74607e32306e1"}, "nodes": [], "docs": [], "macros": ["macro.dbt.incremental_upsert"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/incremental/incremental.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/incremental/incremental.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "f29fd9555f8f24be85b629603b4499e3eac7dde2e52d92343921b6506fad07c7"}, "nodes": [], "docs": [], "macros": ["macro.dbt.materialization_incremental_default"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/common/merge.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/common/merge.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "6f9ce33fdf66a2fa542434570298490548047e6e0ae845d82424bac51bba2322"}, "nodes": [], "docs": [], "macros": ["macro.dbt.get_merge_sql", "macro.dbt.get_delete_insert_merge_sql", "macro.dbt.get_insert_overwrite_merge_sql", "macro.dbt.default__get_merge_sql", "macro.dbt.get_quoted_csv", "macro.dbt.common_get_delete_insert_merge_sql", "macro.dbt.default__get_delete_insert_merge_sql", "macro.dbt.default__get_insert_overwrite_merge_sql"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/table/table.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/table/table.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "7532a98937b3f467b639610ab7d68b121f94f2570576e84ebb285e326c52d93f"}, "nodes": [], "docs": [], "macros": ["macro.dbt.materialization_table_default"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/view/view.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/view/view.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "495441a9fa472aa6e369a9e87c469e3e82bd2f5cdf90605a3e574b6bfcf9a999"}, "nodes": [], "docs": [], "macros": ["macro.dbt.materialization_view_default"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/materializations/view/create_or_replace_view.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/view/create_or_replace_view.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "f248f585af455af494d885fb929bcca529e44e080670740feb2c792674599eba"}, "nodes": [], "docs": [], "macros": ["macro.dbt.handle_existing_table", "macro.dbt.default__handle_existing_table", "macro.dbt.create_or_replace_view"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/etc/get_custom_alias.sql": {"path": {"searched_path": "macros", "relative_path": "etc/get_custom_alias.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "a5e6fbf352700a021e2a4726818beb8b164bb8f29d664fbb68aa8fe142ec589e"}, "nodes": [], "docs": [], "macros": ["macro.dbt.generate_alias_name"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/etc/query.sql": {"path": {"searched_path": "macros", "relative_path": "etc/query.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "332f51dd1615c90e372c87aeb65651c2a66a6f8313be34dfae1e91eb7c5e1316"}, "nodes": [], "docs": [], "macros": ["macro.dbt.run_query"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/etc/is_incremental.sql": {"path": {"searched_path": "macros", "relative_path": "etc/is_incremental.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "08a74e7b1a42476e996dedbd89c97ffb47e95c864b9fec6ddad6e9771eeeb7f1"}, "nodes": [], "docs": [], "macros": ["macro.dbt.is_incremental"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/etc/get_relation_comment.sql": {"path": {"searched_path": "macros", "relative_path": "etc/get_relation_comment.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "653267a61c95a535c6d47f8baea9dbbc533fcb3c671e6cd1d8ac5419d218da26"}, "nodes": [], "docs": [], "macros": ["macro.dbt.table_options", "macro.dbt.get_relation_comment"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/etc/datetime.sql": {"path": {"searched_path": "macros", "relative_path": "etc/datetime.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "0ebb8f28f68f1506962974dd513917a68a196f0cabf70ce3a43d9a72159ddc6c"}, "nodes": [], "docs": [], "macros": ["macro.dbt.convert_datetime", "macro.dbt.dates_in_range", "macro.dbt.partition_range", "macro.dbt.py_current_timestring"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/etc/get_custom_schema.sql": {"path": {"searched_path": "macros", "relative_path": "etc/get_custom_schema.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "3a7d4b9d5105010dd92327027f81c9e079b9a5cd68098b02682fedde376fa5de"}, "nodes": [], "docs": [], "macros": ["macro.dbt.generate_schema_name", "macro.dbt.generate_schema_name_for_env"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/etc/get_custom_database.sql": {"path": {"searched_path": "macros", "relative_path": "etc/get_custom_database.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "2b76c8cc7aede4270f5e37d5623788978688e5c382f4dc4e222453a592b0b532"}, "nodes": [], "docs": [], "macros": ["macro.dbt.generate_database_name"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/adapters/common.sql": {"path": {"searched_path": "macros", "relative_path": "adapters/common.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "b20f3411a1cb7997bdbbe6df7867d993d405230b63c8bf14710eb9fefd96ca56"}, "nodes": [], "docs": [], "macros": ["macro.dbt.adapter_macro", "macro.dbt.get_columns_in_query", "macro.dbt.default__get_columns_in_query", "macro.dbt.create_schema", "macro.dbt.default__create_schema", "macro.dbt.drop_schema", "macro.dbt.default__drop_schema", "macro.dbt.create_table_as", "macro.dbt.default__create_table_as", "macro.dbt.create_view_as", "macro.dbt.default__create_view_as", "macro.dbt.get_catalog", "macro.dbt.default__get_catalog", "macro.dbt.get_columns_in_relation", "macro.dbt.sql_convert_columns_in_relation", "macro.dbt.default__get_columns_in_relation", "macro.dbt.alter_column_type", "macro.dbt.default__alter_column_type", "macro.dbt.drop_relation", "macro.dbt.default__drop_relation", "macro.dbt.truncate_relation", "macro.dbt.default__truncate_relation", "macro.dbt.rename_relation", "macro.dbt.default__rename_relation", "macro.dbt.information_schema_name", "macro.dbt.default__information_schema_name", "macro.dbt.list_schemas", "macro.dbt.default__list_schemas", "macro.dbt.check_schema_exists", "macro.dbt.default__check_schema_exists", "macro.dbt.list_relations_without_caching", "macro.dbt.default__list_relations_without_caching", "macro.dbt.current_timestamp", "macro.dbt.default__current_timestamp", "macro.dbt.collect_freshness", "macro.dbt.default__collect_freshness", "macro.dbt.make_temp_relation", "macro.dbt.default__make_temp_relation", "macro.dbt.set_sql_header"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/schema_tests/relationships.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/relationships.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "4f50036d55fcfe56fbe7d283b8d29b6af935ca7e9abffa57043e20e5680609be"}, "nodes": [], "docs": [], "macros": ["macro.dbt.test_relationships"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/schema_tests/not_null.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/not_null.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "a7fd6f2e1f9645059f33cd6a94598a2d72a7bf9c5d568eefc604b1824640efc7"}, "nodes": [], "docs": [], "macros": ["macro.dbt.test_not_null"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/schema_tests/unique.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/unique.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "a4d53f54a4fa7e846d347418471ebf00e364f4e850f2655e3ce8c6fb49e83bf4"}, "nodes": [], "docs": [], "macros": ["macro.dbt.test_unique"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/macros/schema_tests/accepted_values.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/accepted_values.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "b7c3adabeeb96b9e19e19a8fe0e9f56dcc5af20804a613f71f100eba8ae520a9"}, "nodes": [], "docs": [], "macros": ["macro.dbt.test_accepted_values"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift/macros/catalog.sql": {"path": {"searched_path": "macros", "relative_path": "catalog.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift"}, "checksum": {"name": "sha256", "checksum": "9111a46f1e702e83765e0702a6bfd26ce338d53084b519845cd576fa310ed0f8"}, "nodes": [], "docs": [], "macros": ["macro.dbt_redshift.redshift__get_base_catalog", "macro.dbt_redshift.redshift__get_extended_catalog", "macro.dbt_redshift.redshift__can_select_from", "macro.dbt_redshift.redshift__no_svv_table_info_warning", "macro.dbt_redshift.redshift__get_catalog"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift/macros/relations.sql": {"path": {"searched_path": "macros", "relative_path": "relations.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift"}, "checksum": {"name": "sha256", "checksum": "c249d423babe6c519e80b6f408532fccd6f48d75b339ac0c8171ca92e9c2f3fd"}, "nodes": [], "docs": [], "macros": ["macro.dbt_redshift.redshift__get_relations"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift/macros/adapters.sql": {"path": {"searched_path": "macros", "relative_path": "adapters.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift"}, "checksum": {"name": "sha256", "checksum": "5f64d4b31f1791c2bc3f8bc6b50cb9785fe71e74cea302b3bac6505741367c08"}, "nodes": [], "docs": [], "macros": ["macro.dbt_redshift.dist", "macro.dbt_redshift.sort", "macro.dbt_redshift.redshift__create_table_as", "macro.dbt_redshift.redshift__create_view_as", "macro.dbt_redshift.redshift__create_schema", "macro.dbt_redshift.redshift__drop_schema", "macro.dbt_redshift.redshift__get_columns_in_relation", "macro.dbt_redshift.redshift__list_relations_without_caching", "macro.dbt_redshift.redshift__information_schema_name", "macro.dbt_redshift.redshift__list_schemas", "macro.dbt_redshift.redshift__check_schema_exists", "macro.dbt_redshift.redshift__current_timestamp", "macro.dbt_redshift.redshift__snapshot_get_time", "macro.dbt_redshift.redshift__snapshot_string_as_time", "macro.dbt_redshift.redshift__make_temp_relation"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift/macros/materializations/snapshot_merge.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/snapshot_merge.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/redshift"}, "checksum": {"name": "sha256", "checksum": "0b7abdb6167c936c926efbafc0634df9264eb0a5c396649660cf26cac52bf053"}, "nodes": [], "docs": [], "macros": ["macro.dbt_redshift.redshift__snapshot_merge_sql"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres/macros/catalog.sql": {"path": {"searched_path": "macros", "relative_path": "catalog.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres"}, "checksum": {"name": "sha256", "checksum": "66026d3423ab9e6ed0f2ab7fb7924d2f474de06cb19453072df22fc13addf3cd"}, "nodes": [], "docs": [], "macros": ["macro.dbt_postgres.postgres__get_catalog"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres/macros/relations.sql": {"path": {"searched_path": "macros", "relative_path": "relations.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres"}, "checksum": {"name": "sha256", "checksum": "6b4cb13349d8314702b5eee62d8b6d4d1a14586b1851bcae7dc77ee5d1956ba9"}, "nodes": [], "docs": [], "macros": ["macro.dbt_postgres.postgres_get_relations"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres/macros/adapters.sql": {"path": {"searched_path": "macros", "relative_path": "adapters.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres"}, "checksum": {"name": "sha256", "checksum": "e8b9338cc35fd28109ed2b282dd89b18803bd8bfa7e9861dd7432d862896005d"}, "nodes": [], "docs": [], "macros": ["macro.dbt_postgres.postgres__create_table_as", "macro.dbt_postgres.postgres__create_schema", "macro.dbt_postgres.postgres__drop_schema", "macro.dbt_postgres.postgres__get_columns_in_relation", "macro.dbt_postgres.postgres__list_relations_without_caching", "macro.dbt_postgres.postgres__information_schema_name", "macro.dbt_postgres.postgres__list_schemas", "macro.dbt_postgres.postgres__check_schema_exists", "macro.dbt_postgres.postgres__current_timestamp", "macro.dbt_postgres.postgres__snapshot_string_as_time", "macro.dbt_postgres.postgres__snapshot_get_time", "macro.dbt_postgres.postgres__make_temp_relation"], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres/macros/materializations/snapshot_merge.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/snapshot_merge.sql", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/postgres"}, "checksum": {"name": "sha256", "checksum": "8b3bbe37eddd6ac43d224b116c4c9d4fa7c2729412c4ec69d409e15d2e140aa7"}, "nodes": [], "docs": [], "macros": ["macro.dbt_postgres.postgres__snapshot_merge_sql"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/except.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/except.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "6695ddb45bb31cebda6ddbd4d41b18552cf74cf5752c8a3c4ecaee4304274fa4"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.except", "macro.dbt_utils.default__except", "macro.dbt_utils.bigquery__except"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/replace.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/replace.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "31b87b44de1b4c36337a04baf357b92aaec9968c4b24361e65f345097c6106b8"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.replace", "macro.dbt_utils.default__replace"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/concat.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/concat.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "1e548194e9c92d6cd0a60e53651516fa28582854051d83523cd705e87da38832"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.concat", "macro.dbt_utils.default__concat", "macro.dbt_utils.alternative_concat", "macro.dbt_utils.redshift__concat", "macro.dbt_utils.snowflake__concat"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/identifer.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/identifer.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "bdaaf100faa62e971a7e2b766f21127cb9d9fd0aa11412c2840dc66f1355aaae"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.identifier", "macro.dbt_utils.default__identifier", "macro.dbt_utils.bigquery__identifier"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/datatypes.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/datatypes.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "8ee37eb4f2c2fd9e6086e5bd7589c7fc6008d8e6a8225b1e3beae1dd13afcb57"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.type_string", "macro.dbt_utils.default__type_string", "macro.dbt_utils.redshift__type_string", "macro.dbt_utils.postgres__type_string", "macro.dbt_utils.snowflake__type_string", "macro.dbt_utils.type_timestamp", "macro.dbt_utils.default__type_timestamp", "macro.dbt_utils.snowflake__type_timestamp", "macro.dbt_utils.type_float", "macro.dbt_utils.default__type_float", "macro.dbt_utils.bigquery__type_float", "macro.dbt_utils.type_numeric", "macro.dbt_utils.default__type_numeric", "macro.dbt_utils.bigquery__type_numeric", "macro.dbt_utils.type_bigint", "macro.dbt_utils.default__type_bigint", "macro.dbt_utils.bigquery__type_bigint", "macro.dbt_utils.type_int", "macro.dbt_utils.default__type_int", "macro.dbt_utils.bigquery__type_int"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/_is_relation.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/_is_relation.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "9d37d4547affe42d0f29d215fa3b68bfe00ab075aa8d988de70093b55ad6a68b"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils._is_relation"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/length.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/length.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "85f8613d4e8d7c7dbf5c2a0ff64723e6d756913271277d875683b54cece3b6b0"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.length", "macro.dbt_utils.default__length", "macro.dbt_utils.redshift__length"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/dateadd.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/dateadd.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "4463f081c3275fcf5e9e5e8af182fb2e81fafd9ac3e09d77035ea6473c843b7d"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.dateadd", "macro.dbt_utils.default__dateadd", "macro.dbt_utils.bigquery__dateadd", "macro.dbt_utils.postgres__dateadd"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/intersect.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/intersect.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "f5abb85f0b7d9e80b24ed0b3b11dd6a91b6b5b4caf0dbf0c21a070353b5b1d82"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.intersect", "macro.dbt_utils.default__intersect", "macro.dbt_utils.bigquery__intersect"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/right.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/right.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "ce8b346909fc377f131b8de6e40e49dc822da29ccd5d3add77079608a198a375"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.right", "macro.dbt_utils.default__right", "macro.dbt_utils.bigquery__right", "macro.dbt_utils.snowflake__right"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/datediff.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/datediff.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "f3cecf2575d87b90e19d000c52be2c0c83c25969ad193256bd1eab06886dff60"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.datediff", "macro.dbt_utils.default__datediff", "macro.dbt_utils.bigquery__datediff", "macro.dbt_utils.postgres__datediff"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/safe_cast.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/safe_cast.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "1ad027695168ced61cdba224ddca8f07e861d32aab95efd30008a0bce76241ac"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.safe_cast", "macro.dbt_utils.default__safe_cast", "macro.dbt_utils.snowflake__safe_cast", "macro.dbt_utils.bigquery__safe_cast"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/hash.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/hash.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "9ac8186a8bfa84a019a05caf6fbb6ecbdd15f9965ea4739dc565115df4c20cb4"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.hash", "macro.dbt_utils.default__hash", "macro.dbt_utils.bigquery__hash"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/position.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/position.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "b5d4dde3fa181616bcd106ae094cb6c75b21d14503e76c0d736d0dc65d92ceeb"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.position", "macro.dbt_utils.default__position", "macro.dbt_utils.bigquery__position"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/literal.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/literal.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "8355a51715ff75a4f65991a132e1f1b1086d60376f673804ef5806aa967e0775"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.string_literal", "macro.dbt_utils.default__string_literal"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/current_timestamp.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/current_timestamp.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "1e3d0b51c513a0670e0e4851cbc33801890e9813d64376ab2e43dc3c3744f039"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.current_timestamp", "macro.dbt_utils.default__current_timestamp", "macro.dbt_utils.redshift__current_timestamp", "macro.dbt_utils.bigquery__current_timestamp", "macro.dbt_utils.current_timestamp_in_utc", "macro.dbt_utils.default__current_timestamp_in_utc", "macro.dbt_utils.snowflake__current_timestamp_in_utc", "macro.dbt_utils.postgres__current_timestamp_in_utc"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/width_bucket.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/width_bucket.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "287296cc63427c7bd046e85aed1de4aa7fc73ebb3223b7f59e4ba68a20f23de1"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.width_bucket", "macro.dbt_utils.default__width_bucket", "macro.dbt_utils.redshift__width_bucket", "macro.dbt_utils.snowflake__width_bucket"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/last_day.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/last_day.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "1e207372f905a7d14f800b518761d85fedec738444b4e9ed7be02b9aeb5bbbfe"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.last_day", "macro.dbt_utils.default_last_day", "macro.dbt_utils.default__last_day", "macro.dbt_utils.postgres__last_day"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/split_part.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/split_part.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "ec1d9db903a2a00b513f90c8345682c076800e99e109228dce881b67c0e00cf7"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.split_part", "macro.dbt_utils.default__split_part", "macro.dbt_utils.bigquery__split_part"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/cross_db_utils/date_trunc.sql": {"path": {"searched_path": "macros", "relative_path": "cross_db_utils/date_trunc.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "2fec19945722b85c7fd737436589122d2959ed9c0bcc2d4778da32687ff992f2"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.date_trunc", "macro.dbt_utils.default__date_trunc", "macro.dbt_utils.bigquery__date_trunc"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/materializations/insert_by_period_materialization.sql": {"path": {"searched_path": "macros", "relative_path": "materializations/insert_by_period_materialization.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "6f4e65d6de0fe33a5f5259507b234831a288c563f56df9eaa70ef3eb5dd3b1b8"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_period_boundaries", "macro.dbt_utils.get_period_sql", "macro.dbt_utils.materialization_insert_by_period_default"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/logger/pretty_log_format.sql": {"path": {"searched_path": "macros", "relative_path": "logger/pretty_log_format.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "788092f1026c7d2fd3398f31870caf4f81d43b686c4af633a57fafd1aeef304a"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.pretty_log_format"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/logger/pretty_time.sql": {"path": {"searched_path": "macros", "relative_path": "logger/pretty_time.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "d5cdb4ceb135e1d855367d2ecb54e63b1fd01d3c9aa074852a553de789f45e5f"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.pretty_time"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/logger/log_info.sql": {"path": {"searched_path": "macros", "relative_path": "logger/log_info.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "6a0420dcc9a03bb7748026162ababb6e877a0e45d7697f77d8b228fd7c6cf717"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.log_info"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/datetime/date_spine.sql": {"path": {"searched_path": "macros", "relative_path": "datetime/date_spine.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "6e164f9e7198e71e4c2f18b0478b69405288b2a5cf8958596271eee490131575"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_intervals_between", "macro.dbt_utils.date_spine"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/web/get_url_host.sql": {"path": {"searched_path": "macros", "relative_path": "web/get_url_host.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "75246509db12e34e95190175211e0331063c8ed017a0bfac1dcbfd5da79c6ce8"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_url_host"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/web/get_url_path.sql": {"path": {"searched_path": "macros", "relative_path": "web/get_url_path.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "b976b094bc2a26a7b553431dc93fdefe28b129abd7155d8846e254046f02a39c"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_url_path"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/web/get_url_parameter.sql": {"path": {"searched_path": "macros", "relative_path": "web/get_url_parameter.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "b10234d9d0b1030a402a6a72a94f78a0d2293661a32cec604b0ef48c50511a56"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_url_parameter"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/geo/haversine_distance.sql": {"path": {"searched_path": "macros", "relative_path": "geo/haversine_distance.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "b5f48844bc062e5ad283aedbd9dd11d68863db6b0f81efbc767b384115079d62"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.haversine_distance"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/schema_tests/equal_rowcount.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/equal_rowcount.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "7163ce75cb298af96172c41a0ba73a184d9116a92d63889573d24a12e551f560"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_equal_rowcount"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/schema_tests/relationships_where.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/relationships_where.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "48c6eb8de34d6925bccf56ce59ee7d3d8dc2c1426f951b15f8ca4560125005b9"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_relationships_where"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/schema_tests/recency.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/recency.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "b2542d28abc4e53309c744b111fb1f2f4be2cfcf4f611b4a31b37aba0fed6bc2"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_recency"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/schema_tests/not_constant.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/not_constant.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "8710079ef29da7534dcb9728407af27814a247fa8d17080f5d1d4c39eee44023"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_not_constant"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/schema_tests/at_least_one.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/at_least_one.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "cc5c686c96681f67f0e97f49cc987b6d65115e8aaf51ea487e39f7865e3d335d"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_at_least_one"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/schema_tests/unique_combination_of_columns.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/unique_combination_of_columns.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "785bbaca0448f809197823afd810753c6a55124ece7bec7d4befe4dbd9eb39dd"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_unique_combination_of_columns"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/schema_tests/cardinality_equality.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/cardinality_equality.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "e037e4539e2f94632db24ca2526fc06a489dd60663bfbb5246e1d24ac4fdcae7"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_cardinality_equality"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/schema_tests/expression_is_true.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/expression_is_true.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "be92c446fea64c14d543c9b9944cf725d28161cf459fa3a17ce9f7be91cb1cac"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_expression_is_true"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/schema_tests/equality.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/equality.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "1bdac20b6a7592fe91748dfa489c964dbd433c1e1a9e9839937396b0b297a864"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_equality"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/schema_tests/mutually_exclusive_ranges.sql": {"path": {"searched_path": "macros", "relative_path": "schema_tests/mutually_exclusive_ranges.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "6d92959cd620e418f5faed654e21e126c956f1b370ca932675a5a7a53ace2539"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.test_mutually_exclusive_ranges"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/sql/nullcheck_table.sql": {"path": {"searched_path": "macros", "relative_path": "sql/nullcheck_table.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "9fd89ad3b49bf05c5ea4769e84687510cafcf255f7e3579613d1f8588ceb19cc"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.nullcheck_table"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/sql/generate_series.sql": {"path": {"searched_path": "macros", "relative_path": "sql/generate_series.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "1ca1782077c9ffef4532460d20b9f9f7a94495cff99f1342c48e46f2cd3c070b"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_powers_of_two", "macro.dbt_utils.generate_series"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/sql/get_relations_by_prefix.sql": {"path": {"searched_path": "macros", "relative_path": "sql/get_relations_by_prefix.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "86e15bf943f7a9bddf0ceb2fac257c944cf77143e9b0d16fd3f8c21c04adba64"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_relations_by_prefix", "macro.dbt_utils.get_tables_by_prefix"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/sql/get_tables_by_prefix_sql.sql": {"path": {"searched_path": "macros", "relative_path": "sql/get_tables_by_prefix_sql.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "e4eb8a02c7d6051e583231bd2f516f799611de36febf68599f8a7a74f883f08c"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_tables_by_prefix_sql", "macro.dbt_utils.default__get_tables_by_prefix_sql", "macro.dbt_utils.bigquery__get_tables_by_prefix_sql"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/sql/star.sql": {"path": {"searched_path": "macros", "relative_path": "sql/star.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "e5adedeb3df80e25df2d680fb384468bd389fd332a12119a46e8accae4cbd54d"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.star"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/sql/unpivot.sql": {"path": {"searched_path": "macros", "relative_path": "sql/unpivot.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "071b5b6f49b07cf7de141fb67878f942a7eb5d50d6b20bd44d678b1edd1a774f"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.unpivot"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/sql/union.sql": {"path": {"searched_path": "macros", "relative_path": "sql/union.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "6b3d705e5ad1f956cfd25bbff1db4c1cf51d6cd19258636bb1ce2919e3975690"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.union_relations", "macro.dbt_utils.union_tables"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/sql/groupby.sql": {"path": {"searched_path": "macros", "relative_path": "sql/groupby.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "ee3fb695561e40aeeed2d05a0dbea10331be8f039b07bd771e6a5741e02adead"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.group_by"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/sql/surrogate_key.sql": {"path": {"searched_path": "macros", "relative_path": "sql/surrogate_key.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "12bd84d1303045d702ad913c23a00913d2bd450e343818123ef39ed12a30387d"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.surrogate_key"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/sql/nullcheck.sql": {"path": {"searched_path": "macros", "relative_path": "sql/nullcheck.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "d2cd945bca708f6660ea54685dc57ee4abaa1266306dfb3d2e84e04174058c68"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.nullcheck"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/sql/get_column_values.sql": {"path": {"searched_path": "macros", "relative_path": "sql/get_column_values.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "ab0317329a6a695608746064c7a1cccca7d45e908b5f796bcb30cb53fea006fc"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_column_values"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/sql/pivot.sql": {"path": {"searched_path": "macros", "relative_path": "sql/pivot.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "d9ee0399b76d4b7c575a7dad9ba1ad0c2a2c20f9531edec2e2e4233b7d35a9f2"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.pivot"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils/macros/sql/get_query_results_as_dict.sql": {"path": {"searched_path": "macros", "relative_path": "sql/get_query_results_as_dict.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/dbt_utils"}, "checksum": {"name": "sha256", "checksum": "9b4b370b1667d3a3a0fd3cf2bdebcd04d2223bbc020f929132a99022589da2d5"}, "nodes": [], "docs": [], "macros": ["macro.dbt_utils.get_query_results_as_dict"], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/data/example_segment_pages.csv": {"path": {"searched_path": "data", "relative_path": "example_segment_pages.csv", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests"}, "checksum": {"name": "path", "checksum": "/Users/claire/fishtown/packages/segment/integration_tests/data/example_segment_pages.csv"}, "nodes": ["seed.segment_integration_tests.example_segment_pages"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project/docs/overview.md": {"path": {"searched_path": "docs", "relative_path": "overview.md", "project_root": "/usr/local/Cellar/dbt@0.16.0-rc2/0.16.0rc2_1/libexec/lib/python3.7/site-packages/dbt/include/global_project"}, "checksum": {"name": "sha256", "checksum": "66db3d93aa0f4fa15a61ea3441e71b887d93e11c626bb000d73b6da808231747"}, "nodes": [], "docs": ["dbt.__overview__"], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment/models/sessionization/segment_web_user_stitching.sql": {"path": {"searched_path": "models", "relative_path": "sessionization/segment_web_user_stitching.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment"}, "checksum": {"name": "sha256", "checksum": "bc17c765a644313f8cbb600ddb7f2672be38cc3738029492b1fe49717c6a1886"}, "nodes": ["model.segment.segment_web_user_stitching"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment/models/sessionization/segment_web_sessions.sql": {"path": {"searched_path": "models", "relative_path": "sessionization/segment_web_sessions.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment"}, "checksum": {"name": "sha256", "checksum": "657ba3d24e6849ba2c5570b24d3acc2d11a80bfdd284e95a939153afd96c07e2"}, "nodes": ["model.segment.segment_web_sessions"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment/models/sessionization/segment_web_sessions__stitched.sql": {"path": {"searched_path": "models", "relative_path": "sessionization/segment_web_sessions__stitched.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment"}, "checksum": {"name": "sha256", "checksum": "5aed5a0292ac5cd9932e48c685abf51e2f6e126a3098458aca3535a51f1f5587"}, "nodes": ["model.segment.segment_web_sessions__stitched"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment/models/sessionization/segment_web_sessions__initial.sql": {"path": {"searched_path": "models", "relative_path": "sessionization/segment_web_sessions__initial.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment"}, "checksum": {"name": "sha256", "checksum": "208756af421689656eea70adf89c86080bf1141b9b214c58af90ec372ad8fa82"}, "nodes": ["model.segment.segment_web_sessions__initial"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment/models/sessionization/segment_web_page_views__sessionized.sql": {"path": {"searched_path": "models", "relative_path": "sessionization/segment_web_page_views__sessionized.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment"}, "checksum": {"name": "sha256", "checksum": "edd7bed9b4fe85bfb06c4b51d8bf21fd29f026c64064764bafb6cc333538a726"}, "nodes": ["model.segment.segment_web_page_views__sessionized"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment/models/base/segment_web_page_views.sql": {"path": {"searched_path": "models", "relative_path": "base/segment_web_page_views.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment"}, "checksum": {"name": "sha256", "checksum": "cd03be98c23df7481a908b58870f3c877782a06ad490c906bb1b66720a7f8bac"}, "nodes": ["model.segment.segment_web_page_views"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment/analysis/mode_queries/audience_overview.sql": {"path": {"searched_path": "analysis", "relative_path": "mode_queries/audience_overview.sql", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment"}, "checksum": {"name": "sha256", "checksum": "6a3e1a7f961312947e03b8e82864fa85a9a9aabfc6e43f1d0cb5abfe8637c724"}, "nodes": ["analysis.segment.audience_overview"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment/data/referrer_mapping.csv": {"path": {"searched_path": "data", "relative_path": "referrer_mapping.csv", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment"}, "checksum": {"name": "path", "checksum": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment/data/referrer_mapping.csv"}, "nodes": ["seed.segment.referrer_mapping"], "docs": [], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment/models/sessionization/docs.md": {"path": {"searched_path": "models", "relative_path": "sessionization/docs.md", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment"}, "checksum": {"name": "sha256", "checksum": "9885ca96d72b7abe7b4339193824851a1c201d6cc1d3fe0af04511375633c9ce"}, "nodes": [], "docs": ["segment.segment_web_user_stitching", "segment.segment_web_page_views__sessionized", "segment.segment_web_sessions__initial", "segment.segment_web_sessions__stitched", "segment.segment_web_sessions"], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment/models/base/docs.md": {"path": {"searched_path": "models", "relative_path": "base/docs.md", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment"}, "checksum": {"name": "sha256", "checksum": "8e1d07d57e39d1cbe937ce6e830f4779d6ea57152d809e48adc2d94067e0d058"}, "nodes": [], "docs": ["segment.segment_web_page_views"], "macros": [], "sources": [], "patches": [], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment/models/sessionization/schema.yml": {"path": {"searched_path": "models", "relative_path": "sessionization/schema.yml", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment"}, "checksum": {"name": "sha256", "checksum": "2c51f5619c49c73e1d100436c4b46adf78b0775f2c668d36f8a7dac462d8fc40"}, "nodes": ["test.segment.unique_segment_web_user_stitching_anonymous_id", "test.segment.not_null_segment_web_user_stitching_anonymous_id", "test.segment.unique_segment_web_page_views__sessionized_page_view_id", "test.segment.not_null_segment_web_page_views__sessionized_page_view_id", "test.segment.unique_segment_web_sessions__initial_session_id", "test.segment.not_null_segment_web_sessions__initial_session_id", "test.segment.unique_segment_web_sessions__stitched_session_id", "test.segment.not_null_segment_web_sessions__stitched_session_id", "test.segment.unique_segment_web_sessions_session_id", "test.segment.not_null_segment_web_sessions_session_id"], "docs": [], "macros": [], "sources": [], "patches": ["segment_web_user_stitching", "segment_web_page_views__sessionized", "segment_web_sessions__initial", "segment_web_sessions__stitched", "segment_web_sessions"], "macro_patches": []}, "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment/models/base/schema.yml": {"path": {"searched_path": "models", "relative_path": "base/schema.yml", "project_root": "/Users/claire/fishtown/packages/segment/integration_tests/dbt_modules/segment"}, "checksum": {"name": "sha256", "checksum": "55e0b0cc0808aa87f5b7299fdc7d39cd4ddea712bfbff80da22e8860e22484aa"}, "nodes": ["test.segment.unique_segment_web_page_views_page_view_id", "test.segment.not_null_segment_web_page_views_page_view_id"], "docs": [], "macros": [], "sources": [], "patches": ["segment_web_page_views"], "macro_patches": []}}}